{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598d844d",
   "metadata": {},
   "source": [
    "# 5) Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71a7e2",
   "metadata": {},
   "source": [
    "Table of Content here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280fb30",
   "metadata": {},
   "source": [
    "## 5.1) Import necessary packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3117253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e238bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de675b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444692bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa34d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28350464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cd4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b35b4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "090254e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "563300c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c54be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "18530394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a0e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2475ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6837c310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1885, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age25-34</th>\n",
       "      <th>age35-44</th>\n",
       "      <th>age45-54</th>\n",
       "      <th>age55-64</th>\n",
       "      <th>age65+</th>\n",
       "      <th>Male</th>\n",
       "      <th>Edu_gr2</th>\n",
       "      <th>Edu_gr3</th>\n",
       "      <th>Edu_gr4</th>\n",
       "      <th>Edu_gr5</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_level</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Age_level</th>\n",
       "      <th>Amyl_binary</th>\n",
       "      <th>Amyl_user</th>\n",
       "      <th>Cannabis_binary</th>\n",
       "      <th>Cannabis_user</th>\n",
       "      <th>Edu_gr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Professional certificate</td>\n",
       "      <td>UK</td>\n",
       "      <td>Mixed-White/Asian</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>Edu_gr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>2</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Professional certificate</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Masters degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age25-34  age35-44  age45-54  age55-64  age65+  Male  Edu_gr2  Edu_gr3  \\\n",
       "0         0         1         0         0       0     0        0        1   \n",
       "1         1         0         0         0       0     1        0        0   \n",
       "2         0         1         0         0       0     1        0        1   \n",
       "3         0         0         0         0       0     0        0        0   \n",
       "4         0         1         0         0       0     0        0        0   \n",
       "\n",
       "   Edu_gr4  Edu_gr5  ...  Education_level                 Education  Country  \\\n",
       "0        0        0  ...                6  Professional certificate       UK   \n",
       "1        0        1  ...                9          Doctorate degree       UK   \n",
       "2        0        0  ...                6  Professional certificate       UK   \n",
       "3        0        1  ...                8            Masters degree       UK   \n",
       "4        0        1  ...                9          Doctorate degree       UK   \n",
       "\n",
       "           Ethnicity  Age_level  Amyl_binary  Amyl_user  Cannabis_binary  \\\n",
       "0  Mixed-White/Asian          3     Non-user          0         Non-user   \n",
       "1              White          2         User          1             User   \n",
       "2              White          3     Non-user          0             User   \n",
       "3              White          1     Non-user          0             User   \n",
       "4              White          3     Non-user          0             User   \n",
       "\n",
       "   Cannabis_user   Edu_gr  \n",
       "0              0  Edu_gr3  \n",
       "1              1  Edu_gr5  \n",
       "2              1  Edu_gr3  \n",
       "3              1  Edu_gr5  \n",
       "4              1  Edu_gr5  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the latest dataset\n",
    "drug_2 = pd.read_csv('../data/drug_2.csv', index_col=0)\n",
    "print(drug_2.shape)\n",
    "drug_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be835b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21457f39",
   "metadata": {},
   "source": [
    "## 5.2) Modeling Amyl consumption\n",
    "There are two approaches to treat Age:\n",
    "i) Consider Age as numerical type. That is to use 'Age_value' feature (Age_value has 6 levels).\n",
    "ii) Consider Age as categorical type. That is to use dummies 'age25_34', 'age35_44' and so.\n",
    "In section 5.2.1 we will do the first approach, and section 5.2.2 the second. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b922cd4",
   "metadata": {},
   "source": [
    "### 5.2.1) Modeling with Age as numerical type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5a95f",
   "metadata": {},
   "source": [
    "#### 5.2.1.1) Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a4d067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "      <th>Edu_gr2</th>\n",
       "      <th>Edu_gr3</th>\n",
       "      <th>Edu_gr4</th>\n",
       "      <th>Edu_gr5</th>\n",
       "      <th>Canada</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Other</th>\n",
       "      <th>Republic of Ireland</th>\n",
       "      <th>UK</th>\n",
       "      <th>USA</th>\n",
       "      <th>Age_value</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Male  Edu_gr2  Edu_gr3  Edu_gr4  Edu_gr5  Canada  New Zealand  Other  \\\n",
       "0     0        0        1        0        0       0            0      0   \n",
       "1     1        0        0        0        1       0            0      0   \n",
       "2     1        0        1        0        0       0            0      0   \n",
       "3     0        0        0        0        1       0            0      0   \n",
       "4     0        0        0        0        1       0            0      0   \n",
       "\n",
       "   Republic of Ireland  UK  USA  Age_value   Nscore   Escore   Oscore  \\\n",
       "0                    0   1    0    0.49788  0.31287 -0.57545 -0.58331   \n",
       "1                    0   1    0   -0.07854 -0.67825  1.93886  1.43533   \n",
       "2                    0   1    0    0.49788 -0.46725  0.80523 -0.84732   \n",
       "3                    0   1    0   -0.95197 -0.14882 -0.80615 -0.01928   \n",
       "4                    0   1    0    0.49788  0.73545 -1.63340 -0.45174   \n",
       "\n",
       "    Ascore   Cscore  Impulsive       SS  \n",
       "0 -0.91699 -0.00665   -0.21712 -1.18084  \n",
       "1  0.76096 -0.14277   -0.71126 -0.21575  \n",
       "2 -1.62090 -1.01450   -1.37983  0.40148  \n",
       "3  0.59042  0.58489   -1.37983 -1.18084  \n",
       "4 -0.30172  1.30612   -0.21712 -0.21575  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = ['Male', 'Edu_gr2', 'Edu_gr3', 'Edu_gr4', 'Edu_gr5', 'Canada', 'New Zealand', 'Other', 'Republic of Ireland', \n",
    "            'UK', 'USA', 'Age_value', 'Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS']\n",
    "X = drug_2[col_list]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc1b9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Amyl_user, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = drug_2['Amyl_user']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c131cf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.803714\n",
       "1    0.196286\n",
       "Name: Amyl_user, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_2['Amyl_user'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ad813829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.808355\n",
       "1    0.191645\n",
       "Name: Amyl_user, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "153758fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.785146\n",
       "1    0.214854\n",
       "Name: Amyl_user, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad615be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1508, 19) (1508,)\n",
      "(377, 19) (377,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=12)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Next time we will do 'stratify', but for now this train-test-split is good (almost the same class proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78822e80",
   "metadata": {},
   "source": [
    "#### 5.2.1.2) Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4203eea",
   "metadata": {},
   "source": [
    "#### Explore Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0ad33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_feature_names', '_check_n_features', '_compute_oob_predictions', '_estimator_type', '_get_oob_predictions', '_get_param_names', '_get_tags', '_make_estimator', '_more_tags', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_set_oob_score_and_attributes', '_validate_X_predict', '_validate_data', '_validate_estimator', '_validate_y_class_weight', 'apply', 'decision_path', 'feature_importances_', 'fit', 'get_params', 'n_features_', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params']\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "print(dir(RandomForestClassifier))\n",
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f61710d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08713b6a",
   "metadata": {},
   "source": [
    "#### Explore RandomForestClassifier through Cross-Validation. Use only X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "729fe096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80794702, 0.81788079, 0.81788079, 0.82724252, 0.80730897])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore RandomForestClassifier through Cross-Validation. Use only X_train and y_train\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, X_train, y_train, cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462af370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73397755, 0.74879032, 0.75740358, 0.74801587, 0.74390244])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use roc_auc as performance measure\n",
    "cross_val_score(rf, X_train, y_train, cv=k_fold, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1326b70",
   "metadata": {},
   "source": [
    "#### Explore RandomForestClassifier through holdout set. Use both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df0dc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with default hyper-parameters\n",
    "rf_fit = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86d50cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12242663450905042, 'Cscore'),\n",
       " (0.11514545930584628, 'Nscore'),\n",
       " (0.1144220742437734, 'Oscore'),\n",
       " (0.11066689941455875, 'Ascore'),\n",
       " (0.1090545563188401, 'Escore'),\n",
       " (0.09841159456701842, 'SS'),\n",
       " (0.07736107504946627, 'Impulsive'),\n",
       " (0.07102014698826864, 'Age_value'),\n",
       " (0.03347117805552255, 'Male'),\n",
       " (0.03151184892986846, 'USA'),\n",
       " (0.026174061488758178, 'UK'),\n",
       " (0.020252095605134343, 'Edu_gr4'),\n",
       " (0.019680128804221424, 'Edu_gr3'),\n",
       " (0.01797576039798906, 'Edu_gr5'),\n",
       " (0.009258103788733188, 'Other'),\n",
       " (0.009213690762690173, 'Edu_gr2'),\n",
       " (0.006269491838442038, 'Canada'),\n",
       " (0.0057204191070267365, 'Republic of Ireland'),\n",
       " (0.0019647808247915547, 'New Zealand')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output feature importance\n",
    "sorted(zip(rf_fit.feature_importances_, X_train.columns), reverse=True)\n",
    "# Yes, similar to what we have in EDA step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddcacccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_fit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc37cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n",
      "[[0.83 0.17]\n",
      " [0.86 0.14]\n",
      " [0.78 0.22]\n",
      " [0.99 0.01]\n",
      " [0.76 0.24]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on X_test\n",
    "y_pred = rf_fit.predict(X_test)\n",
    "y_pred_probs = rf_fit.predict_proba(X_test)\n",
    "print(y_pred[:5])\n",
    "print(y_pred_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29174ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.526 / Recall: 0.123 / Accuracy: 0.788\n"
     ]
    }
   ],
   "source": [
    "# Output performance\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label=1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3),\n",
    "                                                        round((y_pred==y_test).sum() / len(y_pred),3)))\n",
    "# Performance is not greate, but consistent with rough version in EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17796ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 1.0 / Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict on X_train and output train performance\n",
    "y_pred_train = rf_fit.predict(X_train)\n",
    "precision_train, recall_train, fscore_train, support_train = score(y_train, y_pred_train, pos_label=1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision_train, 3),\n",
    "                                                        round(recall_train, 3),\n",
    "                                                        round((y_pred_train==y_train).sum() / len(y_pred_train),3)))\n",
    "# OK, this might be the evidence of overfitting. We have 'max_depth': None and 'min_samples_leaf': 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a672f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55346a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.683\n"
     ]
    }
   ],
   "source": [
    "# Output roc_auc\n",
    "print('roc_auc: {}'.format(round(roc_auc_score(y_test, y_pred_probs[:, 1]), 3)))\n",
    "\n",
    "# Interesing roc_auc here is smaller than cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7807bf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs[:, 1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d31c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32d7ac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.333 / Recall: 0.049 / Accuracy: 0.775\n",
      "Precision_train: 1.0 / Recall_train: 0.654 / Accuracy_train: 0.934\n"
     ]
    }
   ],
   "source": [
    "# Try some not default hyperparameters\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=10, n_jobs=-1)\n",
    "rf_fit = rf.fit(X_train, y_train)\n",
    "\n",
    "# Test performance\n",
    "y_pred = rf_fit.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label=1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3),\n",
    "                                                        round((y_pred==y_test).sum() / len(y_pred),3)))\n",
    "\n",
    "# Train performance\n",
    "y_pred_train = rf_fit.predict(X_train)\n",
    "precision_train, recall_train, fscore_train, support_train = score(y_train, y_pred_train, pos_label=1, average='binary')\n",
    "print('Precision_train: {} / Recall_train: {} / Accuracy_train: {}'.format(round(precision_train, 3),\n",
    "                                                        round(recall_train, 3),\n",
    "                                                        round((y_pred_train==y_train).sum() / len(y_pred_train),3)))\n",
    "\n",
    "# Now, train performance is worse, but test performance is worse as well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bf91c",
   "metadata": {},
   "source": [
    "#### Explore RandomForestClassifier with Grid-search (write your own grid search)\n",
    "With holdout test set. Use both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04d3a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function fit RF and output test performance (code from the Linkedin course)\n",
    "def train_RF(n_est, depth):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1)\n",
    "    rf_fit = rf.fit(X_train, y_train)\n",
    "    y_pred = rf_fit.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label=1, average='binary')\n",
    "    print('Est: {} / Depth: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        n_est, depth, round(precision, 3), round(recall, 3),\n",
    "        round((y_pred==y_test).sum() / len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23918726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ---- Precision: 0.368 / Recall: 0.086 / Accuracy: 0.772\n",
      "Est: 10 / Depth: 20 ---- Precision: 0.389 / Recall: 0.086 / Accuracy: 0.775\n",
      "Est: 10 / Depth: 30 ---- Precision: 0.5 / Recall: 0.16 / Accuracy: 0.785\n",
      "Est: 10 / Depth: None ---- Precision: 0.36 / Recall: 0.111 / Accuracy: 0.767\n",
      "Est: 50 / Depth: 10 ---- Precision: 0.529 / Recall: 0.111 / Accuracy: 0.788\n",
      "Est: 50 / Depth: 20 ---- Precision: 0.5 / Recall: 0.136 / Accuracy: 0.785\n",
      "Est: 50 / Depth: 30 ---- Precision: 0.478 / Recall: 0.136 / Accuracy: 0.782\n",
      "Est: 50 / Depth: None ---- Precision: 0.474 / Recall: 0.111 / Accuracy: 0.782\n",
      "Est: 100 / Depth: 10 ---- Precision: 0.438 / Recall: 0.086 / Accuracy: 0.78\n",
      "Est: 100 / Depth: 20 ---- Precision: 0.5 / Recall: 0.123 / Accuracy: 0.785\n",
      "Est: 100 / Depth: 30 ---- Precision: 0.429 / Recall: 0.111 / Accuracy: 0.777\n",
      "Est: 100 / Depth: None ---- Precision: 0.5 / Recall: 0.173 / Accuracy: 0.785\n",
      "Est: 150 / Depth: 10 ---- Precision: 0.375 / Recall: 0.074 / Accuracy: 0.775\n",
      "Est: 150 / Depth: 20 ---- Precision: 0.5 / Recall: 0.111 / Accuracy: 0.785\n",
      "Est: 150 / Depth: 30 ---- Precision: 0.478 / Recall: 0.136 / Accuracy: 0.782\n",
      "Est: 150 / Depth: None ---- Precision: 0.45 / Recall: 0.111 / Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100, 150]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_RF(n_est, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e4763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de6f73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let use roc_auc performance measure\n",
    "# Function fit RF and output test performance (code from the Linkedin course)\n",
    "def train_RF(n_est, depth):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1)\n",
    "    rf_fit = rf.fit(X_train, y_train)\n",
    "    y_pred_probs = rf_fit.predict_proba(X_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_probs) \n",
    "    print('Est: {} / Depth: {} ---- roc_auc: {}'.format(\n",
    "        n_est, depth, round(roc_auc, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2879e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ---- roc_auc: 0.693\n",
      "Est: 10 / Depth: 20 ---- roc_auc: 0.661\n",
      "Est: 10 / Depth: 30 ---- roc_auc: 0.616\n",
      "Est: 10 / Depth: None ---- roc_auc: 0.69\n",
      "Est: 50 / Depth: 10 ---- roc_auc: 0.688\n",
      "Est: 50 / Depth: 20 ---- roc_auc: 0.686\n",
      "Est: 50 / Depth: 30 ---- roc_auc: 0.678\n",
      "Est: 50 / Depth: None ---- roc_auc: 0.69\n",
      "Est: 100 / Depth: 10 ---- roc_auc: 0.694\n",
      "Est: 100 / Depth: 20 ---- roc_auc: 0.697\n",
      "Est: 100 / Depth: 30 ---- roc_auc: 0.713\n",
      "Est: 100 / Depth: None ---- roc_auc: 0.696\n",
      "Est: 150 / Depth: 10 ---- roc_auc: 0.701\n",
      "Est: 150 / Depth: 20 ---- roc_auc: 0.69\n",
      "Est: 150 / Depth: 30 ---- roc_auc: 0.693\n",
      "Est: 150 / Depth: None ---- roc_auc: 0.705\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100, 150]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_RF(n_est, depth)\n",
    "        \n",
    "# n_est = 100, depth 30 is the best\n",
    "# Interesting why still smaller than the numbers in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a880b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9903702f",
   "metadata": {},
   "source": [
    "#### Explore RandomForestClassifier with GridSearchCV. Use only train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b46a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.158404</td>\n",
       "      <td>0.00213</td>\n",
       "      <td>0.019747</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.817881</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.810631</td>\n",
       "      <td>0.818957</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.158404       0.00213         0.019747        0.003909   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "0            None                100   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'max_depth': None, 'n_estimators': 100}           0.827815   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.824503           0.817881           0.813953           0.810631   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.818957        0.006399                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GridSearchCV with default hyperparameters\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [100],\n",
    "        'max_depth': [None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]\n",
    "\n",
    "# Yes, the numbers are close to original cross-validation that I had above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd92d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.446488</td>\n",
       "      <td>0.040041</td>\n",
       "      <td>0.051070</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 150}</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>0.807309</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816305</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.323203</td>\n",
       "      <td>0.055206</td>\n",
       "      <td>0.023641</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 100}</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.831126</td>\n",
       "      <td>0.817881</td>\n",
       "      <td>0.817276</td>\n",
       "      <td>0.800664</td>\n",
       "      <td>0.816303</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337261</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.044489</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.831126</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>0.807309</td>\n",
       "      <td>0.807309</td>\n",
       "      <td>0.816301</td>\n",
       "      <td>0.009739</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.526986</td>\n",
       "      <td>0.054869</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.817881</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794020</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812323</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       0.446488      0.040041         0.051070        0.024453   \n",
       "0       0.323203      0.055206         0.023641        0.001711   \n",
       "2       0.337261      0.034783         0.044489        0.017436   \n",
       "3       0.526986      0.054869         0.022740        0.007633   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "1              30                150   \n",
       "0              30                100   \n",
       "2            None                100   \n",
       "3            None                150   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "1    {'max_depth': 30, 'n_estimators': 150}           0.824503   \n",
       "0    {'max_depth': 30, 'n_estimators': 100}           0.814570   \n",
       "2  {'max_depth': None, 'n_estimators': 100}           0.824503   \n",
       "3  {'max_depth': None, 'n_estimators': 150}           0.817881   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.824503           0.811258           0.807309           0.813953   \n",
       "0           0.831126           0.817881           0.817276           0.800664   \n",
       "2           0.831126           0.811258           0.807309           0.807309   \n",
       "3           0.821192           0.814570           0.794020           0.813953   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.816305        0.007019                1  \n",
       "0         0.816303        0.009703                2  \n",
       "2         0.816301        0.009739                3  \n",
       "3         0.812323        0.009511                4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GridSearchCV if n_est = 100, depth 30 is the best\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [100, 150],\n",
    "        'max_depth': [30, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]\n",
    "\n",
    "# Very close performance. max_depth 30 is better than 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3d586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac3e429a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525581</td>\n",
       "      <td>0.018564</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.714528</td>\n",
       "      <td>0.742263</td>\n",
       "      <td>0.767312</td>\n",
       "      <td>0.756137</td>\n",
       "      <td>0.746153</td>\n",
       "      <td>0.745279</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380448</td>\n",
       "      <td>0.096840</td>\n",
       "      <td>0.021251</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.700360</td>\n",
       "      <td>0.757808</td>\n",
       "      <td>0.758727</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>0.743133</td>\n",
       "      <td>0.739792</td>\n",
       "      <td>0.021213</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.396610</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.029528</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 150}</td>\n",
       "      <td>0.723431</td>\n",
       "      <td>0.724774</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.736732</td>\n",
       "      <td>0.724655</td>\n",
       "      <td>0.732477</td>\n",
       "      <td>0.011253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.261139</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.020149</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 100}</td>\n",
       "      <td>0.709864</td>\n",
       "      <td>0.727530</td>\n",
       "      <td>0.765440</td>\n",
       "      <td>0.721087</td>\n",
       "      <td>0.728178</td>\n",
       "      <td>0.730420</td>\n",
       "      <td>0.018705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       0.525581      0.018564         0.017555        0.000489   \n",
       "2       0.380448      0.096840         0.021251        0.001688   \n",
       "1       0.396610      0.006166         0.029528        0.000586   \n",
       "0       0.261139      0.001596         0.020149        0.000399   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "3            None                150   \n",
       "2            None                100   \n",
       "1              30                150   \n",
       "0              30                100   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "3  {'max_depth': None, 'n_estimators': 150}           0.714528   \n",
       "2  {'max_depth': None, 'n_estimators': 100}           0.700360   \n",
       "1    {'max_depth': 30, 'n_estimators': 150}           0.723431   \n",
       "0    {'max_depth': 30, 'n_estimators': 100}           0.709864   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.742263           0.767312           0.756137           0.746153   \n",
       "2           0.757808           0.758727           0.738931           0.743133   \n",
       "1           0.724774           0.752791           0.736732           0.724655   \n",
       "0           0.727530           0.765440           0.721087           0.728178   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.745279        0.017657                1  \n",
       "2         0.739792        0.021213                2  \n",
       "1         0.732477        0.011253                3  \n",
       "0         0.730420        0.018705                4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GridSearchCV if n_est = 100, depth 30 is the best in term of roc_auc\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [100, 150],\n",
    "        'max_depth': [30, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]\n",
    "\n",
    "# The best now is 150 and None. Interesting cross-validation is better than with holdout test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f4dfa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.225943</td>\n",
       "      <td>0.057881</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'max_features': 'auto'}</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>0.810631</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814321</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329879</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_features': 7}</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.803987</td>\n",
       "      <td>0.810631</td>\n",
       "      <td>0.812328</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.225943      0.057881         0.019149        0.006161   \n",
       "1       0.329879      0.007555         0.019357        0.001647   \n",
       "\n",
       "  param_max_features                    params  split0_test_score  \\\n",
       "0               auto  {'max_features': 'auto'}           0.814570   \n",
       "1                  7       {'max_features': 7}           0.807947   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.821192           0.811258           0.810631           0.813953   \n",
       "1           0.811258           0.827815           0.803987           0.810631   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.814321        0.003752                1  \n",
       "1         0.812328        0.008156                2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here if we use default performance metric\n",
    "rf = RandomForestClassifier()\n",
    "n_features = 19\n",
    "param = {'max_features': ['auto', int(np.sqrt(n_features) + 3)]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59eb851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d56ab146",
   "metadata": {},
   "source": [
    "#### Hyperparameters search with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b0afce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
      "['gini', 'entropy', 'log_loss']\n",
      "['auto', 6, 8]\n",
      "[10, 30, 50, 70, 90, None]\n",
      "[2, 6, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
       " 'criterion': ['gini', 'entropy', 'log_loss'],\n",
       " 'max_depth': [10, 30, 50, 70, 90, None],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto', 6, 8]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 19 # Input the number of features here. Alternatively estimate a model and get _n_features_in_ attribute\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 9)]\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "max_features = ['auto', int(np.sqrt(n_features)) + 2, int(np.sqrt(n_features)) + 4]\n",
    "max_depth = [int(x) for x in np.linspace(10, 90, num = 5)]   \n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 6, 10]\n",
    "\n",
    "print(n_estimators)\n",
    "print(criteria)\n",
    "print(max_features)\n",
    "print(max_depth)\n",
    "print(min_samples_split)\n",
    "\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'criterion': criteria,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'max_features': max_features\n",
    "        }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab6af847",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2430 fits failed out of a total of 7290.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2430 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.7398585  0.74480837 0.74256583 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.686549</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>0.046880</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.745124</td>\n",
       "      <td>0.766959</td>\n",
       "      <td>0.776993</td>\n",
       "      <td>0.758408</td>\n",
       "      <td>0.736195</td>\n",
       "      <td>0.756736</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.775801</td>\n",
       "      <td>0.039541</td>\n",
       "      <td>0.047498</td>\n",
       "      <td>0.004090</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.740178</td>\n",
       "      <td>0.761023</td>\n",
       "      <td>0.786744</td>\n",
       "      <td>0.758408</td>\n",
       "      <td>0.728645</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1.036223</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.072124</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.743358</td>\n",
       "      <td>0.763002</td>\n",
       "      <td>0.778265</td>\n",
       "      <td>0.757485</td>\n",
       "      <td>0.730155</td>\n",
       "      <td>0.754453</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>1.271461</td>\n",
       "      <td>0.086368</td>\n",
       "      <td>0.090373</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>450</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.739401</td>\n",
       "      <td>0.760953</td>\n",
       "      <td>0.778547</td>\n",
       "      <td>0.757273</td>\n",
       "      <td>0.734254</td>\n",
       "      <td>0.754085</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1.454498</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.098252</td>\n",
       "      <td>0.010982</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.739189</td>\n",
       "      <td>0.758267</td>\n",
       "      <td>0.779890</td>\n",
       "      <td>0.756918</td>\n",
       "      <td>0.734685</td>\n",
       "      <td>0.753790</td>\n",
       "      <td>0.016058</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1.357724</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.088578</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>entropy</td>\n",
       "      <td>70</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 70, 'max...</td>\n",
       "      <td>0.746608</td>\n",
       "      <td>0.751767</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.737993</td>\n",
       "      <td>0.753063</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1.087629</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.742157</td>\n",
       "      <td>0.754734</td>\n",
       "      <td>0.776710</td>\n",
       "      <td>0.757273</td>\n",
       "      <td>0.733535</td>\n",
       "      <td>0.752882</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0.803497</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.054062</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>entropy</td>\n",
       "      <td>90</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 90, 'max...</td>\n",
       "      <td>0.734313</td>\n",
       "      <td>0.758197</td>\n",
       "      <td>0.773742</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.739934</td>\n",
       "      <td>0.752678</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0.823357</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>entropy</td>\n",
       "      <td>90</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 90, 'max...</td>\n",
       "      <td>0.747032</td>\n",
       "      <td>0.754522</td>\n",
       "      <td>0.772046</td>\n",
       "      <td>0.757769</td>\n",
       "      <td>0.729436</td>\n",
       "      <td>0.752161</td>\n",
       "      <td>0.013965</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1.187261</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.080201</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>450</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.739118</td>\n",
       "      <td>0.761518</td>\n",
       "      <td>0.775155</td>\n",
       "      <td>0.754576</td>\n",
       "      <td>0.729724</td>\n",
       "      <td>0.752018</td>\n",
       "      <td>0.016097</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "507       0.686549      0.029421         0.046880        0.001516   \n",
       "534       0.775801      0.039541         0.047498        0.004090   \n",
       "501       1.036223      0.007631         0.072124        0.000976   \n",
       "511       1.271461      0.086368         0.090373        0.020181   \n",
       "512       1.454498      0.121219         0.098252        0.010982   \n",
       "755       1.357724      0.016105         0.088578        0.000874   \n",
       "510       1.087629      0.059590         0.078000        0.011370   \n",
       "832       0.803497      0.001997         0.054062        0.001359   \n",
       "823       0.823357      0.010117         0.054655        0.001715   \n",
       "502       1.187261      0.008305         0.080201        0.002235   \n",
       "\n",
       "    param_criterion param_max_depth param_max_features  \\\n",
       "507         entropy              10               auto   \n",
       "534         entropy              10                  6   \n",
       "501         entropy              10               auto   \n",
       "511         entropy              10               auto   \n",
       "512         entropy              10               auto   \n",
       "755         entropy              70               auto   \n",
       "510         entropy              10               auto   \n",
       "832         entropy              90               auto   \n",
       "823         entropy              90               auto   \n",
       "502         entropy              10               auto   \n",
       "\n",
       "    param_min_samples_split param_n_estimators  \\\n",
       "507                      10                250   \n",
       "534                      10                250   \n",
       "501                       6                400   \n",
       "511                      10                450   \n",
       "512                      10                500   \n",
       "755                      10                500   \n",
       "510                      10                400   \n",
       "832                      10                300   \n",
       "823                       6                300   \n",
       "502                       6                450   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "507  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.745124   \n",
       "534  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.740178   \n",
       "501  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.743358   \n",
       "511  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.739401   \n",
       "512  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.739189   \n",
       "755  {'criterion': 'entropy', 'max_depth': 70, 'max...           0.746608   \n",
       "510  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.742157   \n",
       "832  {'criterion': 'entropy', 'max_depth': 90, 'max...           0.734313   \n",
       "823  {'criterion': 'entropy', 'max_depth': 90, 'max...           0.747032   \n",
       "502  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.739118   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "507           0.766959           0.776993           0.758408   \n",
       "534           0.761023           0.786744           0.758408   \n",
       "501           0.763002           0.778265           0.757485   \n",
       "511           0.760953           0.778547           0.757273   \n",
       "512           0.758267           0.779890           0.756918   \n",
       "755           0.751767           0.775862           0.753086   \n",
       "510           0.754734           0.776710           0.757273   \n",
       "832           0.758197           0.773742           0.757202   \n",
       "823           0.754522           0.772046           0.757769   \n",
       "502           0.761518           0.775155           0.754576   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "507           0.736195         0.756736        0.014659                1  \n",
       "534           0.728645         0.755000        0.019849                2  \n",
       "501           0.730155         0.754453        0.016509                3  \n",
       "511           0.734254         0.754085        0.015904                4  \n",
       "512           0.734685         0.753790        0.016058                5  \n",
       "755           0.737993         0.753063        0.012572                6  \n",
       "510           0.733535         0.752882        0.014696                7  \n",
       "832           0.739934         0.752678        0.014102                8  \n",
       "823           0.729436         0.752161        0.013965                9  \n",
       "502           0.729724         0.752018        0.016097               10  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV here\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator = rf,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ad81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500],: best 250, 400 \n",
    "# 'criterion': ['gini', 'entropy', 'log_loss'],  :best is entropy\n",
    "# 'max_depth': [10, 30, 50, 70, 90, None],: best 10\n",
    "# 'min_samples_split': [2, 6, 10],: best 10, 6\n",
    "# 'max_features': ['auto', 6, 8]}: best is auto, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "999922ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf89f44",
   "metadata": {},
   "source": [
    "For GridSearch we have 9x3x6x3x3 = 1458 combinations. With vc=5, we estimate 5x1458 = 7290 models. About 10 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50524ae1",
   "metadata": {},
   "source": [
    "#### Hyperparameters search with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "663b39b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "200 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.74604295 0.74098577        nan\n",
      " 0.74362952 0.74446759 0.74363003 0.73948799        nan 0.7321864\n",
      "        nan 0.74255947        nan 0.75221585        nan 0.74523358\n",
      "        nan 0.731511   0.738993          nan        nan 0.74718785\n",
      " 0.74389385 0.73875024 0.74217075 0.74154           nan 0.74518237\n",
      "        nan 0.73581177 0.73932689        nan 0.74364023        nan\n",
      " 0.74562331 0.73292237        nan 0.74125345 0.73699713 0.74434484\n",
      "        nan 0.74104763        nan        nan        nan        nan\n",
      " 0.73513732        nan        nan 0.73557609        nan 0.74103117\n",
      "        nan 0.74749157        nan        nan        nan 0.73701985\n",
      "        nan 0.74445159        nan 0.74776278        nan 0.73082475\n",
      " 0.74011364 0.74976906        nan        nan 0.74161161 0.73383936\n",
      " 0.73580232 0.74043856 0.744987          nan 0.74482594 0.74317984\n",
      " 0.73901765 0.73922386 0.74440388 0.74303251        nan 0.74209482\n",
      "        nan 0.75190762 0.73580873        nan 0.73748512 0.74182121\n",
      " 0.74919153 0.73395357 0.73689944        nan        nan        nan\n",
      " 0.73179856 0.73585921 0.73428583 0.73757864]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.897755</td>\n",
       "      <td>0.016666</td>\n",
       "      <td>0.059056</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>90</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 350, 'min_samples_split': 10,...</td>\n",
       "      <td>0.744418</td>\n",
       "      <td>0.748445</td>\n",
       "      <td>0.769503</td>\n",
       "      <td>0.757485</td>\n",
       "      <td>0.741228</td>\n",
       "      <td>0.752216</td>\n",
       "      <td>0.010221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.249607</td>\n",
       "      <td>0.022403</td>\n",
       "      <td>0.085183</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 10,...</td>\n",
       "      <td>0.731204</td>\n",
       "      <td>0.756713</td>\n",
       "      <td>0.777841</td>\n",
       "      <td>0.760749</td>\n",
       "      <td>0.733031</td>\n",
       "      <td>0.751908</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.215304</td>\n",
       "      <td>0.110755</td>\n",
       "      <td>0.077801</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>450</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 450, 'min_samples_split': 10,...</td>\n",
       "      <td>0.735656</td>\n",
       "      <td>0.760882</td>\n",
       "      <td>0.771622</td>\n",
       "      <td>0.756066</td>\n",
       "      <td>0.724619</td>\n",
       "      <td>0.749769</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.603863</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>250</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 250, 'min_samples_split': 10,...</td>\n",
       "      <td>0.742581</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.779890</td>\n",
       "      <td>0.740528</td>\n",
       "      <td>0.737058</td>\n",
       "      <td>0.749192</td>\n",
       "      <td>0.015615</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.733372</td>\n",
       "      <td>0.128985</td>\n",
       "      <td>0.101340</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.736645</td>\n",
       "      <td>0.754452</td>\n",
       "      <td>0.769679</td>\n",
       "      <td>0.749716</td>\n",
       "      <td>0.728322</td>\n",
       "      <td>0.747763</td>\n",
       "      <td>0.014356</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.900705</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.059249</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>30</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 350, 'min_samples_split': 10,...</td>\n",
       "      <td>0.733324</td>\n",
       "      <td>0.751767</td>\n",
       "      <td>0.771410</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.729077</td>\n",
       "      <td>0.747492</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.259555</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.019548</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>70</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "      <td>0.740107</td>\n",
       "      <td>0.753392</td>\n",
       "      <td>0.770774</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.718579</td>\n",
       "      <td>0.747188</td>\n",
       "      <td>0.017310</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.480695</td>\n",
       "      <td>0.011060</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 6, ...</td>\n",
       "      <td>0.734737</td>\n",
       "      <td>0.734101</td>\n",
       "      <td>0.774802</td>\n",
       "      <td>0.740457</td>\n",
       "      <td>0.746117</td>\n",
       "      <td>0.746043</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.097200</td>\n",
       "      <td>0.029070</td>\n",
       "      <td>0.087478</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>70</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 400, 'min_samples_split': 10,...</td>\n",
       "      <td>0.743428</td>\n",
       "      <td>0.736433</td>\n",
       "      <td>0.772329</td>\n",
       "      <td>0.746346</td>\n",
       "      <td>0.729580</td>\n",
       "      <td>0.745623</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.139459</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.058850</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 350, 'min_samples_split': 10,...</td>\n",
       "      <td>0.737422</td>\n",
       "      <td>0.750283</td>\n",
       "      <td>0.765757</td>\n",
       "      <td>0.750603</td>\n",
       "      <td>0.722102</td>\n",
       "      <td>0.745234</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15       0.897755      0.016666         0.059056        0.001247   \n",
       "85       1.249607      0.022403         0.085183        0.001275   \n",
       "67       1.215304      0.110755         0.077801        0.004207   \n",
       "90       0.603863      0.021837         0.043786        0.001853   \n",
       "63       1.733372      0.128985         0.101340        0.018523   \n",
       "55       0.900705      0.026123         0.059249        0.001154   \n",
       "23       0.259555      0.003085         0.019548        0.000797   \n",
       "3        0.480695      0.011060         0.040004        0.008198   \n",
       "36       1.097200      0.029070         0.087478        0.018686   \n",
       "17       1.139459      0.016792         0.058850        0.001043   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_max_features  \\\n",
       "15                350                      10               auto   \n",
       "85                500                      10               auto   \n",
       "67                450                      10               auto   \n",
       "90                250                      10               auto   \n",
       "63                500                       2                  6   \n",
       "55                350                      10               auto   \n",
       "23                100                      10               auto   \n",
       "3                 200                       6               auto   \n",
       "36                400                      10               auto   \n",
       "17                350                      10                  8   \n",
       "\n",
       "   param_max_depth param_criterion  \\\n",
       "15              90         entropy   \n",
       "85              10         entropy   \n",
       "67              10         entropy   \n",
       "90              50            gini   \n",
       "63              90         entropy   \n",
       "55              30         entropy   \n",
       "23              70         entropy   \n",
       "3               10            gini   \n",
       "36              70            gini   \n",
       "17              30         entropy   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "15  {'n_estimators': 350, 'min_samples_split': 10,...           0.744418   \n",
       "85  {'n_estimators': 500, 'min_samples_split': 10,...           0.731204   \n",
       "67  {'n_estimators': 450, 'min_samples_split': 10,...           0.735656   \n",
       "90  {'n_estimators': 250, 'min_samples_split': 10,...           0.742581   \n",
       "63  {'n_estimators': 500, 'min_samples_split': 2, ...           0.736645   \n",
       "55  {'n_estimators': 350, 'min_samples_split': 10,...           0.733324   \n",
       "23  {'n_estimators': 100, 'min_samples_split': 10,...           0.740107   \n",
       "3   {'n_estimators': 200, 'min_samples_split': 6, ...           0.734737   \n",
       "36  {'n_estimators': 400, 'min_samples_split': 10,...           0.743428   \n",
       "17  {'n_estimators': 350, 'min_samples_split': 10,...           0.737422   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.748445           0.769503           0.757485   \n",
       "85           0.756713           0.777841           0.760749   \n",
       "67           0.760882           0.771622           0.756066   \n",
       "90           0.745902           0.779890           0.740528   \n",
       "63           0.754452           0.769679           0.749716   \n",
       "55           0.751767           0.771410           0.751880   \n",
       "23           0.753392           0.770774           0.753086   \n",
       "3            0.734101           0.774802           0.740457   \n",
       "36           0.736433           0.772329           0.746346   \n",
       "17           0.750283           0.765757           0.750603   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15           0.741228         0.752216        0.010221                1  \n",
       "85           0.733031         0.751908        0.017656                2  \n",
       "67           0.724619         0.749769        0.017161                3  \n",
       "90           0.737058         0.749192        0.015615                4  \n",
       "63           0.728322         0.747763        0.014356                5  \n",
       "55           0.729077         0.747492        0.015162                6  \n",
       "23           0.718579         0.747188        0.017310                7  \n",
       "3            0.746117         0.746043        0.015025                8  \n",
       "36           0.729580         0.745623        0.014563                9  \n",
       "17           0.722102         0.745234        0.014640               10  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV\n",
    "# This random search the grid that we created before.\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rs = RandomizedSearchCV(estimator = rf,\n",
    "                  param_distributions = grid,\n",
    "                  n_iter = 100,      \n",
    "                  scoring='roc_auc',\n",
    "                  n_jobs=-1,\n",
    "                  cv=5)\n",
    "rs_fit = rs.fit(X_train, y_train)\n",
    "pd.DataFrame(rs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd8e44",
   "metadata": {},
   "source": [
    "- For RandomizedSearchCV, if the distribution is given as list then it will be sampled uniformly. Of course, the results should be worse than GridSearchCV (but we save time). This is OK if our grid has small steps.\n",
    "- If distribution is given as distribution, we might able to find better performance than GridSearchCV, especially the grid steps are big (see the reading in Unit18).\n",
    "- Let try to give distribution here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aacef207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]\n",
      "['gini', 'entropy', 'log_loss']\n",
      "['auto', 6, 8]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, None]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  151,\n",
       "  152,\n",
       "  153,\n",
       "  154,\n",
       "  155,\n",
       "  156,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  172,\n",
       "  173,\n",
       "  174,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  187,\n",
       "  188,\n",
       "  189,\n",
       "  190,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  194,\n",
       "  195,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  202,\n",
       "  203,\n",
       "  204,\n",
       "  205,\n",
       "  206,\n",
       "  207,\n",
       "  208,\n",
       "  209,\n",
       "  210,\n",
       "  211,\n",
       "  212,\n",
       "  213,\n",
       "  214,\n",
       "  215,\n",
       "  216,\n",
       "  217,\n",
       "  218,\n",
       "  219,\n",
       "  220,\n",
       "  221,\n",
       "  222,\n",
       "  223,\n",
       "  224,\n",
       "  225,\n",
       "  226,\n",
       "  227,\n",
       "  228,\n",
       "  229,\n",
       "  230,\n",
       "  231,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  247,\n",
       "  248,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  255,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  261,\n",
       "  262,\n",
       "  263,\n",
       "  264,\n",
       "  265,\n",
       "  266,\n",
       "  267,\n",
       "  268,\n",
       "  269,\n",
       "  270,\n",
       "  271,\n",
       "  272,\n",
       "  273,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  279,\n",
       "  280,\n",
       "  281,\n",
       "  282,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  286,\n",
       "  287,\n",
       "  288,\n",
       "  289,\n",
       "  290,\n",
       "  291,\n",
       "  292,\n",
       "  293,\n",
       "  294,\n",
       "  295,\n",
       "  296,\n",
       "  297,\n",
       "  298,\n",
       "  299,\n",
       "  300,\n",
       "  301,\n",
       "  302,\n",
       "  303,\n",
       "  304,\n",
       "  305,\n",
       "  306,\n",
       "  307,\n",
       "  308,\n",
       "  309,\n",
       "  310,\n",
       "  311,\n",
       "  312,\n",
       "  313,\n",
       "  314,\n",
       "  315,\n",
       "  316,\n",
       "  317,\n",
       "  318,\n",
       "  319,\n",
       "  320,\n",
       "  321,\n",
       "  322,\n",
       "  323,\n",
       "  324,\n",
       "  325,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  329,\n",
       "  330,\n",
       "  331,\n",
       "  332,\n",
       "  333,\n",
       "  334,\n",
       "  335,\n",
       "  336,\n",
       "  337,\n",
       "  338,\n",
       "  339,\n",
       "  340,\n",
       "  341,\n",
       "  342,\n",
       "  343,\n",
       "  344,\n",
       "  345,\n",
       "  346,\n",
       "  347,\n",
       "  348,\n",
       "  349,\n",
       "  350,\n",
       "  351,\n",
       "  352,\n",
       "  353,\n",
       "  354,\n",
       "  355,\n",
       "  356,\n",
       "  357,\n",
       "  358,\n",
       "  359,\n",
       "  360,\n",
       "  361,\n",
       "  362,\n",
       "  363,\n",
       "  364,\n",
       "  365,\n",
       "  366,\n",
       "  367,\n",
       "  368,\n",
       "  369,\n",
       "  370,\n",
       "  371,\n",
       "  372,\n",
       "  373,\n",
       "  374,\n",
       "  375,\n",
       "  376,\n",
       "  377,\n",
       "  378,\n",
       "  379,\n",
       "  380,\n",
       "  381,\n",
       "  382,\n",
       "  383,\n",
       "  384,\n",
       "  385,\n",
       "  386,\n",
       "  387,\n",
       "  388,\n",
       "  389,\n",
       "  390,\n",
       "  391,\n",
       "  392,\n",
       "  393,\n",
       "  394,\n",
       "  395,\n",
       "  396,\n",
       "  397,\n",
       "  398,\n",
       "  399,\n",
       "  400,\n",
       "  401,\n",
       "  402,\n",
       "  403,\n",
       "  404,\n",
       "  405,\n",
       "  406,\n",
       "  407,\n",
       "  408,\n",
       "  409,\n",
       "  410,\n",
       "  411,\n",
       "  412,\n",
       "  413,\n",
       "  414,\n",
       "  415,\n",
       "  416,\n",
       "  417,\n",
       "  418,\n",
       "  419,\n",
       "  420,\n",
       "  421,\n",
       "  422,\n",
       "  423,\n",
       "  424,\n",
       "  425,\n",
       "  426,\n",
       "  427,\n",
       "  428,\n",
       "  429,\n",
       "  430,\n",
       "  431,\n",
       "  432,\n",
       "  433,\n",
       "  434,\n",
       "  435,\n",
       "  436,\n",
       "  437,\n",
       "  438,\n",
       "  439,\n",
       "  440,\n",
       "  441,\n",
       "  442,\n",
       "  443,\n",
       "  444,\n",
       "  445,\n",
       "  446,\n",
       "  447,\n",
       "  448,\n",
       "  449,\n",
       "  450,\n",
       "  451,\n",
       "  452,\n",
       "  453,\n",
       "  454,\n",
       "  455,\n",
       "  456,\n",
       "  457,\n",
       "  458,\n",
       "  459,\n",
       "  460,\n",
       "  461,\n",
       "  462,\n",
       "  463,\n",
       "  464,\n",
       "  465,\n",
       "  466,\n",
       "  467,\n",
       "  468,\n",
       "  469,\n",
       "  470,\n",
       "  471,\n",
       "  472,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  476,\n",
       "  477,\n",
       "  478,\n",
       "  479,\n",
       "  480,\n",
       "  481,\n",
       "  482,\n",
       "  483,\n",
       "  484,\n",
       "  485,\n",
       "  486,\n",
       "  487,\n",
       "  488,\n",
       "  489,\n",
       "  490,\n",
       "  491,\n",
       "  492,\n",
       "  493,\n",
       "  494,\n",
       "  495,\n",
       "  496,\n",
       "  497,\n",
       "  498,\n",
       "  499,\n",
       "  500],\n",
       " 'criterion': ['gini', 'entropy', 'log_loss'],\n",
       " 'max_depth': [10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  None],\n",
       " 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       " 'max_features': ['auto', 6, 8]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = list(range(100, 501, 1))\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "max_features = ['auto', int(np.sqrt(n_features)) + 2, int(np.sqrt(n_features)) + 4]\n",
    "max_depth = list(range(10, 91, 1)) + [None]  \n",
    "min_samples_split = list(range(2, 11, 1))\n",
    "\n",
    "print(n_estimators)\n",
    "print(criteria)\n",
    "print(max_features)\n",
    "print(max_depth)\n",
    "print(min_samples_split)\n",
    "\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'criterion': criteria,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'max_features': max_features\n",
    "        }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43d9093d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "160 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.73543179        nan        nan 0.74418416 0.74260679 0.74248171\n",
      " 0.73222406        nan        nan 0.74290951 0.74418134        nan\n",
      " 0.74476205        nan 0.74216387 0.74133856        nan 0.74578955\n",
      "        nan 0.74610668        nan        nan 0.74041409 0.73850511\n",
      " 0.72781526 0.74111742 0.73935702 0.74259292 0.73955612 0.74419409\n",
      " 0.74126801 0.73739775 0.74799363 0.74566357 0.74311295 0.73976473\n",
      "        nan        nan 0.73982046        nan        nan 0.74114037\n",
      " 0.72994847 0.73243783        nan 0.74747927 0.74591838 0.74307203\n",
      " 0.73808768 0.74536738        nan        nan 0.73886489 0.74587189\n",
      " 0.74287131 0.74026187        nan        nan        nan 0.74678224\n",
      " 0.73710644 0.73317661        nan 0.74079159 0.75019935        nan\n",
      " 0.74283317        nan 0.72475447 0.73912894        nan 0.73496827\n",
      " 0.74333748 0.74352211 0.74755838 0.74471368        nan 0.73609925\n",
      " 0.74398848 0.73932146 0.74490661        nan        nan 0.7411693\n",
      " 0.74032479 0.74396099 0.74425233        nan 0.7426055  0.74493834\n",
      "        nan 0.74233645 0.73926258 0.73674692        nan 0.73864091\n",
      "        nan        nan 0.74173917 0.73679422]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.643169</td>\n",
       "      <td>0.083596</td>\n",
       "      <td>0.047879</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>203</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>41</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 203, 'min_samples_split': 6, ...</td>\n",
       "      <td>0.740743</td>\n",
       "      <td>0.758833</td>\n",
       "      <td>0.769997</td>\n",
       "      <td>0.749255</td>\n",
       "      <td>0.732169</td>\n",
       "      <td>0.750199</td>\n",
       "      <td>0.013281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.324336</td>\n",
       "      <td>0.089802</td>\n",
       "      <td>0.082692</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>487</td>\n",
       "      <td>9</td>\n",
       "      <td>auto</td>\n",
       "      <td>57</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 487, 'min_samples_split': 9, ...</td>\n",
       "      <td>0.727106</td>\n",
       "      <td>0.761588</td>\n",
       "      <td>0.768584</td>\n",
       "      <td>0.756705</td>\n",
       "      <td>0.725985</td>\n",
       "      <td>0.747994</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.170138</td>\n",
       "      <td>0.138445</td>\n",
       "      <td>0.060644</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>359</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 359, 'min_samples_split': 8, ...</td>\n",
       "      <td>0.735726</td>\n",
       "      <td>0.751555</td>\n",
       "      <td>0.773106</td>\n",
       "      <td>0.748687</td>\n",
       "      <td>0.728717</td>\n",
       "      <td>0.747558</td>\n",
       "      <td>0.015264</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.233260</td>\n",
       "      <td>0.123606</td>\n",
       "      <td>0.074709</td>\n",
       "      <td>0.006669</td>\n",
       "      <td>371</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 371, 'min_samples_split': 8, ...</td>\n",
       "      <td>0.732052</td>\n",
       "      <td>0.743499</td>\n",
       "      <td>0.768443</td>\n",
       "      <td>0.751384</td>\n",
       "      <td>0.742019</td>\n",
       "      <td>0.747479</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.575093</td>\n",
       "      <td>0.104205</td>\n",
       "      <td>0.098354</td>\n",
       "      <td>0.039169</td>\n",
       "      <td>484</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 484, 'min_samples_split': 10,...</td>\n",
       "      <td>0.737210</td>\n",
       "      <td>0.751979</td>\n",
       "      <td>0.775791</td>\n",
       "      <td>0.742515</td>\n",
       "      <td>0.726416</td>\n",
       "      <td>0.746782</td>\n",
       "      <td>0.016692</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.972120</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>0.056256</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>319</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 319, 'min_samples_split': 9, ...</td>\n",
       "      <td>0.730709</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.774166</td>\n",
       "      <td>0.749539</td>\n",
       "      <td>0.729652</td>\n",
       "      <td>0.746107</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.079053</td>\n",
       "      <td>0.056185</td>\n",
       "      <td>0.061144</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>350</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 350, 'min_samples_split': 7, ...</td>\n",
       "      <td>0.741238</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.769715</td>\n",
       "      <td>0.748191</td>\n",
       "      <td>0.724547</td>\n",
       "      <td>0.745918</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.154862</td>\n",
       "      <td>0.062361</td>\n",
       "      <td>0.072617</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>411</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>60</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 411, 'min_samples_split': 7, ...</td>\n",
       "      <td>0.724421</td>\n",
       "      <td>0.758055</td>\n",
       "      <td>0.768584</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.726632</td>\n",
       "      <td>0.745872</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.422526</td>\n",
       "      <td>0.046536</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>16</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 160, 'min_samples_split': 10,...</td>\n",
       "      <td>0.719262</td>\n",
       "      <td>0.745336</td>\n",
       "      <td>0.775933</td>\n",
       "      <td>0.737122</td>\n",
       "      <td>0.751294</td>\n",
       "      <td>0.745790</td>\n",
       "      <td>0.018536</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.791796</td>\n",
       "      <td>0.090166</td>\n",
       "      <td>0.053163</td>\n",
       "      <td>0.017160</td>\n",
       "      <td>231</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 231, 'min_samples_split': 6, ...</td>\n",
       "      <td>0.728166</td>\n",
       "      <td>0.752968</td>\n",
       "      <td>0.764980</td>\n",
       "      <td>0.744643</td>\n",
       "      <td>0.737561</td>\n",
       "      <td>0.745664</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "64       0.643169      0.083596         0.047879        0.009455   \n",
       "32       1.324336      0.089802         0.082692        0.002238   \n",
       "74       1.170138      0.138445         0.060644        0.002240   \n",
       "45       1.233260      0.123606         0.074709        0.006669   \n",
       "59       1.575093      0.104205         0.098354        0.039169   \n",
       "19       0.972120      0.068803         0.056256        0.002028   \n",
       "46       1.079053      0.056185         0.061144        0.003321   \n",
       "53       1.154862      0.062361         0.072617        0.005999   \n",
       "17       0.422526      0.046536         0.035905        0.009313   \n",
       "33       0.791796      0.090166         0.053163        0.017160   \n",
       "\n",
       "   param_n_estimators param_min_samples_split param_max_features  \\\n",
       "64                203                       6               auto   \n",
       "32                487                       9               auto   \n",
       "74                359                       8                  6   \n",
       "45                371                       8                  6   \n",
       "59                484                      10                  6   \n",
       "19                319                       9                  6   \n",
       "46                350                       7                  6   \n",
       "53                411                       7               auto   \n",
       "17                160                      10               auto   \n",
       "33                231                       6                  6   \n",
       "\n",
       "   param_max_depth param_criterion  \\\n",
       "64              41         entropy   \n",
       "32              57         entropy   \n",
       "74              72         entropy   \n",
       "45              34         entropy   \n",
       "59              67         entropy   \n",
       "19              46         entropy   \n",
       "46              88         entropy   \n",
       "53              60         entropy   \n",
       "17              16            gini   \n",
       "33              44         entropy   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "64  {'n_estimators': 203, 'min_samples_split': 6, ...           0.740743   \n",
       "32  {'n_estimators': 487, 'min_samples_split': 9, ...           0.727106   \n",
       "74  {'n_estimators': 359, 'min_samples_split': 8, ...           0.735726   \n",
       "45  {'n_estimators': 371, 'min_samples_split': 8, ...           0.732052   \n",
       "59  {'n_estimators': 484, 'min_samples_split': 10,...           0.737210   \n",
       "19  {'n_estimators': 319, 'min_samples_split': 9, ...           0.730709   \n",
       "46  {'n_estimators': 350, 'min_samples_split': 7, ...           0.741238   \n",
       "53  {'n_estimators': 411, 'min_samples_split': 7, ...           0.724421   \n",
       "17  {'n_estimators': 160, 'min_samples_split': 10,...           0.719262   \n",
       "33  {'n_estimators': 231, 'min_samples_split': 6, ...           0.728166   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "64           0.758833           0.769997           0.749255   \n",
       "32           0.761588           0.768584           0.756705   \n",
       "74           0.751555           0.773106           0.748687   \n",
       "45           0.743499           0.768443           0.751384   \n",
       "59           0.751979           0.775791           0.742515   \n",
       "19           0.746467           0.774166           0.749539   \n",
       "46           0.745902           0.769715           0.748191   \n",
       "53           0.758055           0.768584           0.751667   \n",
       "17           0.745336           0.775933           0.737122   \n",
       "33           0.752968           0.764980           0.744643   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "64           0.732169         0.750199        0.013281                1  \n",
       "32           0.725985         0.747994        0.017918                2  \n",
       "74           0.728717         0.747558        0.015264                3  \n",
       "45           0.742019         0.747479        0.012152                4  \n",
       "59           0.726416         0.746782        0.016692                5  \n",
       "19           0.729652         0.746107        0.016168                6  \n",
       "46           0.724547         0.745918        0.014492                7  \n",
       "53           0.726632         0.745872        0.017483                8  \n",
       "17           0.751294         0.745790        0.018536                9  \n",
       "33           0.737561         0.745664        0.012644               10  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV with distribution of hyperparameters\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rs = RandomizedSearchCV(estimator = rf,\n",
    "                  param_distributions = grid,\n",
    "                  n_iter = 100,      \n",
    "                  scoring='roc_auc',\n",
    "                  n_jobs=-1,\n",
    "                  cv=5)\n",
    "rs_fit = rs.fit(X_train, y_train)\n",
    "pd.DataFrame(rs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]\n",
    "\n",
    "# The results are not better even thought here we give the algorithm more choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b7071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9e8a5c3",
   "metadata": {},
   "source": [
    "#### Hyperparameters search with BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed325b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianOptimization optimize over a range, for example from 1 to 100.\n",
    "# I don't know how to give it a categorical values, for example ['gini', 'entropy', 'log_loss']\n",
    "# So in this section, for categorical hyperparameters we will use the best parameters from the results in GricSearchCV\n",
    "# We will use BayesianOptimization to find optimal over the range of numerical parameters.\n",
    "# The goal is to see if we can improve the performance over GridSearchCV with fewer iterations (i.e. save time)\n",
    "# Of course, we can write a loop to do optimization over each of combinations of categorical parameters. \n",
    "# There are probably libraries that allow us to do so. \n",
    "\n",
    "# Here is the best hyperparameters from GridSearch. We will fix criterion and max_features, and try to find the best\n",
    "# values for the remaining parameters using BayesianOptimization\n",
    "# #{'criterion': 'entropy',\n",
    "# 'max_depth': 10,\n",
    "# 'max_features': 'auto',\n",
    "# 'min_samples_split': 10,\n",
    "# 'n_estimators': 250}\n",
    "\n",
    "# with fixed criterion and max_feature, the GridSearch would have to try 9x6x3 = 162 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "951fcc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to be optimized. This is roc_auc of cross-validation.\n",
    "def rf_eval(max_depth, min_samples_split, n_estimators):\n",
    "    rf = RandomForestClassifier(criterion = 'entropy',\n",
    "                                max_features = 'auto',\n",
    "                                n_jobs = -1,\n",
    "                                max_depth = int(max_depth),\n",
    "                                min_samples_split = int(min_samples_split),\n",
    "                                n_estimators = int(n_estimators))\n",
    "    k_fold = KFold(n_splits=5)\n",
    "    return np.mean(cross_val_score(rf, X_train, y_train, cv=k_fold, scoring='roc_auc', n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7f904f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529637876447101"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with the best model\n",
    "rf_eval(10, 10, 250)\n",
    "\n",
    "# performance is close, but not exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8a6ce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.7433   \u001b[0m | \u001b[0m14.39    \u001b[0m | \u001b[0m3.293    \u001b[0m | \u001b[0m189.0    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.7472   \u001b[0m | \u001b[95m33.65    \u001b[0m | \u001b[95m4.075    \u001b[0m | \u001b[95m444.5    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.7346   \u001b[0m | \u001b[0m65.3     \u001b[0m | \u001b[0m2.232    \u001b[0m | \u001b[0m108.6    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.7464   \u001b[0m | \u001b[0m19.53    \u001b[0m | \u001b[0m5.756    \u001b[0m | \u001b[0m402.4    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.7452   \u001b[0m | \u001b[0m27.94    \u001b[0m | \u001b[0m4.952    \u001b[0m | \u001b[0m490.3    \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.7481   \u001b[0m | \u001b[95m38.02    \u001b[0m | \u001b[95m6.852    \u001b[0m | \u001b[95m441.2    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.7472   \u001b[0m | \u001b[0m90.0     \u001b[0m | \u001b[0m6.874    \u001b[0m | \u001b[0m416.0    \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.7498   \u001b[0m | \u001b[95m89.67    \u001b[0m | \u001b[95m9.026    \u001b[0m | \u001b[95m480.9    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.7453   \u001b[0m | \u001b[0m88.38    \u001b[0m | \u001b[0m8.015    \u001b[0m | \u001b[0m295.3    \u001b[0m |\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m0.7514   \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m299.8    \u001b[0m |\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m0.752    \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m260.8    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.7431   \u001b[0m | \u001b[0m40.07    \u001b[0m | \u001b[0m2.245    \u001b[0m | \u001b[0m265.1    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.7471   \u001b[0m | \u001b[0m11.86    \u001b[0m | \u001b[0m7.273    \u001b[0m | \u001b[0m332.2    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.7516   \u001b[0m | \u001b[0m10.5     \u001b[0m | \u001b[0m9.051    \u001b[0m | \u001b[0m261.1    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.7494   \u001b[0m | \u001b[0m10.95    \u001b[0m | \u001b[0m7.906    \u001b[0m | \u001b[0m238.8    \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# Use BayesianOptimization to find the best hyperparameters\n",
    "rfBO = BayesianOptimization(rf_eval, {'max_depth': (10, 90),\n",
    "                                      'min_samples_split': (2, 10),\n",
    "                                      'n_estimators': (100, 500)\n",
    "                                     })\n",
    "\n",
    "rfBO.maximize(n_iter=10, init_points=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our best parameters from GridSearchCV\n",
    "# 'max_depth': 10,\n",
    "# 'min_samples_split': 10,\n",
    "# 'n_estimators': 250}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ea447ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.7439   \u001b[0m | \u001b[0m18.91    \u001b[0m | \u001b[0m4.556    \u001b[0m | \u001b[0m325.3    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.7451   \u001b[0m | \u001b[0m69.58    \u001b[0m | \u001b[0m6.854    \u001b[0m | \u001b[0m397.6    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.744    \u001b[0m | \u001b[0m78.62    \u001b[0m | \u001b[0m5.168    \u001b[0m | \u001b[0m316.8    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.7387   \u001b[0m | \u001b[0m49.34    \u001b[0m | \u001b[0m3.38     \u001b[0m | \u001b[0m194.3    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.7448   \u001b[0m | \u001b[0m14.36    \u001b[0m | \u001b[0m2.65     \u001b[0m | \u001b[0m106.7    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.7452   \u001b[0m | \u001b[0m39.29    \u001b[0m | \u001b[0m2.53     \u001b[0m | \u001b[0m346.1    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.7463   \u001b[0m | \u001b[0m22.07    \u001b[0m | \u001b[0m2.78     \u001b[0m | \u001b[0m351.7    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.741    \u001b[0m | \u001b[0m24.48    \u001b[0m | \u001b[0m5.241    \u001b[0m | \u001b[0m235.1    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.7479   \u001b[0m | \u001b[0m84.77    \u001b[0m | \u001b[0m6.135    \u001b[0m | \u001b[0m331.2    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.7502   \u001b[0m | \u001b[0m45.04    \u001b[0m | \u001b[0m5.387    \u001b[0m | \u001b[0m268.1    \u001b[0m |\n",
      "| \u001b[95m26       \u001b[0m | \u001b[95m0.7523   \u001b[0m | \u001b[95m11.2     \u001b[0m | \u001b[95m9.838    \u001b[0m | \u001b[95m254.2    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.7505   \u001b[0m | \u001b[0m52.57    \u001b[0m | \u001b[0m8.717    \u001b[0m | \u001b[0m269.4    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.7456   \u001b[0m | \u001b[0m44.81    \u001b[0m | \u001b[0m8.741    \u001b[0m | \u001b[0m277.2    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.7486   \u001b[0m | \u001b[0m10.07    \u001b[0m | \u001b[0m2.746    \u001b[0m | \u001b[0m250.7    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.7479   \u001b[0m | \u001b[0m11.33    \u001b[0m | \u001b[0m5.14     \u001b[0m | \u001b[0m291.9    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.7515   \u001b[0m | \u001b[0m18.32    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m257.3    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.7512   \u001b[0m | \u001b[0m11.57    \u001b[0m | \u001b[0m7.11     \u001b[0m | \u001b[0m306.6    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.7452   \u001b[0m | \u001b[0m18.97    \u001b[0m | \u001b[0m2.092    \u001b[0m | \u001b[0m304.4    \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.7497   \u001b[0m | \u001b[0m52.2     \u001b[0m | \u001b[0m9.768    \u001b[0m | \u001b[0m260.1    \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.742    \u001b[0m | \u001b[0m62.87    \u001b[0m | \u001b[0m2.419    \u001b[0m | \u001b[0m267.8    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.7506   \u001b[0m | \u001b[0m17.04    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m248.9    \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.748    \u001b[0m | \u001b[0m80.5     \u001b[0m | \u001b[0m5.711    \u001b[0m | \u001b[0m473.7    \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.749    \u001b[0m | \u001b[0m82.03    \u001b[0m | \u001b[0m9.238    \u001b[0m | \u001b[0m491.2    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.7495   \u001b[0m | \u001b[0m13.85    \u001b[0m | \u001b[0m8.993    \u001b[0m | \u001b[0m271.4    \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.7456   \u001b[0m | \u001b[0m67.18    \u001b[0m | \u001b[0m6.341    \u001b[0m | \u001b[0m486.1    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.7461   \u001b[0m | \u001b[0m89.94    \u001b[0m | \u001b[0m3.314    \u001b[0m | \u001b[0m496.5    \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.7457   \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m314.2    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.7454   \u001b[0m | \u001b[0m21.52    \u001b[0m | \u001b[0m8.729    \u001b[0m | \u001b[0m266.2    \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.7504   \u001b[0m | \u001b[0m11.08    \u001b[0m | \u001b[0m9.464    \u001b[0m | \u001b[0m299.4    \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.7461   \u001b[0m | \u001b[0m89.61    \u001b[0m | \u001b[0m7.797    \u001b[0m | \u001b[0m465.2    \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "rfBO.maximize(n_iter=20, init_points=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f407f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7a3c3df",
   "metadata": {},
   "source": [
    "#### 5.2.1.3) Gradient Boosting model\n",
    "We still need to find a good guidance on what hyperparameters are the most important in tuning Gradient Boosting.\n",
    "This article https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae describes the following parameters:\n",
    "\n",
    "Boosting parameters:\n",
    "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01] - 0.1 was optimal for his dataset\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200] - 32 was optimal\n",
    "\n",
    "Tree parameters:\n",
    "max_depths = np.linspace(1, 32, 32, endpoint=True) - 4\n",
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True) - 0.9\n",
    "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True) - 0.3\n",
    "max_features = list(range(1,train.shape[1]))\n",
    "\n",
    "This article seems to be more comprehensive: https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66926c60",
   "metadata": {},
   "source": [
    "#### Explore Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5309f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_SUPPORTED_LOSS', '__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_feature_names', '_check_initialized', '_check_n_features', '_check_params', '_clear_state', '_compute_partial_dependence_recursion', '_estimator_type', '_fit_stage', '_fit_stages', '_get_param_names', '_get_tags', '_init_state', '_is_initialized', '_make_estimator', '_more_tags', '_raw_predict', '_raw_predict_init', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_resize_state', '_staged_raw_predict', '_validate_data', '_validate_estimator', '_validate_y', '_warn_mae_for_criterion', 'apply', 'decision_function', 'feature_importances_', 'fit', 'get_params', 'n_features_', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'set_params', 'staged_decision_function', 'staged_predict', 'staged_predict_proba']\n"
     ]
    }
   ],
   "source": [
    "print(dir(GradientBoostingClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd55da58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9cd14bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72590822, 0.76108871, 0.76177686, 0.72930839, 0.68780488])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore GradientBoostingClassifier through Cross-Validation. Use only X_train and y_train\n",
    "gb = GradientBoostingClassifier()\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(gb, X_train, y_train, cv=k_fold, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# AUC seems to be smaller than RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e35367d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79470199, 0.79801325, 0.8013245 , 0.82724252, 0.81395349])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at accuracy\n",
    "cross_val_score(gb, X_train, y_train, cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e510fea",
   "metadata": {},
   "source": [
    "#### Hyperparameter search using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a40861d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.05, 0.1, 0.15],\n",
       " 'n_estimators': [50, 100, 150],\n",
       " 'subsample': [0.8, 1],\n",
       " 'max_depth': [3, 6, 9, 12, 15],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto', 6, 8]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 19 # Input the number of features here. Alternatively estimate a model and get _n_features_in_ attribute\n",
    "max_features = ['auto', int(np.sqrt(n_features)) + 2, int(np.sqrt(n_features)) + 4]\n",
    "\n",
    "grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 1],\n",
    "    'max_depth': [3, 6, 9, 12, 15],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'max_features': max_features\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b824cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV here\n",
    "start = time.time()\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]\n",
    "\n",
    "end = time.time()\n",
    "tune_time = (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f3f4a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364.0726172924042"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f4a953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.127488</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.747845</td>\n",
       "      <td>0.775049</td>\n",
       "      <td>0.801583</td>\n",
       "      <td>0.757769</td>\n",
       "      <td>0.719478</td>\n",
       "      <td>0.760345</td>\n",
       "      <td>0.027385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.115812</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.745230</td>\n",
       "      <td>0.774484</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.719550</td>\n",
       "      <td>0.759773</td>\n",
       "      <td>0.027715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.141952</td>\n",
       "      <td>0.026121</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.747809</td>\n",
       "      <td>0.775120</td>\n",
       "      <td>0.798686</td>\n",
       "      <td>0.757627</td>\n",
       "      <td>0.719478</td>\n",
       "      <td>0.759744</td>\n",
       "      <td>0.026537</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.129474</td>\n",
       "      <td>0.027234</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'max_fe...</td>\n",
       "      <td>0.762578</td>\n",
       "      <td>0.762931</td>\n",
       "      <td>0.786532</td>\n",
       "      <td>0.747410</td>\n",
       "      <td>0.730515</td>\n",
       "      <td>0.757993</td>\n",
       "      <td>0.018585</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.229638</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.748339</td>\n",
       "      <td>0.777381</td>\n",
       "      <td>0.792220</td>\n",
       "      <td>0.762771</td>\n",
       "      <td>0.705062</td>\n",
       "      <td>0.757155</td>\n",
       "      <td>0.029872</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.118511</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.734737</td>\n",
       "      <td>0.767171</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>0.757592</td>\n",
       "      <td>0.723217</td>\n",
       "      <td>0.756754</td>\n",
       "      <td>0.027133</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.132378</td>\n",
       "      <td>0.017219</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.758126</td>\n",
       "      <td>0.762542</td>\n",
       "      <td>0.780314</td>\n",
       "      <td>0.757911</td>\n",
       "      <td>0.724799</td>\n",
       "      <td>0.756738</td>\n",
       "      <td>0.017961</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.130375</td>\n",
       "      <td>0.026511</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'max_fe...</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.776957</td>\n",
       "      <td>0.793527</td>\n",
       "      <td>0.760998</td>\n",
       "      <td>0.705278</td>\n",
       "      <td>0.756292</td>\n",
       "      <td>0.030241</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.082692</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.752402</td>\n",
       "      <td>0.763355</td>\n",
       "      <td>0.788440</td>\n",
       "      <td>0.765361</td>\n",
       "      <td>0.710490</td>\n",
       "      <td>0.756010</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.219161</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.751696</td>\n",
       "      <td>0.778123</td>\n",
       "      <td>0.782434</td>\n",
       "      <td>0.749290</td>\n",
       "      <td>0.716782</td>\n",
       "      <td>0.755665</td>\n",
       "      <td>0.023619</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7         0.127488      0.022066         0.003789        0.000400   \n",
       "13        0.115812      0.006984         0.003192        0.000399   \n",
       "1         0.141952      0.026121         0.008784        0.010334   \n",
       "270       0.129474      0.027234         0.003591        0.000798   \n",
       "3         0.229638      0.003972         0.003989        0.000631   \n",
       "6         0.118511      0.018911         0.003590        0.000489   \n",
       "0         0.132378      0.017219         0.004389        0.001017   \n",
       "271       0.130375      0.026511         0.003293        0.000400   \n",
       "30        0.082692      0.011523         0.003391        0.000488   \n",
       "2         0.219161      0.007777         0.003991        0.000631   \n",
       "\n",
       "    param_learning_rate param_max_depth param_max_features  \\\n",
       "7                  0.05               3               auto   \n",
       "13                 0.05               3               auto   \n",
       "1                  0.05               3               auto   \n",
       "270                 0.1               3               auto   \n",
       "3                  0.05               3               auto   \n",
       "6                  0.05               3               auto   \n",
       "0                  0.05               3               auto   \n",
       "271                 0.1               3               auto   \n",
       "30                 0.05               3                  6   \n",
       "2                  0.05               3               auto   \n",
       "\n",
       "    param_min_samples_split param_n_estimators param_subsample  \\\n",
       "7                         6                 50               1   \n",
       "13                       10                 50               1   \n",
       "1                         2                 50               1   \n",
       "270                       2                 50             0.8   \n",
       "3                         2                100               1   \n",
       "6                         6                 50             0.8   \n",
       "0                         2                 50             0.8   \n",
       "271                       2                 50               1   \n",
       "30                       10                 50             0.8   \n",
       "2                         2                100             0.8   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "7    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.747845   \n",
       "13   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.745230   \n",
       "1    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.747809   \n",
       "270  {'learning_rate': 0.1, 'max_depth': 3, 'max_fe...           0.762578   \n",
       "3    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.748339   \n",
       "6    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.734737   \n",
       "0    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.758126   \n",
       "271  {'learning_rate': 0.1, 'max_depth': 3, 'max_fe...           0.744700   \n",
       "30   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.752402   \n",
       "2    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.751696   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7             0.775049           0.801583           0.757769   \n",
       "13            0.774484           0.802077           0.757521   \n",
       "1             0.775120           0.798686           0.757627   \n",
       "270           0.762931           0.786532           0.747410   \n",
       "3             0.777381           0.792220           0.762771   \n",
       "6             0.767171           0.801053           0.757592   \n",
       "0             0.762542           0.780314           0.757911   \n",
       "271           0.776957           0.793527           0.760998   \n",
       "30            0.763355           0.788440           0.765361   \n",
       "2             0.778123           0.782434           0.749290   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7             0.719478         0.760345        0.027385                1  \n",
       "13            0.719550         0.759773        0.027715                2  \n",
       "1             0.719478         0.759744        0.026537                3  \n",
       "270           0.730515         0.757993        0.018585                4  \n",
       "3             0.705062         0.757155        0.029872                5  \n",
       "6             0.723217         0.756754        0.027133                6  \n",
       "0             0.724799         0.756738        0.017961                7  \n",
       "271           0.705278         0.756292        0.030241                8  \n",
       "30            0.710490         0.756010        0.025605                9  \n",
       "2             0.716782         0.755665        0.023619               10  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]\n",
    "# Best learning rate mostly 0.05 (8 out of top 10) => reduce further\n",
    "# Best max_depth all 3 for top 10 \n",
    "# Best max_features = auto \n",
    "# min_samples_split 6, 10, 2 (all possible values)\n",
    "# n_estimators = 50 => let reduce this further\n",
    "# subsample = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a24cc9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.02, 0.035, 0.05],\n",
       " 'n_estimators': [10, 30, 50],\n",
       " 'subsample': [1],\n",
       " 'max_depth': [3],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto']}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to reduce learning_rate and n_estimator\n",
    "\n",
    "grid = {\n",
    "    'learning_rate': [0.02, 0.035, 0.05],\n",
    "    'n_estimators': [10, 30, 50],\n",
    "    'subsample': [1],\n",
    "    'max_depth': [3],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'max_features': ['auto']\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f79e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.830493688583374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.164391</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>2.985345e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.750742</td>\n",
       "      <td>0.775049</td>\n",
       "      <td>0.801583</td>\n",
       "      <td>0.757627</td>\n",
       "      <td>0.719478</td>\n",
       "      <td>0.760896</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.186234</td>\n",
       "      <td>0.024029</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>3.590987e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.749399</td>\n",
       "      <td>0.774484</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.757521</td>\n",
       "      <td>0.719550</td>\n",
       "      <td>0.760606</td>\n",
       "      <td>0.027325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.113124</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>7.462510e-04</td>\n",
       "      <td>0.035</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.035, 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.751166</td>\n",
       "      <td>0.773495</td>\n",
       "      <td>0.800099</td>\n",
       "      <td>0.756918</td>\n",
       "      <td>0.721024</td>\n",
       "      <td>0.760540</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.113016</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>3.988033e-04</td>\n",
       "      <td>0.035</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.035, 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.750071</td>\n",
       "      <td>0.773566</td>\n",
       "      <td>0.800099</td>\n",
       "      <td>0.756492</td>\n",
       "      <td>0.721024</td>\n",
       "      <td>0.760250</td>\n",
       "      <td>0.026160</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.117114</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>3.993036e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.747527</td>\n",
       "      <td>0.774837</td>\n",
       "      <td>0.798686</td>\n",
       "      <td>0.757379</td>\n",
       "      <td>0.719478</td>\n",
       "      <td>0.759581</td>\n",
       "      <td>0.026534</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.116608</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>5.436780e-07</td>\n",
       "      <td>0.035</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.035, 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.746008</td>\n",
       "      <td>0.773495</td>\n",
       "      <td>0.800028</td>\n",
       "      <td>0.756918</td>\n",
       "      <td>0.721240</td>\n",
       "      <td>0.759538</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.068632</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>7.975221e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.744877</td>\n",
       "      <td>0.775120</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.752377</td>\n",
       "      <td>0.720700</td>\n",
       "      <td>0.758444</td>\n",
       "      <td>0.026759</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.069628</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>3.991130e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.740284</td>\n",
       "      <td>0.775049</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.752235</td>\n",
       "      <td>0.720700</td>\n",
       "      <td>0.757483</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.092269</td>\n",
       "      <td>0.028474</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>3.645332e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.738341</td>\n",
       "      <td>0.775049</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.751951</td>\n",
       "      <td>0.720700</td>\n",
       "      <td>0.757037</td>\n",
       "      <td>0.027544</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>3.977902e-04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.738977</td>\n",
       "      <td>0.776569</td>\n",
       "      <td>0.797131</td>\n",
       "      <td>0.752341</td>\n",
       "      <td>0.716171</td>\n",
       "      <td>0.756238</td>\n",
       "      <td>0.028299</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "23       0.164391      0.049898         0.005186    2.985345e-03   \n",
       "26       0.186234      0.024029         0.007780    3.590987e-03   \n",
       "14       0.113124      0.002833         0.003790    7.462510e-04   \n",
       "17       0.113016      0.001716         0.003790    3.988033e-04   \n",
       "20       0.117114      0.007398         0.003192    3.993036e-04   \n",
       "11       0.116608      0.004259         0.003989    5.436780e-07   \n",
       "19       0.068632      0.002123         0.003591    7.975221e-04   \n",
       "22       0.069628      0.003672         0.003191    3.991130e-04   \n",
       "25       0.092269      0.028474         0.007181    3.645332e-03   \n",
       "2        0.120300      0.008045         0.003693    3.977902e-04   \n",
       "\n",
       "   param_learning_rate param_max_depth param_max_features  \\\n",
       "23                0.05               3               auto   \n",
       "26                0.05               3               auto   \n",
       "14               0.035               3               auto   \n",
       "17               0.035               3               auto   \n",
       "20                0.05               3               auto   \n",
       "11               0.035               3               auto   \n",
       "19                0.05               3               auto   \n",
       "22                0.05               3               auto   \n",
       "25                0.05               3               auto   \n",
       "2                 0.02               3               auto   \n",
       "\n",
       "   param_min_samples_split param_n_estimators param_subsample  \\\n",
       "23                       6                 50               1   \n",
       "26                      10                 50               1   \n",
       "14                       6                 50               1   \n",
       "17                      10                 50               1   \n",
       "20                       2                 50               1   \n",
       "11                       2                 50               1   \n",
       "19                       2                 30               1   \n",
       "22                       6                 30               1   \n",
       "25                      10                 30               1   \n",
       "2                        2                 50               1   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "23  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.750742   \n",
       "26  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.749399   \n",
       "14  {'learning_rate': 0.035, 'max_depth': 3, 'max_...           0.751166   \n",
       "17  {'learning_rate': 0.035, 'max_depth': 3, 'max_...           0.750071   \n",
       "20  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.747527   \n",
       "11  {'learning_rate': 0.035, 'max_depth': 3, 'max_...           0.746008   \n",
       "19  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.744877   \n",
       "22  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.740284   \n",
       "25  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.738341   \n",
       "2   {'learning_rate': 0.02, 'max_depth': 3, 'max_f...           0.738977   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "23           0.775049           0.801583           0.757627   \n",
       "26           0.774484           0.802077           0.757521   \n",
       "14           0.773495           0.800099           0.756918   \n",
       "17           0.773566           0.800099           0.756492   \n",
       "20           0.774837           0.798686           0.757379   \n",
       "11           0.773495           0.800028           0.756918   \n",
       "19           0.775120           0.799145           0.752377   \n",
       "22           0.775049           0.799145           0.752235   \n",
       "25           0.775049           0.799145           0.751951   \n",
       "2            0.776569           0.797131           0.752341   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "23           0.719478         0.760896        0.027148                1  \n",
       "26           0.719550         0.760606        0.027325                2  \n",
       "14           0.721024         0.760540        0.026059                3  \n",
       "17           0.721024         0.760250        0.026160                4  \n",
       "20           0.719478         0.759581        0.026534                5  \n",
       "11           0.721240         0.759538        0.026423                6  \n",
       "19           0.720700         0.758444        0.026759                7  \n",
       "22           0.720700         0.757483        0.027279                8  \n",
       "25           0.720700         0.757037        0.027544                9  \n",
       "2            0.716171         0.756238        0.028299               10  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV with reduced values for learning rate and n_estimators\n",
    "start = time.time()\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "tune_time = (end - start)\n",
    "print(tune_time)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]\n",
    "\n",
    "# Interesting (lucky) the best parameters remain the same. learning_rate=0.05, n_estimators=50 seem to be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "79365777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21c4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db285a4d",
   "metadata": {},
   "source": [
    "#### 5.2.1.4) Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7bf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a9058be",
   "metadata": {},
   "source": [
    "### 5.2.2) Modeling with Age as categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252a985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836fc38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1a6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279687c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cc166b4",
   "metadata": {},
   "source": [
    "### 5.2.3) Optimal threshold and final model perfomance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bba603",
   "metadata": {},
   "source": [
    "#### 5.2.3.1 Choosing optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf5516",
   "metadata": {},
   "source": [
    "The below was wrong. Need to redo splititng train set to 70-30 and determine the optimal threshold\n",
    "The below was wrong. Need to redo splititng train set to 70-30 and determine the optimal threshold\n",
    "The below was wrong. Need to redo splititng train set to 70-30 and determine the optimal threshold\n",
    "The below was wrong. Need to redo splititng train set to 70-30 and determine the optimal threshold\n",
    "The below was wrong. Need to redo splititng train set to 70-30 and determine the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633d602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d41124be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.05, max_depth=3, max_features='auto', min_samples_split=6,\n",
    "                                n_estimators=50, subsample=1)\n",
    "gb_fit = gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d1733a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.22252023429168744, 'Age_value'),\n",
       " (0.15943717851155256, 'SS'),\n",
       " (0.1427625163850986, 'USA'),\n",
       " (0.10326515315859808, 'Male'),\n",
       " (0.08778675946957659, 'UK'),\n",
       " (0.08631467943869432, 'Cscore'),\n",
       " (0.0694381418695978, 'Oscore'),\n",
       " (0.04372869546569823, 'Ascore'),\n",
       " (0.023376029466515107, 'Nscore'),\n",
       " (0.01903346948549887, 'Impulsive'),\n",
       " (0.0178723383325867, 'Escore'),\n",
       " (0.015351466704207813, 'Republic of Ireland'),\n",
       " (0.004620986710157502, 'Edu_gr4'),\n",
       " (0.002993127406126623, 'Edu_gr2'),\n",
       " (0.0014992233044036991, 'New Zealand'),\n",
       " (0.0, 'Other'),\n",
       " (0.0, 'Edu_gr5'),\n",
       " (0.0, 'Edu_gr3'),\n",
       " (0.0, 'Canada')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output feature importance\n",
    "sorted(zip(gb_fit.feature_importances_, X_train.columns), reverse=True)\n",
    "# Interesting, different from RF, for GB most important features are demographic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "896cda50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_fit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7760559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n",
      "[[0.85205945 0.14794055]\n",
      " [0.87298777 0.12701223]\n",
      " [0.62279203 0.37720797]\n",
      " [0.94623221 0.05376779]\n",
      " [0.83654968 0.16345032]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on X_test\n",
    "y_pred = gb_fit.predict(X_test)\n",
    "y_pred_probs = gb_fit.predict_proba(X_test)\n",
    "print(y_pred[:5])\n",
    "print(y_pred_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "58444509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.222 / Recall: 0.025 / Accuracy: 0.772\n"
     ]
    }
   ],
   "source": [
    "# Output some TEST performance \n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label=1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                        round(recall, 3),\n",
    "                                                        round((y_pred==y_test).sum() / len(y_pred),3)))\n",
    "# Performance is bad in term of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6644ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.767 / Recall: 0.114 / Accuracy: 0.824\n"
     ]
    }
   ],
   "source": [
    "# Predict on X_train and output TRAIN performance\n",
    "y_pred_train = gb_fit.predict(X_train)\n",
    "precision_train, recall_train, fscore_train, support_train = score(y_train, y_pred_train, pos_label=1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision_train, 3),\n",
    "                                                        round(recall_train, 3),\n",
    "                                                        round((y_pred_train==y_train).sum() / len(y_pred_train),3)))\n",
    "\n",
    "# OK, still might be the evidence of overfitting after GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab956eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.712\n"
     ]
    }
   ],
   "source": [
    "# Output roc_auc\n",
    "print('roc_auc: {}'.format(round(roc_auc_score(y_test, y_pred_probs[:, 1]), 3)))\n",
    "\n",
    "# Interesing roc_auc here is smaller than cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4723f17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs[:, 1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9bfe90a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Precision-Recall (PC) curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs[:, 1])\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b296ef0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Precision-Recall (PC) curve without the last pair\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs[:, 1])\n",
    "plt.plot(recall[:313], precision[:313])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "762bbbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x240ee095550>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot precision and recall as function of thresholds \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thresholds, precision[:313], label='Precision')\n",
    "ax.plot(thresholds, recall[:313], label='Recall')\n",
    "ax.set_xlabel('Thresholds')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bb9aa048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Other way to draw Precision-Recall curve\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    gb_fit, X_test, y_test, name=\"GradientBoosting\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "50b00783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRpklEQVR4nO3deVxU5f4H8M8wMKwC4oKgCBRuuEWSBVxzySAxl26aCyWmVuY1F1KvprnlUrmhJmJpmuVCrmWR200Rl0xQsgJNBQQRrrmBLLIMz+8PL/NjYAZmhoGB4+f9es3rJc85Z+Y7R2A+PM9zniMTQggQERERSYSZqQsgIiIiMiaGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhRzUxdQ10pLS3Hz5k00atQIMpnM1OUQERGRDoQQePDgAVxdXWFmVnXfzGMXbm7evAk3NzdTl0FEREQGSE9PR6tWrarc57ELN40aNQLw6OTY29ubuBoiIiLSRU5ODtzc3FSf41V57MJN2VCUvb09ww0REVEDo8uUEk4oJiIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIkkxabg5ceIEBgwYAFdXV8hkMuzfv7/aY2JiYtCtWzdYWVnhiSeeQGRkZO0XSkRERA2GScNNXl4eunbtis8++0yn/VNSUhAcHIwePXrgwoUL+OCDDzBp0iTs2bOnlislIiKihsKkN87s168f+vXrp/P+kZGRaN26NcLDwwEAHTp0QFxcHJYvX45XX321lqrUjRACBcVKAIC1hVynG3sRERGR8TWoOTdnzpxBYGCgWltQUBDi4uJQXFys8ZjCwkLk5OSoPWpDQbES3nMPwXvuIVXIISIiorrXoMJNVlYWnJ2d1dqcnZ1RUlKC27dvazxm6dKlcHBwUD3c3NzqolQiIiIykQYVbgBUGu4RQmhsLzNr1ixkZ2erHunp6bVeIxEREZmOSefc6KtFixbIyspSa7t16xbMzc3RpEkTjcdYWlrC0tKyLsojIiKieqBB9dz4+fnhyJEjam2HDx+Gr68vLCwsTFQVERER1ScmDTe5ublISEhAQkICgEeXeickJCAtLQ3AoyGlUaNGqfYfP348rl+/jrCwMCQlJeHLL7/Epk2bMG3aNFOUT0RERPWQSYel4uLi0Lt3b9XXYWFhAIDQ0FBs2bIFmZmZqqADAJ6enoiOjsbUqVOxbt06uLq6Ys2aNSa/DJyIiIjqD5OGm169eqkmBGuyZcuWSm09e/bE+fPna7EqIiIiasga1JwbIiIiouow3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpJg83ERERMDT0xNWVlbo1q0bYmNjq9x/27Zt6Nq1K2xsbODi4oI333wTd+7cqaNqiYiIqL4zabiJiorClClTMHv2bFy4cAE9evRAv379kJaWpnH/kydPYtSoURg7diz+/PNP7Nq1C+fOncO4cePquHIiIiKqr0wablauXImxY8di3Lhx6NChA8LDw+Hm5ob169dr3P+XX36Bh4cHJk2aBE9PT/zjH//AO++8g7i4OK2vUVhYiJycHLUHERERSZfJwk1RURHi4+MRGBio1h4YGIjTp09rPMbf3x83btxAdHQ0hBD473//i927d6N///5aX2fp0qVwcHBQPdzc3Iz6PoiIiKh+MVm4uX37NpRKJZydndXanZ2dkZWVpfEYf39/bNu2DcOGDYNCoUCLFi3g6OiItWvXan2dWbNmITs7W/VIT0836vsgIiKi+sXkE4plMpna10KISm1lEhMTMWnSJMydOxfx8fE4ePAgUlJSMH78eK3Pb2lpCXt7e7UHERERSZe5qV64adOmkMvllXppbt26Vak3p8zSpUsREBCA6dOnAwC6dOkCW1tb9OjRA4sWLYKLi0ut101ERET1m8l6bhQKBbp164YjR46otR85cgT+/v4aj8nPz4eZmXrJcrkcwKMeHyIiIiKTDkuFhYVh48aN+PLLL5GUlISpU6ciLS1NNcw0a9YsjBo1SrX/gAEDsHfvXqxfvx7Jyck4deoUJk2ahO7du8PV1dVUb4OIiIjqEZMNSwHAsGHDcOfOHSxcuBCZmZno1KkToqOj4e7uDgDIzMxUW/Nm9OjRePDgAT777DO8//77cHR0RJ8+ffDJJ5+Y6i0QERFRPSMTj9l4Tk5ODhwcHJCdnW3UycX5RSXwnnsIAJC4MAg2CpPmRiIiIknR5/Pb5FdLERERERkTww0RERFJit5jJ0IIxMTEIDY2FqmpqcjPz0ezZs3g4+ODvn37cgVgIiIiMimde24KCgqwZMkSuLm5oV+/fvjxxx9x//59yOVyXL16FfPmzYOnpyeCg4Pxyy+/1GbNRERERFrp3HPTtm1bPPvss4iMjERQUBAsLCwq7XP9+nVs374dw4YNw5w5c/DWW28ZtVgiIiKi6ugcbn766Sd06tSpyn3c3d0xa9YsvP/++7h+/XqNiyMiIiLSl87DUtUFm/IUCgXatGljUEFERERENWHUq6Xy8vJw4sQJYz4lERERkV6MGm6uXr2K3r17G/MpiYiIiPTCdW6IiIhIUvRa58bJyanK7UqlskbFEBEREdWUXuGmsLAQ7777Ljp37qxx+/Xr17FgwQKjFEZERERkCL3CzVNPPQU3NzeEhoZq3P7bb78x3BAREZFJ6TXnpn///rh//77W7U5OThg1alRNayIiIiIymF49Nx988EGV293c3LB58+YaFURERERUE7xaioiIiCSF4YaIiIgkheGGiIiIJIXhhoiIiCSF4YaIiIgkheGGiIiIJMXgcDNmzBjMnj1bre2DDz7AmDFjalwUERERkaH0WuemvJSUFJSWlqq1ZWRkID09vcZFERERERnK4HBz7NixSm1fffVVjYohIiIiqinOuSEiIiJJ0bnn5vvvv9f5SQcOHGhQMUREREQ1pXO4GTx4sE77yWQyKJVKQ+shIiIiqhGdw03FycNERERE9VGN59w8fPjQGHUQERERGYVB4UapVOKjjz5Cy5YtYWdnh+TkZADAhx9+iE2bNhm1QCIiIiJ9GBRuFi9ejC1btuDTTz+FQqFQtXfu3BkbN240WnFERERE+jIo3GzduhWff/45QkJCIJfLVe1dunTBpUuXjFYcERERkb4MCjcZGRnw8vKq1F5aWori4uIaF0VERERkKIPCTceOHREbG1upfdeuXfDx8alxUURERESGMuj2C/PmzcMbb7yBjIwMlJaWYu/evbh8+TK2bt2KH374wdg1EhEREenMoJ6bAQMGICoqCtHR0ZDJZJg7dy6SkpJw4MABvPjii8aukYiIiEhnBt84MygoCEFBQcashYiIiKjGDA43ABAXF4ekpCTIZDJ06NAB3bp1M1ZdRERERAYxKNzcuHEDI0aMwKlTp+Do6AgAuH//Pvz9/bFjxw64ubkZs0YiIiIinRk052bMmDEoLi5GUlIS7t69i7t37yIpKQlCCIwdO9bYNRIRERHpzKCem9jYWJw+fRrt2rVTtbVr1w5r165FQECA0YojIiIi0pdBPTetW7fWuFhfSUkJWrZsWeOiiIiIiAxlULj59NNP8d577yEuLg5CCACPJhdPnjwZy5cvN2qBRERERPrQeViqcePGkMlkqq/z8vLw7LPPwtz80VOUlJTA3NwcY8aMweDBg41eKBEREZEudA434eHhtVgGERERkXHoHG5CQ0Nrsw4iIiIio6jRIn4AUFBQUGlysb29fU2floiIiMggBk0ozsvLw8SJE9G8eXPY2dmhcePGag8iIiIiUzEo3MyYMQM///wzIiIiYGlpiY0bN2LBggVwdXXF1q1bjV0jERERkc4MGpY6cOAAtm7dil69emHMmDHo0aMHvLy84O7ujm3btiEkJMTYdRIRERHpxKCem7t378LT0xPAo/k1d+/eBQD84x//wIkTJ4xXHREREZGeDAo3TzzxBFJTUwEA3t7e+PbbbwE86tEpu5EmERERkSkYFG7efPNN/PbbbwCAWbNmqebeTJ06FdOnTzdqgURERET6MGjOzdSpU1X/7t27Ny5duoS4uDg8+eST6Nq1q9GKIyIiItJXjde5AR7dSLN169bGeCoiIiKiGtE53KxZs0bnJ500aZJBxRARERHVlM7hZtWqVTrtJ5PJ9Ao3ERERWLZsGTIzM9GxY0eEh4ejR48eWvcvLCzEwoUL8c033yArKwutWrXC7NmzMWbMGJ1fk4iIiKRL53CTkpJi9BePiorClClTEBERgYCAAGzYsAH9+vVDYmKi1mGu1157Df/973+xadMmeHl54datWygpKTF6bURERNQwGWXOjaFWrlyJsWPHYty4cQAe3Xn80KFDWL9+PZYuXVpp/4MHDyImJgbJyclwcnICAHh4eFT5GoWFhSgsLFR9nZOTY7w3QERERPWOQZeCG0NRURHi4+MRGBio1h4YGIjTp09rPOb777+Hr68vPv30U7Rs2RJt27bFtGnTUFBQoPV1li5dCgcHB9XDzc3NqO+DiIiI6heT9dzcvn0bSqUSzs7Oau3Ozs7IysrSeExycjJOnjwJKysr7Nu3D7dv38aECRNw9+5dfPnllxqPmTVrFsLCwlRf5+TkMOAQERFJmEmHpYBHE5DLE0JUaitTWloKmUyGbdu2wcHBAcCjoa0hQ4Zg3bp1sLa2rnSMpaUlLC0tjV84ERER1UsmG5Zq2rQp5HJ5pV6aW7duVerNKePi4oKWLVuqgg0AdOjQAUII3Lhxo1brJSIioobB4HATGxuL119/HX5+fsjIyAAAfP311zh58qROxysUCnTr1g1HjhxRaz9y5Aj8/f01HhMQEICbN28iNzdX1fbXX3/BzMwMrVq1MvCdEBERkZQYFG727NmDoKAgWFtb48KFC6qrkR48eIAlS5bo/DxhYWHYuHEjvvzySyQlJWHq1KlIS0vD+PHjATyaLzNq1CjV/iNHjkSTJk3w5ptvIjExESdOnMD06dMxZswYjUNSRERE9PgxKNwsWrQIkZGR+OKLL2BhYaFq9/f3x/nz53V+nmHDhiE8PBwLFy7EU089hRMnTiA6Ohru7u4AgMzMTKSlpan2t7Ozw5EjR3D//n34+voiJCQEAwYM0Gv1ZCIiIpI2gyYUX758Gc8//3yldnt7e9y/f1+v55owYQImTJigcduWLVsqtbVv377SUBYRERFRGYN6blxcXHD16tVK7SdPnsQTTzxR46KIiIiIDGVQuHnnnXcwefJknD17FjKZDDdv3sS2bdswbdo0rb0wRERERHXBoGGpGTNmIDs7G71798bDhw/x/PPPw9LSEtOmTcPEiRONXSMRERGRzgxexG/x4sWYPXs2EhMTUVpaCm9vb9jZ2RmzNiIiIiK9GTQs9dVXXyEvLw82Njbw9fVF9+7dGWyIiIioXjAo3EybNg3NmzfH8OHD8cMPP6CkpMTYdREREREZxKBwk5mZiaioKMjlcgwfPhwuLi6YMGGC1rt5ExEREdUVg8KNubk5Xn75ZWzbtg23bt1CeHg4rl+/jt69e+PJJ580do1EREREOqvxXcFtbGwQFBSEe/fu4fr160hKSjJGXUREREQGMfjGmfn5+di2bRuCg4Ph6uqKVatWYfDgwfjjjz+MWR8RERGRXgzquRkxYgQOHDgAGxsbDB06FMePH9d6J28iIiKiumRQuJHJZIiKikJQUBDMzWs8skVERERkNAYlk+3btxu7DiIiIiKj0DncrFmzBm+//TasrKywZs2aKvedNGlSjQsjIiIiMoTO4WbVqlUICQmBlZUVVq1apXU/mUzGcENEREQmo3O4SUlJ0fhvIiIiovrEoEvBFy5ciPz8/ErtBQUFWLhwYY2LIiIiIjKUQeFmwYIFyM3NrdSen5+PBQsW1LgoIiIiIkMZFG6EEJDJZJXaf/vtNzg5OdW4KCIiIiJD6XUpeOPGjSGTySCTydC2bVu1gKNUKpGbm4vx48cbvUgiIiIiXekVbsLDwyGEwJgxY7BgwQI4ODiotikUCnh4eMDPz8/oRRIRERHpSq9wExoaCgDw9PSEv78/LCwsaqUoIiIiIkPpHG5ycnJgb28PAPDx8UFBQQEKCgo07lu2HxEREVFd0zncNG7cGJmZmWjevDkcHR01Tigum2isVCqNWiQRERGRrnQONz///LPqSqhjx47VWkFERERENaFzuOnZs6fGfxMRERHVJwatc3Pw4EGcPHlS9fW6devw1FNPYeTIkbh3757RiiMiIiLSl0HhZvr06cjJyQEA/P777wgLC0NwcDCSk5MRFhZm1AKJiIiI9KHXpeBlUlJS4O3tDQDYs2cPBgwYgCVLluD8+fMIDg42aoFERERE+jCo50ahUKhunHn06FEEBgYCAJycnFQ9OkRERESmYFDPzT/+8Q+EhYUhICAAv/76K6KiogAAf/31F1q1amXUAomIiIj0YVDPzWeffQZzc3Ps3r0b69evR8uWLQEAP/30E1566SWjFkhERESkD4N6blq3bo0ffvihUvuqVatqXBARERFRTRgUboBHdwHfv38/kpKSIJPJ0KFDBwwaNAhyudyY9RERERHpxaBwc/XqVQQHByMjIwPt2rWDEAJ//fUX3Nzc8OOPP+LJJ580dp1EREREOjFozs2kSZPw5JNPIj09HefPn8eFCxeQlpYGT09PTJo0ydg1EhEREenMoJ6bmJgY/PLLL6p7TQFAkyZN8PHHHyMgIMBoxRERERHpy6CeG0tLSzx48KBSe25uLhQKRY2LIiIiIjKUQeHm5Zdfxttvv42zZ89CCAEhBH755ReMHz8eAwcONHaNRERERDozKNysWbMGTz75JPz8/GBlZQUrKysEBATAy8sLq1evNnaNRERERDozaM6No6MjvvvuO1y9ehVJSUkQQsDb2xteXl7Gro+IiIhIL3qFm9LSUqxYsQL79+9HcXEx+vbti7lz58LKyqq26iMiIiLSi17DUp988glmzpwJW1tbuLi4YOXKlbz0m4iIiOoVvcLNli1bsHbtWhw+fBjfffcd9u/fj61bt0IIUVv1EREREelFr3Bz/fp1vPzyy6qvg4KCIITAzZs3jV4YERERkSH0CjdFRUWwtrZWfS2TyaBQKFBYWGj0woiIiIgMoffVUh9++CFsbGxUXxcVFWHx4sVwcHBQta1cudI41RERERHpSa9w8/zzz+Py5ctqbf7+/khOTlZ9LZPJjFMZERERkQH0CjfHjx+vpTKIiIiIjMOgFYqJiIiI6iudw83HH3+MvLw8nfY9e/YsfvzxR4OLIhJCIL+oROODSw8QEVFVdB6WSkxMhLu7O4YOHYqBAwfC19cXzZo1AwCUlJQgMTERJ0+exDfffIPMzExs3bq11oomaRNCYEjkGcRfv6dxu7eLPXaN94Mu07usLeScB0ZE9JjROdxs3boVFy9exLp16xASEoLs7GzI5XJYWloiPz8fAODj44O3334boaGhsLS0rLWiSdoKipVagw0AJGbmoOO8Qzo9l6974/8FIQYcIqLHhV4Tirt06YINGzYgMjISFy9eRGpqKgoKCtC0aVM89dRTaNq0aW3VSY+puDl9YaOQAwDu5Bahx6fH9Dv++j3cyStSPUcZ9ugQEUmXQXcFl8lk6Nq1K7p27WrseojU2CjksFE8+jbNVyhV7bEzeqOJnULrcXmFSjyz+CgAwHfR0Urb2aNDRCRdBoUbIlOzLhd6NMkvUmrdBmju0ZFyb44QAgXFms+JlN83ET2eTB5uIiIisGzZMmRmZqJjx44IDw9Hjx49qj3u1KlT6NmzJzp16oSEhITaL5RqTcUP3uqCib7K9/LkFylVPTkVe3RqqzdHW7CojVCh6bWEAIZEnkFSZo7GY9iLRURSY9JwExUVhSlTpiAiIgIBAQHYsGED+vXrh8TERLRu3VrrcdnZ2Rg1ahReeOEF/Pe//63DisnYqrsyyhjK9/JYW8jh694YcRpeL+76PRQUK6vsEdJXVe/P2KHC0HNZG++7ptjTREQ1YdLfZitXrsTYsWMxbtw4AEB4eDgOHTqE9evXY+nSpVqPe+eddzBy5EjI5XLs37+/jqql2lDVlVG+7o1hbSHXuM1QMpkMu8b7Veop0jQvxxiqen81DRWaeryqCzbaerHqgq6BxdClABh6iKiMycJNUVER4uPjMXPmTLX2wMBAnD59WutxmzdvxrVr1/DNN99g0aJF1b5OYWGh2l3Lc3I0d82T6ZW/MgqovQ8rmUxmkl6KsvdnjFBRXQDQdpVZdXOVaos+gaW6kKZtKQAOrxFRGYN+y+Xl5eHjjz/Gf/7zH9y6dQulpaVq28vfSFOb27dvQ6lUwtnZWa3d2dkZWVlZGo+5cuUKZs6cidjYWJib61b60qVLsWDBAp32parV9twRm2o+eJ1sFBr/XdN9jUXT+Sk/f0jT+9M0v0iX81ldj1cTW4XqOawc/z8wmupcGBpY9FkKoD4OrxGRaRj0W2DcuHGIiYnBG2+8ARcXlxp9sFU8Vgih8fmUSiVGjhyJBQsWoG3btjo//6xZsxAWFqb6OicnB25ubgbX+7jSd+5IVUMQ5ekzedjMTIbkJcGqfxtr3+rqqRg2DJm0W3HfMrpcpl5daKqux0vfc6Ht/66s7vI/ntraqjoXugaWiiFN21IAdT28RkT1n0Hh5qeffsKPP/6IgIAAg1+4adOmkMvllXppbt26Vak3BwAePHiAuLg4XLhwARMnTgQAlJaWQggBc3NzHD58GH369Kl0nKWlJVdLNgJ95o7U5iRhfYKKrvvqEzYMfW/l5w9VF/rKX6auS2iqrscL0Odc1O4Eb10DC1A5pJXvdWrpaK3X9wIRPV4MCjeNGzeGk5NTjV5YoVCgW7duOHLkCF555RVV+5EjRzBo0KBK+9vb2+P3339Xa4uIiMDPP/+M3bt3w9PTs0b10P/TtadA21/M1d0+QZPamDysK13CRll40+W9aVpgUNtQU/l9q1t4UBNjnzdD/u+qYszAYmhvHBE9fgwKNx999BHmzp2Lr776CjY2Nga/eFhYGN544w34+vrCz88Pn3/+OdLS0jB+/HgAj4aUMjIysHXrVpiZmaFTp05qxzdv3hxWVlaV2slwuvzlbm2h+6TUikMmVT1nfZgIqm24oyzcaRsOMnTSbvl9qxui0yc06Uuf91dWh6a2ivtWdy70DSwMNUSkC4PCzYoVK3Dt2jU4OzvDw8MDFhYWatvPnz+v0/MMGzYMd+7cwcKFC5GZmYlOnTohOjoa7u7uAIDMzEykpaUZUiIZSJe/3AuKlbC11O1bR5chk/qk/IdxdcNV5d+bPpN2dZnsrClAGPtKJ0PfX1kPS/khJWsDzwVQvwNLXS7ASETGY9BvysGDBxutgAkTJmDChAkat23ZsqXKY+fPn4/58+cbrRZSV9ObVjZ0VQ1XVRwOMvZk57KwUJtXOtX0/WkLafV9+EjbhHBA94nRXGuHqH4zKNzMmzfP2HVQPaTtppVSo09PShlNH2I1neysqY7aDArlX++PBUEo//S6vL+qaquPoQYw3oRprrVDVL/VqI87Pj4eSUlJkMlk8Pb2ho+Pj7HqIqoz+vSkmKKO2goKxghO9TXEANonxhsSbDQNE2rCtXaI6geDfgJv3bqF4cOH4/jx43B0dIQQAtnZ2ejduzd27tyJZs2aGbtOMjFTLIpXl+rLh3Rd11Ff3rex6dJDUzbsWiqATv/rhSnfg1W+XdM8I13X2mlo83Z4Xy+SAoPCzXvvvYecnBz8+eef6NChAwAgMTERoaGhmDRpEnbs2GHUIh8n9fUXYXV/5Ze/ysbYd/U2FakHOikqf9VXVcGm4no72r63q5pnpO3S9fLf/0IAQyPPIFHDvB1dh7D0WVQR0O93RcXnrqpefWomMjWDws3Bgwdx9OhRVbABAG9vb6xbtw6BgYFGK+5xU5d3kC57varWs6mo4i/y6q62qbhPQ1PfJ8bSI9V9H2pajkDTKs6a6DrPSJefhUp1lVusUVtthswR0nXF8OqCjK41m/oPLyJNDAo3paWllS7/BgALC4tK95ki3dXmHaQrMsbESl1ur6DPZeP1EUNN/VfdVV/le2iMQdP3RHU/C+WvrqpusUZ9biKqScUAYkiIqXg1WFU188oxqo8M+tTp06cPJk+ejB07dsDV1RUAkJGRgalTp+KFF14waoGPK2PeQVqT6taz0XflW22LuBHVJV2uaqsNVV15VrGO6oZtdbmJqKZ5QoascA1oDicVz1tVNfPKMaqPDAo3n332GQYNGgQPDw+4ublBJpMhLS0NnTt3xjfffGPsGh9Ldbn4nS7d9tWxfkwuG6f6pz7cc0qfIUxtQUifm4gClecDVReaatLDoqlmXjlG9ZlB33Vubm44f/48jhw5gkuXLkEIAW9vb/Tt29fY9VEdMHaQ4kRcqkv1ZW6Urq+trd7yCzYasu6QPr1H+tJUs7Z6eZd2qg9q9In24osv4sUXXzRWLSQR9eXDhh4fDe37TFO9Nf25qe2fO30WcSQyNZ3DzZo1a/D222/DysoKa9asqXLfSZMm1bgwatj4y45IfzX9ualv6yRVHCrjJGOqKzqHm1WrViEkJARWVlZYtWqV1v1kMhnDzWOCw09EVFFVl8VzkjHVFZ3DTUpKisZ/0+OL3dJEVFFVl8XrsrYPkTEYZRapUqnE77//Dnd3dzRu3NgYT0kaVOzi1XYn44ptmtqNtYowQw0RaVN2ab4+a/uUx9BDhjIo3EyZMgWdO3fG2LFjoVQq8fzzz+PMmTOwsbHBDz/8gF69ehm5zMeXISufEhGZiqZL8w1d24fDWGQog8LN7t278frrrwMADhw4gNTUVFy6dAlbt27F7NmzcerUKaMW+TjTZRXgmtB3sT4ioqpoGq42ZG0fQPNqy0Dlnmlt2PPz+DIo3Ny+fRstWrQAAERHR2Po0KFo27Ytxo4dW+2VVGQ4basAl7VratO2bxn+8BORsel62bgua+XUpMeaPT+PL4PCjbOzMxITE+Hi4oKDBw8iIiICAJCfnw+5nL0AtUXbKsBl7ZratO1LRFSX9Fnbx9pCDl/3xoirwb3vAE5gfpwZ9Cn35ptv4rXXXoOLiwtkMplqIb+zZ8+iffv2Ri2QiIikS1Pokclk2DXeT21Yvqoe6Ir0ncBc1XAXg1DDZFC4mT9/Pjp16oT09HQMHToUlpaWAAC5XI6ZM2catUAiInr8yGQytV7m8kNY1d1DzNAJzJpwaKthMnh8YsiQIZXaQkNDa1QMERGRJrV9c1JteAPQhom3XyAiogahNm5OWiqATv/rxeENQKWDt18gIiLJ0WcCM1dalx7efoGIiB4b2kIPSQsHEU1ECFFpgT5Nk+B4c0oiIiL9GBRuhgwZAl9f30pXRi1btgy//vordu3aZZTipEoIgSGRZxCvwxoOxrg5JQMSEZHhKv7hycvD6z+Dwk1MTAzmzZtXqf2ll17C8uXLa1yU1BUUK6sMNhVviaBrqNEWYnj3biIi/VR1Xz9eHl7/GRRucnNzoVBU7gGwsLBATk5OjYt6nMTN6Wu01TOrCjEMNUREuqvqvn68PLz+MzPkoE6dOiEqKqpS+86dO+Ht7V3joh4nNv+7HUL5hy7BpqpeGgYZIqKaqbhWTuLCIMTN6WvCikgfBsXODz/8EK+++iquXbuGPn36AAD+85//YMeOHZxvU0c41EREVHuq+x2r6QIQzsWpPwwKNwMHDsT+/fuxZMkS7N69G9bW1ujSpQuOHj2Knj17GrtG0oKhhoio9lT8HVvVPByAc3HqE4MHDPv374/+/fsbsxYiIqJ6q6p5OADn4tQnBv8P3L9/H7t370ZycjKmTZsGJycnnD9/Hs7OzmjZsqUxayQiIjI5bfesKn+rBg5X1Q8GhZuLFy+ib9++cHBwQGpqKsaNGwcnJyfs27cP169fx9atW41dJxERkUlpm4ej73CVpkVcq8JwpD+Dwk1YWBhGjx6NTz/9FI0aNVK19+vXDyNHjjRacURERPWJprmOugxX3ckrgo1CDiGAoZFnkJip+7IpnMujP4PCzblz57Bhw4ZK7S1btkRWVlaNiyIiImootA1X5RUq8cziRz05NbnDePlwVB57dLQzKNxYWVlpXKzv8uXLaNasWY2LIiIiaii0DVdpmn9TxtvF/n+9Mdqft7pwVNPhLkC6AcmgcDNo0CAsXLgQ3377LQBAJpMhLS0NM2fOxKuvvmrUAomIiOo7TcNV2np0AN1CRVXhCKg83DUk8gyS9BjuAqQ75GVQuFm+fDmCg4PRvHlzFBQUoGfPnsjKyoKfnx8WL15s7BqJiIganJoutlrbw11A5SGvssnRmrJOQ+rlMSjc2Nvb4+TJk/j5559x/vx5lJaW4umnn0bfvlyamoiIqExNFls1ZLgLAGJn9EYTu8r3fyzPkIDUkHp59A43JSUlsLKyQkJCAvr06aO6/QIREREZl67DXaUC6DTvEACgpaN1taGquoCkSUNapFDvCs3NzeHu7g6lUv8T87iqOMnLkG8qIiIiQHuPjj5DYNUFJG2LFDYUBsWvOXPmYNasWfjmm2/g5ORk7JokRQiBIZFnEH/9npbtdVwQERE1eJoCjD5DYMYISPWZQeFmzZo1uHr1KlxdXeHu7g5bW1u17efPnzdKcVJQUKzUGmzKttta1v8uPiIikpaaBqT6zOBLwRvChKL6Jm5OX9go5LiTW4Qenx4zdTlERER6qTitor5eQWVQuJk/f76Ry3g82CjksFGYI1/BOTdERNQwVHXvrKoWIzRl8NEr3OTn52P69OnYv38/iouL0bdvX6xZswZNmzatrfqIiIjIhKpa9TgxMwcd/zcJudK2hUEmu7JKr1edN28etmzZgpCQEFhZWWHHjh149913sWvXrtqqj4iIiExI05VV9X16hV7hZu/evdi0aROGDx8OAHj99dcREBAApVIJuVxezdFERETU0Gi6ssrK8f8/8yveWqKMtYXpcoFe4SY9PR09evRQfd29e3eYm5vj5s2bcHNzM3pxREREZHoVr6Kq6a0lapte4UapVEKhUF/S2dzcHCUlJUYtioiIiOq3+hhqyugVboQQGD16NCwtLVVtDx8+xPjx49XWutm7d6/xKiQiIiLSg17hJjQ0tFLb66+/brRiHhflJ2eV/zcRERHVnF7hZvPmzbVVx2Olvo9VEhERNWRc999EGGqIiIhqh5mpCyAiIiIyJpOHm4iICHh6esLKygrdunVDbGys1n337t2LF198Ec2aNYO9vT38/Pxw6JDmlRGJiIjo8WTScBMVFYUpU6Zg9uzZuHDhAnr06IF+/fohLS1N4/4nTpzAiy++iOjoaMTHx6N3794YMGAALly4UMeVExERUX1l0nCzcuVKjB07FuPGjUOHDh0QHh4ONzc3rF+/XuP+4eHhmDFjBp555hm0adMGS5YsQZs2bXDgwIE6rpyIiIjqK5OFm6KiIsTHxyMwMFCtPTAwEKdPn9bpOUpLS/HgwQM4OTlp3aewsBA5OTlqDyIiIpIuk4Wb27dvQ6lUwtnZWa3d2dkZWVlZOj3HihUrkJeXh9dee03rPkuXLoWDg4PqwdtEEBERSZvJJxTLZOqXRAshKrVpsmPHDsyfPx9RUVFo3ry51v1mzZqF7Oxs1SM9Pb3GNRMREVH9ZbJ1bpo2bQq5XF6pl+bWrVuVenMqioqKwtixY7Fr1y707du3yn0tLS3VbhdBRERE0maynhuFQoFu3brhyJEjau1HjhyBv7+/1uN27NiB0aNHY/v27ejfv39tl0lEREQNjElXKA4LC8Mbb7wBX19f+Pn54fPPP0daWhrGjx8P4NGQUkZGBrZu3QrgUbAZNWoUVq9ejeeee07V62NtbQ0HBweTvQ8iIiKqP0waboYNG4Y7d+5g4cKFyMzMRKdOnRAdHQ13d3cAQGZmptqaNxs2bEBJSQn+9a9/4V//+peqPTQ0FFu2bKnr8omIiKgeMvm9pSZMmIAJEyZo3FYxsBw/frz2CyIiIqIGzeRXSxEREREZE8MNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJislvvyBF+UVKjf8mIiKi2sdwYyRC/P+/fRcdNV0hREREjzkOSxlJQXHVPTS+7o1hbSGvo2qIiIgeX+y5qQWxM3qjiZ1Crc3aQg6ZTGaiioiIiB4fDDe1wFohh42Cp5aIiMgUOCxFREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJJibuoC6iMhBEpKSqBUKnU+priwCC0byf/370I8NBe1VR4R1QILCwvI5XJTl0FERsBwU0FRUREyMzORn5+v13HKUoH5vZsDAO5k3cB9M1ltlEdEtUQmk6FVq1aws7MzdSlEVEMMN+WUlpYiJSUFcrkcrq6uUCgUkMl0CynFylIo/84FALg3s4OFnCN+RA2FEAJ///03bty4gTZt2rAHh6iBY7gpp6ioCKWlpXBzc4ONjY1ex8qVpZCZFwEArKysGG6IGphmzZohNTUVxcXFDDdEDRw/gTUwM+NpIXrc6NpLS0T1Hz/FiYiISFIYboiIiEhSGG6oRkaPHo3Bgwervu7VqxemTJlisnrqCw8PD4SHh9fJa/38889o3749SktL6+T1GqLCwkK0bt0a8fHxpi6FiOoAw42EZGVlYfLkyfDy8oKVlRWcnZ3xj3/8A5GRkXpf2m6ovXv34qOPPjLqc1YMUGVkMpnqYW5ujtatWyMsLAyFhYVGff2qbNmyBY6OjpXaz507h7fffrtOapgxYwZmz55daa5YQUEBGjduDCcnJxQUFFQ6zsPDQ3X+bGxs0KlTJ2zYsKFWay0sLMR7772Hpk2bwtbWFgMHDsSNGzeqPGb9+vXo0qUL7O3tYW9vDz8/P/z0009q+4wePVrt+0Emk+G5555Tbbe0tMS0adPw73//u1beFxHVLww3EpGcnAwfHx8cPnwYS5YswYULF3D06FFMnToVBw4cwNGjR7UeW1xcbLQ6nJyc0KhRI6M9X3U2b96MzMxMpKSkICIiAl9//TUWLVpUZ6+vTbNmzfS+4s4Qp0+fxpUrVzB06NBK2/bs2YNOnTrB29sbe/fu1Xj8woULkZmZiYsXL2Lw4MEYP348oqKiaq3eKVOmYN++fdi5cydOnjyJ3NxcvPzyy1UumNmqVSt8/PHHiIuLQ1xcHPr06YNBgwbhzz//VNvvpZdeQmZmpuoRHR2ttj0kJASxsbFISkqqlfdGRPWIeMxkZ2cLACI7O7vStoKCApGYmCgKCgpUbaWlpSKvsLjax/38QnE2+bY4m3xb3M8v1OmY6h6lpaU6v6+goCDRqlUrkZubq3F7+ecCINavXy8GDhwobGxsxNy5c0VJSYkYM2aM8PDwEFZWVqJt27YiPDxc7TlKSkrE1KlThYODg3BychLTp08Xo0aNEoMGDVLt07NnTzF58mTV14WFhWL69OnC1dVV2NjYiO7du4tjx46ptm/evFk4ODiIgwcPivbt2wtbW1sRFBQkbt68KYQQYt68eQKA2qPseABi3759ajWOGTNGBAcHq7VFRESIJ554QlhYWIi2bduKrVu3qm2/fv26GDhwoLC1tRWNGjUSQ4cOFVlZWartCQkJolevXsLOzk40atRIPP300+LcuXPi2LFjlWqbN2+eEEIId3d3sWrVKrVz/sUXX4jBgwcLa2tr4eXlJb777ju1Or777jvh5eUlrKysRK9evcSWLVsEAHHv3r2K/50q7733nhgyZIjGbb169RKRkZFi/fr1onfv3pW2V6xRCCHatGkjhg8frvX1auL+/fvCwsJC7Ny5U9WWkZEhzMzMxMGDB/V6rsaNG4uNGzeqvg4NDVX7PtSmV69e4sMPP9S4TdPPPxHVH1V9flfEdW6qUVCshPfcQyZ57cSFQbBRVP9fdOfOHVWPja2trcZ9Kl7mOm/ePCxduhSrVq2CXC5HaWkpWrVqhW+//RZNmzbF6dOn8fbbb8PFxQWvvfYaAGDFihX48ssvsWnTJnh7e2PFihXYt28f+vTpo7W2N998E6mpqdi5cydcXV2xb98+vPTSS/j999/Rpk0bAEB+fj6WL1+Or7/+GmZmZnj99dcxbdo0bNu2DdOmTUNSUhJycnKwefNmAI96hzT566+/cOzYMYwePVrVtm/fPkyePBnh4eHo27cvfvjhB7z55pto1aoVevfuDSEEBg8eDFtbW8TExKCkpAQTJkzAsGHDcPz4cQCP/uL38fHB+vXrIZfLkZCQAAsLC/j7+yM8PBxz587F5cuXAaDK1W0XLFiATz/9FMuWLcPatWsREhKC69evw8nJCampqRgyZAgmT56McePG4cKFC5g2bZrW5ypz4sQJjBgxolL7tWvXcObMGezduxdCCEyZMgXJycl44oknqnw+KyurKnvyOnbsiOvXr2vd7u7uXqlHpUx8fDyKi4sRGBioanN1dUWnTp1w+vRpBAUFVVkbACiVSuzatQt5eXnw8/NT23b8+HE0b94cjo6O6NmzJxYvXozmzZur7dO9e3fExsZW+zpE1LCZPNxERERg2bJlyMzMRMeOHREeHo4ePXpo3T8mJgZhYWH4888/4erqihkzZmD8+PF1WHH9c/XqVQgh0K5dO7X2pk2b4uHDhwCAf/3rX/jkk09U20aOHIkxY8ao7b9gwQLVvz09PXH69Gl8++23qnATHh6OWbNm4dVXXwUAREZG4tAh7cHv2rVr2LFjB27cuAFXV1cAwLRp03Dw4EFs3rwZS5YsAfBoWCwyMhJPPvkkAGDixIlYuHAhgEdhwdraGoWFhWjRokWl1xgxYgTkcjlKSkpQWFiIl19+GbNmzVJtX758OUaPHo0JEyYAAMLCwvDLL79g+fLl6N27N44ePYqLFy8iJSUFbm5uAICvv/4aHTt2xLlz5/DMM88gLS0N06dPR/v27QFAFcoAwMHBATKZTGNtFY0ePVoVRJYsWYK1a9fi119/xUsvvYTIyEi0a9cOy5YtAwC0a9cOf/zxBxYvXlzlc6ampqrObXlffvkl+vXrh8aNGwN4NGTz5Zdfah2yKykpwTfffIPff/8d7777rtbXi46OrjL8WFhYaN2WlZUFhUKhqqmMs7MzsrKytB4HAL///jv8/Pzw8OFD2NnZYd++ffD29lZt79evH4YOHQp3d3ekpKTgww8/RJ8+fRAfHw9LS0vVfi1btkRqamqVr0VEDZ9Jw01UVBSmTJmCiIgIBAQEYMOGDejXrx8SExPRunXrSvunpKQgODgYb731Fr755hucOnUKEyZMQLNmzVQfuMZmbSFH4sLq/6IsVpbictYDAEC7Fo2MskKxtYV+q6RW7J359ddfUVpaipCQkEqTbH19fSsdHxkZiY0bN+L69esoKChAUVERnnrqKQBAdnY2MjMz1f5aNjc3h6+vL4TQfJPQ8+fPQwiBtm3bqrUXFhaiSZMmqq9tbGxUwQYAXFxccOvWLZ3e86pVq9C3b18olUpcvXoVYWFheOONN7Bz504AQFJSUqWJvQEBAVi9erVqu5ubmyrYAIC3tzccHR2RlJSEZ555BmFhYRg3bhy+/vpr9O3bF0OHDlWrV1ddunRR/dvW1haNGjVSvc/Lly/jmWeeUdu/e/fu1T5nQUEBrKys1NqUSiW++uor1XsEgNdffx1Tp07FggUL1Fbf/fe//405c+agsLAQCoUC06dPxzvvvKP19dzd3autSV9CiGoX0GvXrh0SEhJw//597NmzB6GhoYiJiVEFnGHDhqn27dSpE3x9feHu7o4ff/wR//znP1XbrK2t62xyPRGZjknDzcqVKzF27FiMGzcOwKOegUOHDmH9+vVYunRppf0jIyPRunVr1SW2HTp0QFxcHJYvX15r4UYmk+k0NFSsLIXV/8KIjcK8Tm+/4OXlBZlMhkuXLqm1lw1BWFtbVzqm4vDVt99+i6lTp2LFihXw8/NDo0aNsGzZMpw9e9bgukpLSyGXyxEfH19pOfvywzcV/9qXyWRaA1NFLVq0gJeXF4BHH4APHjzAiBEjsGjRIlV7xQ/O8h+m2j5Yy7fPnz8fI0eOxI8//oiffvoJ8+bNw86dO/HKK6/oVGNV77Ps8m1NdehyDpo2bYp79+6ptR06dAgZGRlqH/jAo9Bz+PBh9OvXT9U2ffp0jB49GjY2NnBxcak2ZNRkWKpFixYoKirCvXv31Hpvbt26BX9//ypfV6FQqP4/fX19ce7cOaxevVrr1V0uLi5wd3fHlStX1Nrv3r2LZs2aVflaRNTwmexqqaKiIsTHx6uNvwNAYGAgTp8+rfGYM2fOVNo/KCgIcXFxWrvKCwsLkZOTo/aQmiZNmuDFF1/EZ599hry8PIOeIzY2Fv7+/pgwYQJ8fHzg5eWFa9euqbY7ODjAxcUFv/zyi6qtpKSkynVDfHx8oFQqcevWLXh5eak9dBnGKaNQKKq8mqa8shBVdulzhw4dcPLkSbV9Tp8+jQ4dOgB41EuTlpaG9PR01fbExERkZ2er9gGAtm3bYurUqTh8+DD++c9/qub/6FNbVdq3b49z586ptcXFxVV7nI+PDxITE9XaNm3ahOHDhyMhIUHtERISgk2bNqnt27RpU3h5ecHV1VWn2w9ER0dXet7yj4pXKJXXrVs3WFhY4MiRI6q2zMxM/PHHH9WGm4qEEFVe8n/nzh2kp6fDxcVFrf2PP/6Aj4+PXq9FRA2PyXpubt++DaVSCWdnZ7X2qsbfs7KyNO5fUlKC27dvV/pFBgBLly5Vm0tSW8zNZBr/XVfKhvZ8fX0xf/58dOnSBWZmZjh37hwuXbqEbt26VXm8l5cXtm7dikOHDsHT0xNff/01zp07B09PT9U+kydPxscff4w2bdqgQ4cOWLlyJe7fv6/1Odu2bYuQkBCMGjUKK1asgI+PD27fvo2ff/4ZnTt3RnBwsE7vzcPDA4cOHcLly5fRpEkTODg4qHpB7t+/j6ysLJSWluLKlStYuHAh2rZtqwom06dPx2uvvYann34aL7zwAg4cOIC9e/eqLo3v27cvunTpgpCQEISHh6smFPfs2RO+vr4oKCjA9OnTMWTIEHh6euLGjRs4d+6cqqfQw8MDubm5+M9//oOuXbvCxsbGoEvA33nnHaxcuRL//ve/MXbsWCQkJGDLli0Aqr7nUVBQEL766ivV13///TcOHDiA77//Hp06dVLbNzQ0FP3798fff/9tcO9FTYalHBwcMHbsWLz//vto0qQJnJycMG3aNHTu3Bl9+/ZV7ffCCy/glVdewcSJEwEAH3zwAfr16wc3Nzc8ePAAO3fuxPHjx3Hw4EEAQG5uLubPn49XX30VLi4uSE1NxQcffICmTZtW6l2LjY01+jpMRFQP1c4FW9XLyMgQAMTp06fV2hctWiTatWun8Zg2bdqIJUuWqLWdPHlSABCZmZkaj3n48KHIzs5WPdLT0/W6FFwfpaWlel2+bWw3b94UEydOFJ6ensLCwkLY2dmJ7t27i2XLlom8vDzVftBwCfXDhw/F6NGjhYODg3B0dBTvvvuumDlzpujatatqn+LiYjF58mRhb28vHB0dRVhYWLWXghcVFYm5c+cKDw8PYWFhIVq0aCFeeeUVcfHiRSHE/18KXt6+fftE+W/NW7duiRdffFHY2dlVuhS87CGTyYSLi4sYNmyYuHbtmtrz1eRS8MLCQjF8+HDh5uYmFAqFcHV1FRMnTlT7Hhk/frxo0qRJtZeCVzznDg4OYvPmzaqvyy4Ft7S0FL169RLr168XAKr8frx7966wtrYWly5dEkIIsXz5cuHo6CiKiooq7VtcXCycnJzEihUrNNZYFwoKCsTEiROFk5OTsLa2Fi+//LJIS0tT28fd3V11HoV4dHm/u7u7UCgUolmzZuKFF14Qhw8fVm3Pz88XgYGBolmzZsLCwkK0bt1ahIaGVnre06dPC0dHR5Gfn6+1Nl4KTlR/6XMpuEwIHSc3GFlRURFsbGywa9cutb+uJk+ejISEBMTExFQ65vnnn4ePj4/aRMl9+/bhtddeQ35+fpVXapTJycmBg4MDsrOzYW9vr7bt4cOHSElJgaenZ6VJmkR1bfHixYiMjFQbMtNkxowZyM7OrvXVhRu6oUOHwsfHBx988IHG7fz5J6rfqvr8rshkc24UCgW6deumNv4OAEeOHNE6/u7n51dp/8OHD8PX11enYENUn0VERODcuXNITk7G119/jWXLliE0NLTa42bPng13d3ejzP2RqsLCQnTt2hVTp041dSlEVAdMerVU2WW7vr6+8PPzw+eff460tDTVujWzZs1CRkYGtm7dCgAYP348PvvsM4SFheGtt97CmTNnsGnTJuzYscOUb4PIKK5cuYJFixbh7t27aN26Nd5//321NXu0cXBw0NobQY9YWlpizpw5pi6DiOqIScPNsGHDcOfOHdX9bTp16oTo6GjVpMXMzEykpaWp9vf09ER0dDSmTp2KdevWwdXVFWvWrKm1y8CJ6tKqVauwatUqU5dBRNTgmWzOjalwzg0RacKff6L6rUHMuanPHrO8R0Tgzz2RlDDclFM2KZnLsxM9foqKigCg0mraRNTwmPzGmfWJXC6Ho6Oj6n4/NjY2Oq3aSkQNW2lpKf7++2/Y2NjA3Jy/FokaOv4UV1B2WwBdb9xIRNJgZmaG1q1b8w8aIglguKlAJpPBxcUFzZs313q/KiKSHoVCATMzjtQTSQHDjRZyuZxj70RERA0Q/0whIiIiSWG4ISIiIklhuCEiIiJJeezm3JQt1JWTk2PiSoiIiEhXZZ/buiy4+diFmwcPHgAA3NzcTFwJERER6evBgwdwcHCocp/H7t5SpaWluHnzJho1amT09SxycnLg5uaG9PT0au97QYbjea4bPM91g+e57vBc143aOs9CCDx48ACurq7VLtvw2PXcmJmZoVWrVrX6Gvb29vzBqQM8z3WD57lu8DzXHZ7rulEb57m6HpsynFBMREREksJwQ0RERJLCcGNElpaWmDdvHiwtLU1diqTxPNcNnue6wfNcd3iu60Z9OM+P3YRiIiIikjb23BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNzoKSIiAp6enrCyskK3bt0QGxtb5f4xMTHo1q0brKys8MQTTyAyMrKOKm3Y9DnPe/fuxYsvvohmzZrB3t4efn5+OHToUB1W23Dp+/1c5tSpUzA3N8dTTz1VuwVKhL7nubCwELNnz4a7uzssLS3x5JNP4ssvv6yjahsufc/ztm3b0LVrV9jY2MDFxQVvvvkm7ty5U0fVNkwnTpzAgAED4OrqCplMhv3791d7jEk+BwXpbOfOncLCwkJ88cUXIjExUUyePFnY2tqK69eva9w/OTlZ2NjYiMmTJ4vExETxxRdfCAsLC7F79+46rrxh0fc8T548WXzyySfi119/FX/99ZeYNWuWsLCwEOfPn6/jyhsWfc9zmfv374snnnhCBAYGiq5du9ZNsQ2YIed54MCB4tlnnxVHjhwRKSkp4uzZs+LUqVN1WHXDo+95jo2NFWZmZmL16tUiOTlZxMbGio4dO4rBgwfXceUNS3R0tJg9e7bYs2ePACD27dtX5f6m+hxkuNFD9+7dxfjx49Xa2rdvL2bOnKlx/xkzZoj27durtb3zzjviueeeq7UapUDf86yJt7e3WLBggbFLkxRDz/OwYcPEnDlzxLx58xhudKDvef7pp5+Eg4ODuHPnTl2UJxn6nudly5aJJ554Qq1tzZo1olWrVrVWo9ToEm5M9TnIYSkdFRUVIT4+HoGBgWrtgYGBOH36tMZjzpw5U2n/oKAgxMXFobi4uNZqbcgMOc8VlZaW4sGDB3BycqqNEiXB0PO8efNmXLt2DfPmzavtEiXBkPP8/fffw9fXF59++ilatmyJtm3bYtq0aSgoKKiLkhskQ86zv78/bty4gejoaAgh8N///he7d+9G//7966Lkx4apPgcfuxtnGur27dtQKpVwdnZWa3d2dkZWVpbGY7KysjTuX1JSgtu3b8PFxaXW6m2oDDnPFa1YsQJ5eXl47bXXaqNESTDkPF+5cgUzZ85EbGwszM35q0MXhpzn5ORknDx5ElZWVti3bx9u376NCRMm4O7du5x3o4Uh59nf3x/btm3DsGHD8PDhQ5SUlGDgwIFYu3ZtXZT82DDV5yB7bvQkk8nUvhZCVGqrbn9N7aRO3/NcZseOHZg/fz6ioqLQvHnz2ipPMnQ9z0qlEiNHjsSCBQvQtm3buipPMvT5fi4tLYVMJsO2bdvQvXt3BAcHY+XKldiyZQt7b6qhz3lOTEzEpEmTMHfuXMTHx+PgwYNISUnB+PHj66LUx4opPgf555eOmjZtCrlcXumvgFu3blVKpWVatGihcX9zc3M0adKk1mptyAw5z2WioqIwduxY7Nq1C3379q3NMhs8fc/zgwcPEBcXhwsXLmDixIkAHn0ICyFgbm6Ow4cPo0+fPnVSe0NiyPezi4sLWrZsCQcHB1Vbhw4dIITAjRs30KZNm1qtuSEy5DwvXboUAQEBmD59OgCgS5cusLW1RY8ePbBo0SL2rBuJqT4H2XOjI4VCgW7duuHIkSNq7UeOHIG/v7/GY/z8/Crtf/jwYfj6+sLCwqLWam3IDDnPwKMem9GjR2P79u0cM9eBvufZ3t4ev//+OxISElSP8ePHo127dkhISMCzzz5bV6U3KIZ8PwcEBODmzZvIzc1Vtf31118wMzNDq1atarXehsqQ85yfnw8zM/WPQLlcDuD/exao5kz2OVir05UlpuxSw02bNonExEQxZcoUYWtrK1JTU4UQQsycOVO88cYbqv3LLoGbOnWqSExMFJs2beKl4DrQ9zxv375dmJubi3Xr1onMzEzV4/79+6Z6Cw2Cvue5Il4tpRt9z/ODBw9Eq1atxJAhQ8Sff/4pYmJiRJs2bcS4ceNM9RYaBH3P8+bNm4W5ubmIiIgQ165dEydPnhS+vr6ie/fupnoLDcKDBw/EhQsXxIULFwQAsXLlSnHhwgXVJff15XOQ4UZP69atE+7u7kKhUIinn35axMTEqLaFhoaKnj17qu1//Phx4ePjIxQKhfDw8BDr16+v44obJn3Oc8+ePQWASo/Q0NC6L7yB0ff7uTyGG93pe56TkpJE3759hbW1tWjVqpUICwsT+fn5dVx1w6PveV6zZo3w9vYW1tbWwsXFRYSEhIgbN27UcdUNy7Fjx6r8fVtfPgdlQrD/jYiIiKSDc26IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYbohIjYeHB8LDw1Vfy2Qy7N+/v8pj7ty5g+bNmyM1NbVWayszevRoDB48uMp9jh8/DplMhvv379daHYa8Rq9evTBlypQave6WLVvg6OhYo+fQZNq0aZg0aZLRn5eorjHcENUTo0ePhkwmg0wmg7m5OVq3bo13330X9+7dM3Vp1Vq6dCkGDBgADw8PAEBqaqrqvchkMjRu3BjPP/88YmJijPJ6q1evxpYtW1RfawoM/v7+yMzMVLu79uMsMzMTI0eORLt27WBmZqYxYM2YMQObN29GSkpK3RdIZEQMN0T1yEsvvYTMzEykpqZi48aNOHDgACZMmGDqsqpUUFCATZs2Ydy4cZW2HT16FJmZmYiJiYG9vT2Cg4ON8sHp4OBQbc+FQqFAixYtIJPJavx6UlBYWIhmzZph9uzZ6Nq1q8Z9mjdvjsDAQERGRtZxdUTGxXBDVI9YWlqiRYsWaNWqFQIDAzFs2DAcPnxYbZ/NmzejQ4cOsLKyQvv27REREaG2/caNGxg+fDicnJxga2sLX19fnD17FgBw7do1DBo0CM7OzrCzs8MzzzyDo0eP1qjmn376Cebm5vDz86u0rUmTJmjRogW6dOmCDRs2ID8/X/V+YmJi0L17d1haWsLFxQUzZ85ESUmJ6tjdu3ejc+fOsLa2RpMmTdC3b1/k5eUBUB+WGj16NGJiYrB69WpVT1FqaqrakFF2djasra1x8OBBtfr27t0LW1tb5ObmAgAyMjIwbNgwNG7cGE2aNMGgQYP0Gmq7c+cORowYgVatWsHGxgadO3fGjh07Ku1XUlKCiRMnwtHREU2aNMGcOXNQ/jZ/RUVFmDFjBlq2bAlbW1s8++yzOH78uM51aOLh4YHVq1dj1KhRVfZmDRw4UGPNRA0Jww1RPZWcnIyDBw/CwsJC1fbFF19g9uzZWLx4MZKSkrBkyRJ8+OGH+OqrrwAAubm56NmzJ27evInvv/8ev/32G2bMmIHS0lLV9uDgYBw9ehQXLlxAUFAQBgwYgLS0NIPrPHHiBHx9favdz8bGBgBQXFyMjIwMBAcH45lnnsFvv/2G9evXY9OmTVi0aBGAR0MoI0aMwJgxY5CUlITjx4/jn//8JzTd53f16tXw8/PDW2+9hczMTGRmZsLNzU1tHwcHB/Tv3x/btm1Ta9++fTsGDRoEOzs75Ofno3fv3rCzs8OJEydw8uRJ2NnZ4aWXXkJRUZFO5+Lhw4fo1q0bfvjhB/zxxx94++238cYbb6jCZZmvvvoK5ubmOHv2LNasWYNVq1Zh48aNqu1vvvkmTp06hZ07d+LixYsYOnQoXnrpJVy5ckXj65YNA9Y0AAFA9+7dkZ6ejuvXr9f4uYhMptbvO05EOgkNDRVyuVzY2toKKysrAUAAECtXrlTt4+bmJrZv36523EcffST8/PyEEEJs2LBBNGrUSNy5c0fn1/X29hZr165Vfe3u7i5WrVql+hqA2Ldvn9bjBw0aJMaMGaPWlpKSIgCICxcuCCGEyM3NFe+8846Qy+Xi4sWL4oMPPhDt2rUTpaWlqmPWrVsn7OzshFKpFPHx8QKASE1N1fiaoaGhYtCgQaqve/bsKSZPnqy2z7FjxwQAce/ePSGEEHv37hV2dnYiLy9PCCFEdna2sLKyEj/++KMQQohNmzZVqqmwsFBYW1uLQ4cOaayj4mtoEhwcLN5//321Wjt06KD2Ov/+979Fhw4dhBBCXL16VchkMpGRkaH2PC+88IKYNWuWEEKIzZs3CwcHB9W2GzduiHbt2omzZ89qraM8TeerTHZ2tgAgjh8/rtNzEdVH5qaLVURUUe/evbF+/Xrk5+dj48aN+Ouvv/Dee+8BAP7++2+kp6dj7NixeOutt1THlJSUqIYZEhIS4OPjAycnJ43Pn5eXhwULFuCHH37AzZs3UVJSgoKCghr13BQUFMDKykrjNn9/f5iZmSE/Px8uLi7YsmULOnfujHnz5sHPz09tPkxAQAByc3Nx48YNdO3aFS+88AI6d+6MoKAgBAYGYsiQIWjcuLHBdfbv3x/m5ub4/vvvMXz4cOzZsweNGjVCYGAgACA+Ph5Xr15Fo0aN1I57+PAhrl27ptNrKJVKfPzxx4iKikJGRgYKCwtRWFgIW1tbtf2ee+45tffu5+eHFStWQKlU4vz58xBCoG3btmrHFBYWokmTJhpft2XLlrh06ZJONVbH2toaAJCfn2+U5yMyBYYbonrE1tYWXl5eAIA1a9agd+/eWLBgAT766CPV0NIXX3yBZ599Vu04uVwO4P8/mLSZPn06Dh06hOXLl8PLywvW1tYYMmSIzsMumjRt2lTrFV1RUVHw9vZWzS0pI4SoNNFX/G/ISSaTQS6X48iRIzh9+jQOHz6MtWvXYvbs2Th79iw8PT0NqlOhUGDIkCHYvn07hg8fju3bt2PYsGEwN3/0a7C0tBTdunWrNHQFAM2aNdPpNVasWIFVq1YhPDwcnTt3hq2tLaZMmaLX+S0tLYVcLkd8fLzq/7WMnZ2dzs9jqLt37wLQ/T0T1UcMN0T12Lx589CvXz+8++67cHV1RcuWLZGcnIyQkBCN+3fp0gUbN27E3bt3NfbexMbGYvTo0XjllVcAPJqDU9O1aXx8fPDNN99o3Obm5oYnn3yyUru3tzf27NmjFnJOnz6NRo0aoWXLlgAehZyAgAAEBARg7ty5cHd3x759+xAWFlbp+RQKBZRKZbW1hoSEIDAwEH/++SeOHTuGjz76SLXt6aefRlRUFJo3bw57e3ud3ntFsbGxGDRoEF5//XUAj4LKlStX0KFDB7X9fvnll0pft2nTBnK5HD4+PlAqlbh16xZ69OhhUB018ccff8DCwgIdO3as89cmMhZOKCaqx3r16oWOHTtiyZIlAID58+dj6dKlWL16Nf766y/8/vvv2Lx5M1auXAkAGDFiBFq0aIHBgwfj1KlTSE5Oxp49e3DmzBkAgJeXF/bu3YuEhAT89ttvGDlypKpHyFBBQUH4888/9VqPZ8KECUhPT8d7772HS5cu4bvvvsO8efMQFhYGMzMznD17FkuWLEFcXBzS0tKwd+9e/P3335VCQhkPDw+cPXsWqampuH37ttb31LNnTzg7OyMkJAQeHh547rnnVNtCQkLQtGlTDBo0CLGxsUhJSUFMTAwmT56MGzdu6PS+vLy8VD1OSUlJeOedd5CVlVVpv/T0dISFheHy5cvYsWMH1q5di8mTJwMA2rZti5CQEIwaNQp79+5FSkoKzp07h08++QTR0dEaXzcjIwPt27fHr7/+WmV9CQkJSEhIQG5uLv7++28kJCQgMTFRbZ/Y2Fj06NGj2l5AovqM4YaongsLC8MXX3yB9PR0jBs3Dhs3blTNXenZsye2bNmiGqpRKBQ4fPgwmjdvjuDgYHTu3Bkff/yxanhj1apVaNy4Mfz9/TFgwAAEBQXh6aefrlF9nTt3hq+vL7799ludj2nZsiWio6Px66+/omvXrhg/fjzGjh2LOXPmAADs7e1x4sQJBAcHo23btpgzZw5WrFiBfv36aXy+adOmQS6Xw9vbG82aNdM6h0gmk2HEiBH47bffKvV+2djY4MSJE2jdujX++c9/okOHDhgzZgwKCgp07sn58MMP8fTTTyMoKAi9evVSBc2KRo0ahYKCAnTv3h3/+te/8N577+Htt99Wbd+8eTNGjRqF999/H+3atcPAgQNx9uzZSleBlSkuLsbly5ernSfj4+MDHx8fxMfHY/v27fDx8UFwcLDaPjt27FCb00XUEMmE0HBtJRGRHqKjozFt2jT88ccfMDPj30wN1Y8//ojp06fj4sWLqrlIRA0Rv3uJqMaCg4Nx5coVZGRkaO1doPovLy8PmzdvZrChBo89N0RERCQp7D8mIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJ+T+YRSrDv7bnUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Other way to draw Precision-Recall curve\n",
    "display = PrecisionRecallDisplay.from_predictions(y_test, y_pred_probs[:, 1], name=\"GradientBoosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ed00bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2222222222222222\n",
      "0.024691358024691357\n"
     ]
    }
   ],
   "source": [
    "# Verify precision and recall at thresholds 0.5\n",
    "print(precision_score(y_test, y_pred_probs[:, 1] > 0.5))\n",
    "print(recall_score(y_test, y_pred_probs[:, 1] > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99535bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca5e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "18a042a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.803714\n",
       "1    0.196286\n",
       "Name: Amyl_user, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_2['Amyl_user'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1f6ff5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.808355\n",
       "1    0.191645\n",
       "Name: Amyl_user, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3506c10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.785146\n",
       "1    0.214854\n",
       "Name: Amyl_user, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16a31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff8691c",
   "metadata": {},
   "source": [
    "## 5.3) Modeling Cannabis consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7ec25",
   "metadata": {},
   "source": [
    "### 5.3.1) Modeling with Age as numerical type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a481a30",
   "metadata": {},
   "source": [
    "### 5.3.1.1) Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "537453ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1885, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age25-34</th>\n",
       "      <th>age35-44</th>\n",
       "      <th>age45-54</th>\n",
       "      <th>age55-64</th>\n",
       "      <th>age65+</th>\n",
       "      <th>Male</th>\n",
       "      <th>Edu_gr2</th>\n",
       "      <th>Edu_gr3</th>\n",
       "      <th>Edu_gr4</th>\n",
       "      <th>Edu_gr5</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_level</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Age_level</th>\n",
       "      <th>Amyl_binary</th>\n",
       "      <th>Amyl_user</th>\n",
       "      <th>Cannabis_binary</th>\n",
       "      <th>Cannabis_user</th>\n",
       "      <th>Edu_gr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Professional certificate</td>\n",
       "      <td>UK</td>\n",
       "      <td>Mixed-White/Asian</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>Edu_gr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>2</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Professional certificate</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Masters degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age25-34  age35-44  age45-54  age55-64  age65+  Male  Edu_gr2  Edu_gr3  \\\n",
       "0         0         1         0         0       0     0        0        1   \n",
       "1         1         0         0         0       0     1        0        0   \n",
       "2         0         1         0         0       0     1        0        1   \n",
       "3         0         0         0         0       0     0        0        0   \n",
       "4         0         1         0         0       0     0        0        0   \n",
       "\n",
       "   Edu_gr4  Edu_gr5  ...  Education_level                 Education  Country  \\\n",
       "0        0        0  ...                6  Professional certificate       UK   \n",
       "1        0        1  ...                9          Doctorate degree       UK   \n",
       "2        0        0  ...                6  Professional certificate       UK   \n",
       "3        0        1  ...                8            Masters degree       UK   \n",
       "4        0        1  ...                9          Doctorate degree       UK   \n",
       "\n",
       "           Ethnicity  Age_level  Amyl_binary  Amyl_user  Cannabis_binary  \\\n",
       "0  Mixed-White/Asian          3     Non-user          0         Non-user   \n",
       "1              White          2         User          1             User   \n",
       "2              White          3     Non-user          0             User   \n",
       "3              White          1     Non-user          0             User   \n",
       "4              White          3     Non-user          0             User   \n",
       "\n",
       "   Cannabis_user   Edu_gr  \n",
       "0              0  Edu_gr3  \n",
       "1              1  Edu_gr5  \n",
       "2              1  Edu_gr3  \n",
       "3              1  Edu_gr5  \n",
       "4              1  Edu_gr5  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the latest dataset\n",
    "drug_2 = pd.read_csv('../data/drug_2.csv', index_col=0)\n",
    "print(drug_2.shape)\n",
    "drug_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "465e2d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                     Type        Data/Info\n",
      "--------------------------------------------------\n",
      "GradientBoostingClassifier   ABCMeta     <class 'sklearn.ensemble.<...>dientBoostingClassifier'>\n",
      "GridSearchCV                 ABCMeta     <class 'sklearn.model_sel<...>on._search.GridSearchCV'>\n",
      "KFold                        ABCMeta     <class 'sklearn.model_selection._split.KFold'>\n",
      "RandomForestClassifier       ABCMeta     <class 'sklearn.ensemble.<...>.RandomForestClassifier'>\n",
      "RandomizedSearchCV           ABCMeta     <class 'sklearn.model_sel<...>arch.RandomizedSearchCV'>\n",
      "cross_val_score              function    <function cross_val_score at 0x0000017D7036AAF0>\n",
      "np                           module      <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "pd                           module      <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "plt                          module      <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "precision_recall_curve       function    <function precision_recal<...>ve at 0x0000017D702D1EE0>\n",
      "precision_score              function    <function precision_score at 0x0000017D702E0670>\n",
      "recall_score                 function    <function recall_score at 0x0000017D702E0700>\n",
      "roc_auc_score                function    <function roc_auc_score at 0x0000017D702D1D30>\n",
      "roc_curve                    function    <function roc_curve at 0x0000017D702D1F70>\n",
      "score                        function    <function precision_recal<...>rt at 0x0000017D702E05E0>\n",
      "time                         module      <module 'time' (built-in)>\n",
      "train_test_split             function    <function train_test_split at 0x0000017D70219670>\n"
     ]
    }
   ],
   "source": [
    "# Look at variables in memory. Variables have different types: type, ABCMeta, DataFrame, functions.\n",
    "# use '%who function' to list all functions, '%who DataFrame' to list all DataFrame. \n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3806fde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score\t precision_recall_curve\t precision_score\t recall_score\t rf_eval\t roc_auc_score\t roc_curve\t score\t train_RF\t \n",
      "train_test_split\t \n"
     ]
    }
   ],
   "source": [
    "%who function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3038cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug_2\t \n"
     ]
    }
   ],
   "source": [
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a886417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No variables match your requested type.\n"
     ]
    }
   ],
   "source": [
    "%who Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7349e253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1885, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age25-34</th>\n",
       "      <th>age35-44</th>\n",
       "      <th>age45-54</th>\n",
       "      <th>age55-64</th>\n",
       "      <th>age65+</th>\n",
       "      <th>Male</th>\n",
       "      <th>Edu_gr2</th>\n",
       "      <th>Edu_gr3</th>\n",
       "      <th>Edu_gr4</th>\n",
       "      <th>Edu_gr5</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_level</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Age_level</th>\n",
       "      <th>Amyl_binary</th>\n",
       "      <th>Amyl_user</th>\n",
       "      <th>Cannabis_binary</th>\n",
       "      <th>Cannabis_user</th>\n",
       "      <th>Edu_gr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Professional certificate</td>\n",
       "      <td>UK</td>\n",
       "      <td>Mixed-White/Asian</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>Edu_gr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>2</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Professional certificate</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Masters degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-user</td>\n",
       "      <td>0</td>\n",
       "      <td>User</td>\n",
       "      <td>1</td>\n",
       "      <td>Edu_gr5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age25-34  age35-44  age45-54  age55-64  age65+  Male  Edu_gr2  Edu_gr3  \\\n",
       "0         0         1         0         0       0     0        0        1   \n",
       "1         1         0         0         0       0     1        0        0   \n",
       "2         0         1         0         0       0     1        0        1   \n",
       "3         0         0         0         0       0     0        0        0   \n",
       "4         0         1         0         0       0     0        0        0   \n",
       "\n",
       "   Edu_gr4  Edu_gr5  ...  Education_level                 Education  Country  \\\n",
       "0        0        0  ...                6  Professional certificate       UK   \n",
       "1        0        1  ...                9          Doctorate degree       UK   \n",
       "2        0        0  ...                6  Professional certificate       UK   \n",
       "3        0        1  ...                8            Masters degree       UK   \n",
       "4        0        1  ...                9          Doctorate degree       UK   \n",
       "\n",
       "           Ethnicity  Age_level  Amyl_binary  Amyl_user  Cannabis_binary  \\\n",
       "0  Mixed-White/Asian          3     Non-user          0         Non-user   \n",
       "1              White          2         User          1             User   \n",
       "2              White          3     Non-user          0             User   \n",
       "3              White          1     Non-user          0             User   \n",
       "4              White          3     Non-user          0             User   \n",
       "\n",
       "   Cannabis_user   Edu_gr  \n",
       "0              0  Edu_gr3  \n",
       "1              1  Edu_gr5  \n",
       "2              1  Edu_gr3  \n",
       "3              1  Edu_gr5  \n",
       "4              1  Edu_gr5  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(drug_2.shape)\n",
    "drug_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f08f7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "      <th>Edu_gr2</th>\n",
       "      <th>Edu_gr3</th>\n",
       "      <th>Edu_gr4</th>\n",
       "      <th>Edu_gr5</th>\n",
       "      <th>Canada</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Other</th>\n",
       "      <th>Republic of Ireland</th>\n",
       "      <th>UK</th>\n",
       "      <th>USA</th>\n",
       "      <th>Age_value</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Male  Edu_gr2  Edu_gr3  Edu_gr4  Edu_gr5  Canada  New Zealand  Other  \\\n",
       "0     0        0        1        0        0       0            0      0   \n",
       "1     1        0        0        0        1       0            0      0   \n",
       "2     1        0        1        0        0       0            0      0   \n",
       "3     0        0        0        0        1       0            0      0   \n",
       "4     0        0        0        0        1       0            0      0   \n",
       "\n",
       "   Republic of Ireland  UK  USA  Age_value   Nscore   Escore   Oscore  \\\n",
       "0                    0   1    0    0.49788  0.31287 -0.57545 -0.58331   \n",
       "1                    0   1    0   -0.07854 -0.67825  1.93886  1.43533   \n",
       "2                    0   1    0    0.49788 -0.46725  0.80523 -0.84732   \n",
       "3                    0   1    0   -0.95197 -0.14882 -0.80615 -0.01928   \n",
       "4                    0   1    0    0.49788  0.73545 -1.63340 -0.45174   \n",
       "\n",
       "    Ascore   Cscore  Impulsive       SS  \n",
       "0 -0.91699 -0.00665   -0.21712 -1.18084  \n",
       "1  0.76096 -0.14277   -0.71126 -0.21575  \n",
       "2 -1.62090 -1.01450   -1.37983  0.40148  \n",
       "3  0.59042  0.58489   -1.37983 -1.18084  \n",
       "4 -0.30172  1.30612   -0.21712 -0.21575  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = ['Male', 'Edu_gr2', 'Edu_gr3', 'Edu_gr4', 'Edu_gr5', 'Canada', 'New Zealand', 'Other', 'Republic of Ireland', \n",
    "            'UK', 'USA', 'Age_value', 'Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS']\n",
    "X = drug_2[col_list]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63d6b349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Cannabis_user, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = drug_2['Cannabis_user']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4192b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1508, 19) (1508,)\n",
      "(377, 19) (377,)\n"
     ]
    }
   ],
   "source": [
    "# Split with stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=12, stratify=y)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e42f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug_2:  1    0.671088\n",
      "0    0.328912\n",
      "Name: Cannabis_user, dtype: float64\n",
      "y_train:  1    0.671088\n",
      "0    0.328912\n",
      "Name: Cannabis_user, dtype: float64\n",
      "y_test:  1    0.671088\n",
      "0    0.328912\n",
      "Name: Cannabis_user, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check stratify\n",
    "print('drug_2: ', drug_2['Cannabis_user'].value_counts(normalize=True))\n",
    "print('y_train: ', y_train.value_counts(normalize=True))\n",
    "print('y_test: ', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39352bb8",
   "metadata": {},
   "source": [
    "#### 5.3.1.2) Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ee394",
   "metadata": {},
   "source": [
    "#### Explore RandomForestClassifier through Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a0899a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78476821, 0.81125828, 0.79801325, 0.79401993, 0.82059801])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore RandomForestClassifier through Cross-Validation. Use only X_train and y_train\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, X_train, y_train, cv=k_fold, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Interesting not better than to predict Amyl_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "60d9b2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78807947, 0.8013245 , 0.79470199, 0.80066445, 0.80066445])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning cv=5 to use StratifiedKFold\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "90cc92e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84846535, 0.87304075, 0.8629895 , 0.8880388 , 0.89081408])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use roc_auc as performance measure\n",
    "cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Interesting accuracy is not better, but auc is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3166fd",
   "metadata": {},
   "source": [
    "#### Hyperparameter search using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5faf2263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
      "['gini', 'entropy', 'log_loss']\n",
      "['auto', 6, 8]\n",
      "[10, 30, 50, 70, 90, None]\n",
      "[2, 6, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
       " 'criterion': ['gini', 'entropy', 'log_loss'],\n",
       " 'max_depth': [10, 30, 50, 70, 90, None],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto', 6, 8]}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 19 # Input the number of features here. Alternatively estimate a model and get _n_features_in_ attribute\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 9)]\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "max_features = ['auto', int(np.sqrt(n_features)) + 2, int(np.sqrt(n_features)) + 4]\n",
    "max_depth = [int(x) for x in np.linspace(10, 90, num = 5)]   \n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 6, 10]\n",
    "\n",
    "print(n_estimators)\n",
    "print(criteria)\n",
    "print(max_features)\n",
    "print(max_depth)\n",
    "print(min_samples_split)\n",
    "\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'criterion': criteria,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'max_features': max_features\n",
    "        }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "483ccb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2430 fits failed out of a total of 7290.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2430 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.87256217 0.87436251 0.87603034 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.331073</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>entropy</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 30, 'max...</td>\n",
       "      <td>0.853639</td>\n",
       "      <td>0.886625</td>\n",
       "      <td>0.866323</td>\n",
       "      <td>0.894214</td>\n",
       "      <td>0.896615</td>\n",
       "      <td>0.879483</td>\n",
       "      <td>0.016749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.420435</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.855545</td>\n",
       "      <td>0.883366</td>\n",
       "      <td>0.867542</td>\n",
       "      <td>0.896290</td>\n",
       "      <td>0.894489</td>\n",
       "      <td>0.879446</td>\n",
       "      <td>0.015738</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.150954</td>\n",
       "      <td>0.038788</td>\n",
       "      <td>0.081597</td>\n",
       "      <td>0.010871</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>450</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.851139</td>\n",
       "      <td>0.883017</td>\n",
       "      <td>0.870727</td>\n",
       "      <td>0.895940</td>\n",
       "      <td>0.895690</td>\n",
       "      <td>0.879302</td>\n",
       "      <td>0.016887</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.837827</td>\n",
       "      <td>0.024604</td>\n",
       "      <td>0.070030</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>350</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.849851</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.873414</td>\n",
       "      <td>0.894389</td>\n",
       "      <td>0.894489</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.388338</td>\n",
       "      <td>0.037565</td>\n",
       "      <td>0.031022</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.850792</td>\n",
       "      <td>0.884560</td>\n",
       "      <td>0.868538</td>\n",
       "      <td>0.892989</td>\n",
       "      <td>0.898640</td>\n",
       "      <td>0.879104</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.707242</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.053066</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>0.881525</td>\n",
       "      <td>0.870279</td>\n",
       "      <td>0.896690</td>\n",
       "      <td>0.895490</td>\n",
       "      <td>0.878648</td>\n",
       "      <td>0.017614</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.059691</td>\n",
       "      <td>0.161811</td>\n",
       "      <td>0.080620</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
       "      <td>0.847525</td>\n",
       "      <td>0.884510</td>\n",
       "      <td>0.870229</td>\n",
       "      <td>0.895540</td>\n",
       "      <td>0.894989</td>\n",
       "      <td>0.878559</td>\n",
       "      <td>0.018035</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>1.092514</td>\n",
       "      <td>0.050764</td>\n",
       "      <td>0.072918</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>0.853812</td>\n",
       "      <td>0.881674</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.896790</td>\n",
       "      <td>0.894489</td>\n",
       "      <td>0.878553</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1.318828</td>\n",
       "      <td>0.137286</td>\n",
       "      <td>0.101848</td>\n",
       "      <td>0.019715</td>\n",
       "      <td>gini</td>\n",
       "      <td>70</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 70, 'max_fe...</td>\n",
       "      <td>0.850396</td>\n",
       "      <td>0.882420</td>\n",
       "      <td>0.869632</td>\n",
       "      <td>0.894739</td>\n",
       "      <td>0.894689</td>\n",
       "      <td>0.878376</td>\n",
       "      <td>0.016790</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.844700</td>\n",
       "      <td>0.014482</td>\n",
       "      <td>0.060948</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>350</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 30, 'max_fe...</td>\n",
       "      <td>0.851337</td>\n",
       "      <td>0.882669</td>\n",
       "      <td>0.870080</td>\n",
       "      <td>0.893739</td>\n",
       "      <td>0.893789</td>\n",
       "      <td>0.878323</td>\n",
       "      <td>0.016075</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "594       0.331073      0.021543         0.020753        0.001681   \n",
       "496       0.420435      0.028385         0.028924        0.000630   \n",
       "25        1.150954      0.038788         0.081597        0.010871   \n",
       "23        0.837827      0.024604         0.070030        0.009561   \n",
       "10        0.388338      0.037565         0.031022        0.006449   \n",
       "22        0.707242      0.014188         0.053066        0.001906   \n",
       "186       1.059691      0.161811         0.080620        0.011200   \n",
       "915       1.092514      0.050764         0.072918        0.001494   \n",
       "269       1.318828      0.137286         0.101848        0.019715   \n",
       "104       0.844700      0.014482         0.060948        0.000575   \n",
       "\n",
       "    param_criterion param_max_depth param_max_features  \\\n",
       "594         entropy              30                  6   \n",
       "496         entropy              10               auto   \n",
       "25             gini              10               auto   \n",
       "23             gini              10               auto   \n",
       "10             gini              10               auto   \n",
       "22             gini              10               auto   \n",
       "186            gini              50               auto   \n",
       "915         entropy            None               auto   \n",
       "269            gini              70               auto   \n",
       "104            gini              30               auto   \n",
       "\n",
       "    param_min_samples_split param_n_estimators  \\\n",
       "594                       2                100   \n",
       "496                       6                150   \n",
       "25                       10                450   \n",
       "23                       10                350   \n",
       "10                        6                150   \n",
       "22                       10                300   \n",
       "186                      10                400   \n",
       "915                      10                400   \n",
       "269                      10                500   \n",
       "104                      10                350   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "594  {'criterion': 'entropy', 'max_depth': 30, 'max...           0.853639   \n",
       "496  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.855545   \n",
       "25   {'criterion': 'gini', 'max_depth': 10, 'max_fe...           0.851139   \n",
       "23   {'criterion': 'gini', 'max_depth': 10, 'max_fe...           0.849851   \n",
       "10   {'criterion': 'gini', 'max_depth': 10, 'max_fe...           0.850792   \n",
       "22   {'criterion': 'gini', 'max_depth': 10, 'max_fe...           0.849257   \n",
       "186  {'criterion': 'gini', 'max_depth': 50, 'max_fe...           0.847525   \n",
       "915  {'criterion': 'entropy', 'max_depth': None, 'm...           0.853812   \n",
       "269  {'criterion': 'gini', 'max_depth': 70, 'max_fe...           0.850396   \n",
       "104  {'criterion': 'gini', 'max_depth': 30, 'max_fe...           0.851337   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "594           0.886625           0.866323           0.894214   \n",
       "496           0.883366           0.867542           0.896290   \n",
       "25            0.883017           0.870727           0.895940   \n",
       "23            0.883465           0.873414           0.894389   \n",
       "10            0.884560           0.868538           0.892989   \n",
       "22            0.881525           0.870279           0.896690   \n",
       "186           0.884510           0.870229           0.895540   \n",
       "915           0.881674           0.866000           0.896790   \n",
       "269           0.882420           0.869632           0.894739   \n",
       "104           0.882669           0.870080           0.893739   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "594           0.896615         0.879483        0.016749                1  \n",
       "496           0.894489         0.879446        0.015738                2  \n",
       "25            0.895690         0.879302        0.016887                3  \n",
       "23            0.894489         0.879122        0.016598                4  \n",
       "10            0.898640         0.879104        0.017421                5  \n",
       "22            0.895490         0.878648        0.017614                6  \n",
       "186           0.894989         0.878559        0.018035                7  \n",
       "915           0.894489         0.878553        0.016529                8  \n",
       "269           0.894689         0.878376        0.016790                9  \n",
       "104           0.893789         0.878323        0.016075               10  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV here\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator = rf,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "512edc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 30,\n",
       " 'max_features': 6,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223aed9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f212a78",
   "metadata": {},
   "source": [
    "#### 5.3.1.3) Gradient Boosting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52310c5f",
   "metadata": {},
   "source": [
    "#### Hyperparameter search using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7ca636b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.05, 0.1, 0.15],\n",
       " 'n_estimators': [50, 100, 150],\n",
       " 'subsample': [0.8, 1],\n",
       " 'max_depth': [3, 6, 9, 12, 15],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto', 6, 8]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 19 # Input the number of features here. Alternatively estimate a model and get _n_features_in_ attribute\n",
    "max_features = ['auto', int(np.sqrt(n_features)) + 2, int(np.sqrt(n_features)) + 4]\n",
    "\n",
    "grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 1],\n",
    "    'max_depth': [3, 6, 9, 12, 15],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'max_features': max_features\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6e548c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune time:  335.24870467185974\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.148521</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>7.979635e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.851733</td>\n",
       "      <td>0.875554</td>\n",
       "      <td>0.870777</td>\n",
       "      <td>0.898590</td>\n",
       "      <td>0.892639</td>\n",
       "      <td>0.877858</td>\n",
       "      <td>0.016651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.067634</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>3.977555e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.849653</td>\n",
       "      <td>0.872319</td>\n",
       "      <td>0.871672</td>\n",
       "      <td>0.904215</td>\n",
       "      <td>0.887839</td>\n",
       "      <td>0.877140</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.140547</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>2.042390e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.876648</td>\n",
       "      <td>0.867542</td>\n",
       "      <td>0.899090</td>\n",
       "      <td>0.890589</td>\n",
       "      <td>0.877071</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.150133</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>2.174076e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.852376</td>\n",
       "      <td>0.871225</td>\n",
       "      <td>0.868339</td>\n",
       "      <td>0.900940</td>\n",
       "      <td>0.892389</td>\n",
       "      <td>0.877054</td>\n",
       "      <td>0.017462</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.071020</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>2.653204e-06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.854109</td>\n",
       "      <td>0.870229</td>\n",
       "      <td>0.870503</td>\n",
       "      <td>0.900040</td>\n",
       "      <td>0.890289</td>\n",
       "      <td>0.877034</td>\n",
       "      <td>0.016245</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.068625</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>1.162918e-03</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.15, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>0.880032</td>\n",
       "      <td>0.869583</td>\n",
       "      <td>0.897240</td>\n",
       "      <td>0.888239</td>\n",
       "      <td>0.876870</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.109227</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>4.889687e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.850668</td>\n",
       "      <td>0.872120</td>\n",
       "      <td>0.865975</td>\n",
       "      <td>0.899340</td>\n",
       "      <td>0.896090</td>\n",
       "      <td>0.876839</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.131367</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>4.156970e-07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.851733</td>\n",
       "      <td>0.875554</td>\n",
       "      <td>0.867194</td>\n",
       "      <td>0.898840</td>\n",
       "      <td>0.889589</td>\n",
       "      <td>0.876582</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.206885</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>4.886750e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.849950</td>\n",
       "      <td>0.873961</td>\n",
       "      <td>0.864059</td>\n",
       "      <td>0.898440</td>\n",
       "      <td>0.895740</td>\n",
       "      <td>0.876430</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0.077302</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>4.000264e-04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.15, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.848614</td>\n",
       "      <td>0.876001</td>\n",
       "      <td>0.867244</td>\n",
       "      <td>0.898690</td>\n",
       "      <td>0.891589</td>\n",
       "      <td>0.876428</td>\n",
       "      <td>0.017797</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "50        0.148521      0.004306         0.004588    7.979635e-04   \n",
       "18        0.067634      0.001158         0.003692    3.977555e-04   \n",
       "26        0.140547      0.003000         0.004092    2.042390e-04   \n",
       "38        0.150133      0.003126         0.005689    2.174076e-03   \n",
       "30        0.071020      0.001026         0.002993    2.653204e-06   \n",
       "558       0.068625      0.001532         0.003792    1.162918e-03   \n",
       "6         0.109227      0.006339         0.003591    4.889687e-04   \n",
       "21        0.131367      0.003753         0.003989    4.156970e-07   \n",
       "8         0.206885      0.003919         0.003591    4.886750e-04   \n",
       "582       0.077302      0.004127         0.003293    4.000264e-04   \n",
       "\n",
       "    param_learning_rate param_max_depth param_max_features  \\\n",
       "50                 0.05               3                  8   \n",
       "18                 0.05               3                  6   \n",
       "26                 0.05               3                  6   \n",
       "38                 0.05               3                  8   \n",
       "30                 0.05               3                  6   \n",
       "558                0.15               3                  6   \n",
       "6                  0.05               3               auto   \n",
       "21                 0.05               3                  6   \n",
       "8                  0.05               3               auto   \n",
       "582                0.15               3                  8   \n",
       "\n",
       "    param_min_samples_split param_n_estimators param_subsample  \\\n",
       "50                       10                100             0.8   \n",
       "18                        2                 50             0.8   \n",
       "26                        6                100             0.8   \n",
       "38                        2                100             0.8   \n",
       "30                       10                 50             0.8   \n",
       "558                       2                 50             0.8   \n",
       "6                         6                 50             0.8   \n",
       "21                        2                100               1   \n",
       "8                         6                100             0.8   \n",
       "582                       6                 50             0.8   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "50   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.851733   \n",
       "18   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.849653   \n",
       "26   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.851485   \n",
       "38   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.852376   \n",
       "30   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.854109   \n",
       "558  {'learning_rate': 0.15, 'max_depth': 3, 'max_f...           0.849257   \n",
       "6    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.850668   \n",
       "21   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.851733   \n",
       "8    {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.849950   \n",
       "582  {'learning_rate': 0.15, 'max_depth': 3, 'max_f...           0.848614   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "50            0.875554           0.870777           0.898590   \n",
       "18            0.872319           0.871672           0.904215   \n",
       "26            0.876648           0.867542           0.899090   \n",
       "38            0.871225           0.868339           0.900940   \n",
       "30            0.870229           0.870503           0.900040   \n",
       "558           0.880032           0.869583           0.897240   \n",
       "6             0.872120           0.865975           0.899340   \n",
       "21            0.875554           0.867194           0.898840   \n",
       "8             0.873961           0.864059           0.898440   \n",
       "582           0.876001           0.867244           0.898690   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "50            0.892639         0.877858        0.016651                1  \n",
       "18            0.887839         0.877140        0.018200                2  \n",
       "26            0.890589         0.877071        0.016812                3  \n",
       "38            0.892389         0.877054        0.017462                4  \n",
       "30            0.890289         0.877034        0.016245                5  \n",
       "558           0.888239         0.876870        0.016551                6  \n",
       "6             0.896090         0.876839        0.018450                7  \n",
       "21            0.889589         0.876582        0.016561                8  \n",
       "8             0.895740         0.876430        0.018534                9  \n",
       "582           0.891589         0.876428        0.017797               10  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV here\n",
    "start = time.time()\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Tune time: ', (time.time()-start))\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a10cf43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 8,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f6942d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.02, 0.035, 0.05],\n",
       " 'n_estimators': [50, 100],\n",
       " 'subsample': [0.8, 1.0],\n",
       " 'max_depth': [3],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto', 6, 8]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to reduce learning_rate and modify others \n",
    "\n",
    "grid = {\n",
    "    'learning_rate': [0.02, 0.035, 0.05],\n",
    "    'n_estimators': [50, 100],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_depth': [3],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'max_features': ['auto', 6, 8]\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b019642d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune time:  10.310890197753906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.137960</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>4.012587e-04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.850792</td>\n",
       "      <td>0.870279</td>\n",
       "      <td>0.870926</td>\n",
       "      <td>0.903490</td>\n",
       "      <td>0.894339</td>\n",
       "      <td>0.877965</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.145442</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>4.856809e-04</td>\n",
       "      <td>0.035</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.035, 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.873712</td>\n",
       "      <td>0.872021</td>\n",
       "      <td>0.899040</td>\n",
       "      <td>0.894989</td>\n",
       "      <td>0.877913</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.080701</td>\n",
       "      <td>0.008978</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>1.620893e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.850545</td>\n",
       "      <td>0.874210</td>\n",
       "      <td>0.869234</td>\n",
       "      <td>0.901615</td>\n",
       "      <td>0.893039</td>\n",
       "      <td>0.877729</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.155305</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>1.897788e-06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.851337</td>\n",
       "      <td>0.872518</td>\n",
       "      <td>0.870503</td>\n",
       "      <td>0.899890</td>\n",
       "      <td>0.894339</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.017567</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.235312</td>\n",
       "      <td>0.013626</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>8.888232e-04</td>\n",
       "      <td>0.035</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.035, 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.855396</td>\n",
       "      <td>0.874409</td>\n",
       "      <td>0.864408</td>\n",
       "      <td>0.898265</td>\n",
       "      <td>0.894039</td>\n",
       "      <td>0.877303</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.151616</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>3.991610e-04</td>\n",
       "      <td>0.035</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.035, 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.845644</td>\n",
       "      <td>0.874757</td>\n",
       "      <td>0.869160</td>\n",
       "      <td>0.900640</td>\n",
       "      <td>0.896290</td>\n",
       "      <td>0.877298</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.065941</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>7.461110e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.846188</td>\n",
       "      <td>0.872767</td>\n",
       "      <td>0.869707</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.897640</td>\n",
       "      <td>0.877178</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.075907</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>6.309020e-04</td>\n",
       "      <td>0.035</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.035, 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.850347</td>\n",
       "      <td>0.874708</td>\n",
       "      <td>0.867368</td>\n",
       "      <td>0.900240</td>\n",
       "      <td>0.892939</td>\n",
       "      <td>0.877120</td>\n",
       "      <td>0.017903</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.151426</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>4.422006e-07</td>\n",
       "      <td>0.035</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.035, 'max_depth': 3, 'max_...</td>\n",
       "      <td>0.852030</td>\n",
       "      <td>0.871921</td>\n",
       "      <td>0.866697</td>\n",
       "      <td>0.898040</td>\n",
       "      <td>0.895790</td>\n",
       "      <td>0.876895</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.076117</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>2.221035e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.849356</td>\n",
       "      <td>0.870478</td>\n",
       "      <td>0.873762</td>\n",
       "      <td>0.900740</td>\n",
       "      <td>0.889789</td>\n",
       "      <td>0.876825</td>\n",
       "      <td>0.017574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "19       0.137960      0.014494         0.004189    4.012587e-04   \n",
       "50       0.145442      0.006365         0.004092    4.856809e-04   \n",
       "84       0.080701      0.008978         0.004589    1.620893e-03   \n",
       "22       0.155305      0.016658         0.003990    1.897788e-06   \n",
       "38       0.235312      0.013626         0.004493    8.888232e-04   \n",
       "66       0.151616      0.003254         0.003790    3.991610e-04   \n",
       "93       0.065941      0.001353         0.003790    7.461110e-04   \n",
       "52       0.075907      0.003643         0.003990    6.309020e-04   \n",
       "70       0.151426      0.003546         0.003989    4.422006e-07   \n",
       "88       0.076117      0.004944         0.004787    2.221035e-03   \n",
       "\n",
       "   param_learning_rate param_max_depth param_max_features  \\\n",
       "19                0.02               3                  6   \n",
       "50               0.035               3                  6   \n",
       "84                0.05               3                  6   \n",
       "22                0.02               3                  6   \n",
       "38               0.035               3               auto   \n",
       "66               0.035               3                  8   \n",
       "93                0.05               3                  6   \n",
       "52               0.035               3                  6   \n",
       "70               0.035               3                  8   \n",
       "88                0.05               3                  6   \n",
       "\n",
       "   param_min_samples_split param_n_estimators param_subsample  \\\n",
       "19                       6                100             1.0   \n",
       "50                       2                100             0.8   \n",
       "84                       2                 50             0.8   \n",
       "22                      10                100             0.8   \n",
       "38                       2                100             0.8   \n",
       "66                       6                100             0.8   \n",
       "93                      10                 50             1.0   \n",
       "52                       6                 50             0.8   \n",
       "70                      10                100             0.8   \n",
       "88                       6                 50             0.8   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "19  {'learning_rate': 0.02, 'max_depth': 3, 'max_f...           0.850792   \n",
       "50  {'learning_rate': 0.035, 'max_depth': 3, 'max_...           0.849802   \n",
       "84  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.850545   \n",
       "22  {'learning_rate': 0.02, 'max_depth': 3, 'max_f...           0.851337   \n",
       "38  {'learning_rate': 0.035, 'max_depth': 3, 'max_...           0.855396   \n",
       "66  {'learning_rate': 0.035, 'max_depth': 3, 'max_...           0.845644   \n",
       "93  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.846188   \n",
       "52  {'learning_rate': 0.035, 'max_depth': 3, 'max_...           0.850347   \n",
       "70  {'learning_rate': 0.035, 'max_depth': 3, 'max_...           0.852030   \n",
       "88  {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.849356   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "19           0.870279           0.870926           0.903490   \n",
       "50           0.873712           0.872021           0.899040   \n",
       "84           0.874210           0.869234           0.901615   \n",
       "22           0.872518           0.870503           0.899890   \n",
       "38           0.874409           0.864408           0.898265   \n",
       "66           0.874757           0.869160           0.900640   \n",
       "93           0.872767           0.869707           0.899590   \n",
       "52           0.874708           0.867368           0.900240   \n",
       "70           0.871921           0.866697           0.898040   \n",
       "88           0.870478           0.873762           0.900740   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "19           0.894339         0.877965        0.018797                1  \n",
       "50           0.894989         0.877913        0.017779                2  \n",
       "84           0.893039         0.877729        0.018047                3  \n",
       "22           0.894339         0.877717        0.017567                4  \n",
       "38           0.894039         0.877303        0.016578                5  \n",
       "66           0.896290         0.877298        0.019901                6  \n",
       "93           0.897640         0.877178        0.019782                7  \n",
       "52           0.892939         0.877120        0.017903                8  \n",
       "70           0.895790         0.876895        0.017613                9  \n",
       "88           0.889789         0.876825        0.017574               10  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV here\n",
    "start = time.time()\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Tune time: ', (time.time()-start))\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1e4366ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.02,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 6,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8ab06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125db715",
   "metadata": {},
   "source": [
    "#### 5.3.1.4) Logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeea028",
   "metadata": {},
   "source": [
    "#### Explore Logistic regression through Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89e4cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.8216180371352785\n",
      "Test accuracy 0.8143236074270557\n",
      "Precison 0.8505747126436781\n",
      "Recall 0.8774703557312253\n"
     ]
    }
   ],
   "source": [
    "# Estimate base model\n",
    "logreg = LogisticRegression()\n",
    "logreg_fit = logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg_fit.predict(X_test)\n",
    "\n",
    "print('Train accuracy', logreg_fit.score(X_train, y_train))\n",
    "print('Test accuracy', logreg_fit.score(X_test, y_test))\n",
    "print('Precison', precision_score(y_test, y_pred))\n",
    "print('Recall', recall_score(y_test, y_pred))\n",
    "\n",
    "# See very good performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe48433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7781457 , 0.79470199, 0.81456954, 0.82059801, 0.8538206 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation with default hyperparemeters\n",
    "logreg = LogisticRegression()\n",
    "cross_val_score(logreg, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "327b96de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85861386, 0.86405931, 0.87172215, 0.89708971, 0.89608961])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use roc_auc as performance measure\n",
    "cross_val_score(logreg, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4be657",
   "metadata": {},
   "source": [
    "#### Hyperparameter search using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9fbcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': ['lbfgs',\n",
       "  'liblinear',\n",
       "  'newton-cg',\n",
       "  'newton-cholesky',\n",
       "  'sag',\n",
       "  'saga'],\n",
       " 'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       " 'C': [0.001, 0.1, 1, 10, 100]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "penalties = ['l1', 'l2', 'elasticnet', None]\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "grid = {'solver': solvers,\n",
    "        'penalty': penalties,\n",
    "        'C': Cs    \n",
    "        }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c8f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "425 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.5               nan        nan        nan 0.5\n",
      " 0.86121109 0.85856599 0.86121109        nan 0.86121109 0.86121109\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.87634272        nan        nan        nan 0.87550924\n",
      " 0.87805336 0.87612514 0.87806326        nan 0.87806336 0.87806326\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.87677886        nan        nan        nan 0.87708942\n",
      " 0.87751493 0.87716505 0.87750493        nan 0.87750493 0.87749493\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.87788195        nan        nan        nan 0.87785219\n",
      " 0.87799172 0.87791191 0.87799172        nan 0.87799172 0.87797176\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.87797181        nan        nan        nan 0.87794185\n",
      " 0.87802151 0.87796196 0.87803147        nan 0.87801176 0.8779418\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune time:  4.018561840057373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.869732</td>\n",
       "      <td>0.871225</td>\n",
       "      <td>0.89579</td>\n",
       "      <td>0.89669</td>\n",
       "      <td>0.878063</td>\n",
       "      <td>0.015659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.856931</td>\n",
       "      <td>0.869732</td>\n",
       "      <td>0.871225</td>\n",
       "      <td>0.89574</td>\n",
       "      <td>0.89669</td>\n",
       "      <td>0.878063</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.015263</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.856931</td>\n",
       "      <td>0.869732</td>\n",
       "      <td>0.871225</td>\n",
       "      <td>0.89574</td>\n",
       "      <td>0.89669</td>\n",
       "      <td>0.878063</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.015063</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.869732</td>\n",
       "      <td>0.871225</td>\n",
       "      <td>0.89574</td>\n",
       "      <td>0.89669</td>\n",
       "      <td>0.878053</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.027334</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.860792</td>\n",
       "      <td>0.862467</td>\n",
       "      <td>0.872419</td>\n",
       "      <td>0.89744</td>\n",
       "      <td>0.89704</td>\n",
       "      <td>0.878031</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.061347</td>\n",
       "      <td>0.035190</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.860792</td>\n",
       "      <td>0.862467</td>\n",
       "      <td>0.872369</td>\n",
       "      <td>0.89744</td>\n",
       "      <td>0.89704</td>\n",
       "      <td>0.878022</td>\n",
       "      <td>0.016183</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.069924</td>\n",
       "      <td>0.028470</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>0.860743</td>\n",
       "      <td>0.862517</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.89744</td>\n",
       "      <td>0.89719</td>\n",
       "      <td>0.878012</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>0.860545</td>\n",
       "      <td>0.862766</td>\n",
       "      <td>0.872369</td>\n",
       "      <td>0.89749</td>\n",
       "      <td>0.89679</td>\n",
       "      <td>0.877992</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.047982</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>0.860545</td>\n",
       "      <td>0.862766</td>\n",
       "      <td>0.872369</td>\n",
       "      <td>0.89749</td>\n",
       "      <td>0.89679</td>\n",
       "      <td>0.877992</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.045485</td>\n",
       "      <td>0.010890</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.860545</td>\n",
       "      <td>0.862766</td>\n",
       "      <td>0.872369</td>\n",
       "      <td>0.89749</td>\n",
       "      <td>0.89679</td>\n",
       "      <td>0.877992</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "34        0.011570      0.000798         0.003693        0.000984     0.1   \n",
       "32        0.020052      0.003920         0.002992        0.000631     0.1   \n",
       "35        0.015263      0.002434         0.004189        0.001466     0.1   \n",
       "30        0.015063      0.002328         0.003392        0.000488     0.1   \n",
       "104       0.027334      0.006725         0.002593        0.000488     100   \n",
       "102       0.061347      0.035190         0.008082        0.004310     100   \n",
       "106       0.069924      0.028470         0.007380        0.002863     100   \n",
       "80        0.029123      0.002308         0.003294        0.000400      10   \n",
       "82        0.047982      0.002515         0.004588        0.003192      10   \n",
       "78        0.045485      0.010890         0.002993        0.000892      10   \n",
       "\n",
       "    param_penalty param_solver  \\\n",
       "34             l2          sag   \n",
       "32             l2    newton-cg   \n",
       "35             l2         saga   \n",
       "30             l2        lbfgs   \n",
       "104            l2    newton-cg   \n",
       "102            l2        lbfgs   \n",
       "106            l2          sag   \n",
       "80             l2    newton-cg   \n",
       "82             l2          sag   \n",
       "78             l2        lbfgs   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "34        {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}           0.856881   \n",
       "32   {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...           0.856931   \n",
       "35       {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}           0.856931   \n",
       "30      {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.856881   \n",
       "104  {'C': 100, 'penalty': 'l2', 'solver': 'newton-...           0.860792   \n",
       "102     {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}           0.860792   \n",
       "106       {'C': 100, 'penalty': 'l2', 'solver': 'sag'}           0.860743   \n",
       "80   {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}           0.860545   \n",
       "82         {'C': 10, 'penalty': 'l2', 'solver': 'sag'}           0.860545   \n",
       "78       {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}           0.860545   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "34            0.869732           0.871225            0.89579   \n",
       "32            0.869732           0.871225            0.89574   \n",
       "35            0.869732           0.871225            0.89574   \n",
       "30            0.869732           0.871225            0.89574   \n",
       "104           0.862467           0.872419            0.89744   \n",
       "102           0.862467           0.872369            0.89744   \n",
       "106           0.862517           0.872170            0.89744   \n",
       "80            0.862766           0.872369            0.89749   \n",
       "82            0.862766           0.872369            0.89749   \n",
       "78            0.862766           0.872369            0.89749   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "34             0.89669         0.878063        0.015659                1  \n",
       "32             0.89669         0.878063        0.015634                2  \n",
       "35             0.89669         0.878063        0.015634                2  \n",
       "30             0.89669         0.878053        0.015648                4  \n",
       "104            0.89704         0.878031        0.016180                5  \n",
       "102            0.89704         0.878022        0.016183                6  \n",
       "106            0.89719         0.878012        0.016234                7  \n",
       "80             0.89679         0.877992        0.016133                8  \n",
       "82             0.89679         0.877992        0.016133                8  \n",
       "78             0.89679         0.877992        0.016133                8  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV here\n",
    "start = time.time()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "gs = GridSearchCV(estimator = logreg,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Tune time: ', (time.time()-start))\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bde86304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edc5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e3cb5c7",
   "metadata": {},
   "source": [
    "### 5.3.2) Modeling with Age as categorical type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9e305",
   "metadata": {},
   "source": [
    "#### 5.3.2.1) Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "327ba122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age25-34', 'age35-44', 'age45-54', 'age55-64', 'age65+', 'Male',\n",
       "       'Edu_gr2', 'Edu_gr3', 'Edu_gr4', 'Edu_gr5', 'Canada', 'New Zealand',\n",
       "       'Other', 'Republic of Ireland', 'UK', 'USA', 'ID', 'Age_value',\n",
       "       'Gender_value', 'Education_value', 'Country_value', 'Ethnicity_value',\n",
       "       'Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS',\n",
       "       'Amyl', 'Cannabis', 'Age', 'Gender', 'Education_level', 'Education',\n",
       "       'Country', 'Ethnicity', 'Age_level', 'Amyl_binary', 'Amyl_user',\n",
       "       'Cannabis_binary', 'Cannabis_user', 'Edu_gr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aa123c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "      <th>Edu_gr2</th>\n",
       "      <th>Edu_gr3</th>\n",
       "      <th>Edu_gr4</th>\n",
       "      <th>Edu_gr5</th>\n",
       "      <th>Canada</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Other</th>\n",
       "      <th>Republic of Ireland</th>\n",
       "      <th>UK</th>\n",
       "      <th>...</th>\n",
       "      <th>age45-54</th>\n",
       "      <th>age55-64</th>\n",
       "      <th>age65+</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.94779</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>0.94156</td>\n",
       "      <td>2.04506</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.52593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>-1.11902</td>\n",
       "      <td>1.45039</td>\n",
       "      <td>-0.78155</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.23177</td>\n",
       "      <td>-0.71727</td>\n",
       "      <td>-0.60633</td>\n",
       "      <td>-0.27607</td>\n",
       "      <td>1.86203</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>1.06238</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>0.93949</td>\n",
       "      <td>0.19268</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41667</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.88309</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>-0.52745</td>\n",
       "      <td>0.19268</td>\n",
       "      <td>-0.52593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.69163</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>1.24033</td>\n",
       "      <td>1.28610</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.19268</td>\n",
       "      <td>0.07987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.55078</td>\n",
       "      <td>1.28610</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-0.01729</td>\n",
       "      <td>0.75830</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.84637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>-1.11902</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>0.63779</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.58016</td>\n",
       "      <td>1.45421</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>1.61108</td>\n",
       "      <td>-0.40581</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Male  Edu_gr2  Edu_gr3  Edu_gr4  Edu_gr5  Canada  New Zealand  Other  \\\n",
       "1160     0        0        0        0        1       0            0      0   \n",
       "605      1        0        0        1        0       0            0      0   \n",
       "716      1        0        0        0        0       0            0      1   \n",
       "462      0        0        0        1        0       0            0      0   \n",
       "1499     1        0        0        1        0       0            0      0   \n",
       "847      1        0        0        0        1       0            0      0   \n",
       "38       1        0        0        1        0       0            0      0   \n",
       "86       1        0        1        0        0       0            0      0   \n",
       "651      1        0        1        0        0       0            0      0   \n",
       "975      0        0        0        0        1       0            0      0   \n",
       "\n",
       "      Republic of Ireland  UK  ...  age45-54  age55-64  age65+   Nscore  \\\n",
       "1160                    0   1  ...         0         0       0 -0.14882   \n",
       "605                     0   1  ...         0         0       0 -0.46725   \n",
       "716                     0   0  ...         0         0       0 -0.05188   \n",
       "462                     0   1  ...         0         0       0  0.31287   \n",
       "1499                    0   0  ...         0         0       0  0.41667   \n",
       "847                     0   0  ...         0         1       0 -1.69163   \n",
       "38                      0   1  ...         1         0       0 -1.55078   \n",
       "86                      0   1  ...         0         0       0  0.73545   \n",
       "651                     0   0  ...         0         0       0 -0.67825   \n",
       "975                     0   1  ...         0         0       0 -0.58016   \n",
       "\n",
       "       Escore   Oscore   Ascore   Cscore  Impulsive       SS  \n",
       "1160 -0.94779  0.29338  0.94156  2.04506   -0.71126 -0.52593  \n",
       "605   0.00332 -1.11902  1.45039 -0.78155   -0.21712  1.22470  \n",
       "716  -1.23177 -0.71727 -0.60633 -0.27607    1.86203  1.22470  \n",
       "462  -0.80615  1.06238  0.76096  0.93949    0.19268 -0.21575  \n",
       "1499 -1.92173  0.88309 -0.15487 -0.52745    0.19268 -0.52593  \n",
       "847   0.00332  1.24033  1.28610  0.41594    0.19268  0.07987  \n",
       "38    1.28610  0.29338 -0.01729  0.75830   -0.21712 -0.84637  \n",
       "86   -0.15487 -1.11902  0.13136 -0.14277   -0.21712  0.40148  \n",
       "651   0.63779 -0.01928  0.13136 -0.00665    1.29221  0.40148  \n",
       "975   1.45421 -1.27553  1.61108 -0.40581    1.29221  1.22470  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of taking 'Age_value' we will take 'age25-34', 'age35-44', 'age45-54', 'age55-64', 'age65+'\n",
    "col_list = ['Male', 'Edu_gr2', 'Edu_gr3', 'Edu_gr4', 'Edu_gr5', 'Canada', 'New Zealand', 'Other', 'Republic of Ireland', \n",
    "            'UK', 'USA', 'age25-34', 'age35-44', 'age45-54', 'age55-64', 'age65+', \n",
    "            'Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS']\n",
    "X = drug_2[col_list]\n",
    "X.sample(10)\n",
    "\n",
    "# Now we have 23 predictors instead of 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3ed3aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Cannabis_user, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = drug_2['Cannabis_user']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af333a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1508, 23) (1508,)\n",
      "(377, 23) (377,)\n"
     ]
    }
   ],
   "source": [
    "# Split with stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=12, stratify=y)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69a3253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug_2:  1    0.671088\n",
      "0    0.328912\n",
      "Name: Cannabis_user, dtype: float64\n",
      "y_train:  1    0.671088\n",
      "0    0.328912\n",
      "Name: Cannabis_user, dtype: float64\n",
      "y_test:  1    0.671088\n",
      "0    0.328912\n",
      "Name: Cannabis_user, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check stratify\n",
    "print('drug_2: ', drug_2['Cannabis_user'].value_counts(normalize=True))\n",
    "print('y_train: ', y_train.value_counts(normalize=True))\n",
    "print('y_test: ', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011857e",
   "metadata": {},
   "source": [
    "#### 5.3.2.2) Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e60ba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
      "['gini', 'entropy', 'log_loss']\n",
      "['auto', 6, 8]\n",
      "[10, 30, 50, 70, 90, None]\n",
      "[2, 6, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
       " 'criterion': ['gini', 'entropy', 'log_loss'],\n",
       " 'max_depth': [10, 30, 50, 70, 90, None],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto', 6, 8]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have 23 features instead of 19\n",
    "n_features = 23 # Input the number of features here. Alternatively estimate a model and get _n_features_in_ attribute\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 9)]\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "max_features = ['auto', int(np.sqrt(n_features)) + 2, int(np.sqrt(n_features)) + 4]\n",
    "max_depth = [int(x) for x in np.linspace(10, 90, num = 5)]   \n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 6, 10]\n",
    "\n",
    "print(n_estimators)\n",
    "print(criteria)\n",
    "print(max_features)\n",
    "print(max_depth)\n",
    "print(min_samples_split)\n",
    "\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'criterion': criteria,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'max_features': max_features\n",
    "        }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b960208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2430 fits failed out of a total of 7290.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2430 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.8638115  0.86737165 0.86678415 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.843829</td>\n",
       "      <td>0.047464</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>0.838663</td>\n",
       "      <td>0.882371</td>\n",
       "      <td>0.858287</td>\n",
       "      <td>0.883788</td>\n",
       "      <td>0.883488</td>\n",
       "      <td>0.869320</td>\n",
       "      <td>0.018121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.232828</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.839455</td>\n",
       "      <td>0.887197</td>\n",
       "      <td>0.856048</td>\n",
       "      <td>0.886639</td>\n",
       "      <td>0.876838</td>\n",
       "      <td>0.869235</td>\n",
       "      <td>0.018676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.914437</td>\n",
       "      <td>0.083216</td>\n",
       "      <td>0.065434</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>350</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
       "      <td>0.839406</td>\n",
       "      <td>0.881574</td>\n",
       "      <td>0.863164</td>\n",
       "      <td>0.885089</td>\n",
       "      <td>0.876338</td>\n",
       "      <td>0.869114</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.645407</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.046196</td>\n",
       "      <td>0.010121</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.841980</td>\n",
       "      <td>0.882918</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.882638</td>\n",
       "      <td>0.876388</td>\n",
       "      <td>0.869079</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.412094</td>\n",
       "      <td>0.073822</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'max_fe...</td>\n",
       "      <td>0.840644</td>\n",
       "      <td>0.883814</td>\n",
       "      <td>0.857491</td>\n",
       "      <td>0.878488</td>\n",
       "      <td>0.884638</td>\n",
       "      <td>0.869015</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.291382</td>\n",
       "      <td>0.045248</td>\n",
       "      <td>0.024448</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 30, 'max_fe...</td>\n",
       "      <td>0.838366</td>\n",
       "      <td>0.879733</td>\n",
       "      <td>0.865303</td>\n",
       "      <td>0.877788</td>\n",
       "      <td>0.883588</td>\n",
       "      <td>0.868956</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1.295632</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.094164</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>gini</td>\n",
       "      <td>70</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 70, 'max_fe...</td>\n",
       "      <td>0.839307</td>\n",
       "      <td>0.884759</td>\n",
       "      <td>0.861223</td>\n",
       "      <td>0.879388</td>\n",
       "      <td>0.879888</td>\n",
       "      <td>0.868913</td>\n",
       "      <td>0.016834</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.807514</td>\n",
       "      <td>0.117881</td>\n",
       "      <td>0.053265</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>0.837772</td>\n",
       "      <td>0.883515</td>\n",
       "      <td>0.858685</td>\n",
       "      <td>0.884388</td>\n",
       "      <td>0.879888</td>\n",
       "      <td>0.868850</td>\n",
       "      <td>0.018152</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.101385</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>0.081502</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 30, 'max_fe...</td>\n",
       "      <td>0.838861</td>\n",
       "      <td>0.880828</td>\n",
       "      <td>0.862616</td>\n",
       "      <td>0.881138</td>\n",
       "      <td>0.880788</td>\n",
       "      <td>0.868846</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.832155</td>\n",
       "      <td>0.084140</td>\n",
       "      <td>0.070028</td>\n",
       "      <td>0.018889</td>\n",
       "      <td>gini</td>\n",
       "      <td>90</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 90, 'max_fe...</td>\n",
       "      <td>0.835446</td>\n",
       "      <td>0.882122</td>\n",
       "      <td>0.864557</td>\n",
       "      <td>0.882738</td>\n",
       "      <td>0.878888</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "508       0.843829      0.047464         0.055556        0.003208   \n",
       "18        0.232828      0.003536         0.019251        0.000747   \n",
       "185       0.914437      0.083216         0.065434        0.009154   \n",
       "21        0.645407      0.146137         0.046196        0.010121   \n",
       "181       0.412094      0.073822         0.027925        0.001261   \n",
       "90        0.291382      0.045248         0.024448        0.007051   \n",
       "269       1.295632      0.087510         0.094164        0.009244   \n",
       "22        0.807514      0.117881         0.053265        0.003829   \n",
       "105       1.101385      0.106743         0.081502        0.017060   \n",
       "346       0.832155      0.084140         0.070028        0.018889   \n",
       "\n",
       "    param_criterion param_max_depth param_max_features  \\\n",
       "508         entropy              10               auto   \n",
       "18             gini              10               auto   \n",
       "185            gini              50               auto   \n",
       "21             gini              10               auto   \n",
       "181            gini              50               auto   \n",
       "90             gini              30               auto   \n",
       "269            gini              70               auto   \n",
       "22             gini              10               auto   \n",
       "105            gini              30               auto   \n",
       "346            gini              90               auto   \n",
       "\n",
       "    param_min_samples_split param_n_estimators  \\\n",
       "508                      10                300   \n",
       "18                       10                100   \n",
       "185                      10                350   \n",
       "21                       10                250   \n",
       "181                      10                150   \n",
       "90                        6                100   \n",
       "269                      10                500   \n",
       "22                       10                300   \n",
       "105                      10                400   \n",
       "346                      10                300   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "508  {'criterion': 'entropy', 'max_depth': 10, 'max...           0.838663   \n",
       "18   {'criterion': 'gini', 'max_depth': 10, 'max_fe...           0.839455   \n",
       "185  {'criterion': 'gini', 'max_depth': 50, 'max_fe...           0.839406   \n",
       "21   {'criterion': 'gini', 'max_depth': 10, 'max_fe...           0.841980   \n",
       "181  {'criterion': 'gini', 'max_depth': 50, 'max_fe...           0.840644   \n",
       "90   {'criterion': 'gini', 'max_depth': 30, 'max_fe...           0.838366   \n",
       "269  {'criterion': 'gini', 'max_depth': 70, 'max_fe...           0.839307   \n",
       "22   {'criterion': 'gini', 'max_depth': 10, 'max_fe...           0.837772   \n",
       "105  {'criterion': 'gini', 'max_depth': 30, 'max_fe...           0.838861   \n",
       "346  {'criterion': 'gini', 'max_depth': 90, 'max_fe...           0.835446   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "508           0.882371           0.858287           0.883788   \n",
       "18            0.887197           0.856048           0.886639   \n",
       "185           0.881574           0.863164           0.885089   \n",
       "21            0.882918           0.861472           0.882638   \n",
       "181           0.883814           0.857491           0.878488   \n",
       "90            0.879733           0.865303           0.877788   \n",
       "269           0.884759           0.861223           0.879388   \n",
       "22            0.883515           0.858685           0.884388   \n",
       "105           0.880828           0.862616           0.881138   \n",
       "346           0.882122           0.864557           0.882738   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "508           0.883488         0.869320        0.018121                1  \n",
       "18            0.876838         0.869235        0.018676                2  \n",
       "185           0.876338         0.869114        0.016617                3  \n",
       "21            0.876388         0.869079        0.015627                4  \n",
       "181           0.884638         0.869015        0.017266                5  \n",
       "90            0.883588         0.868956        0.016476                6  \n",
       "269           0.879888         0.868913        0.016834                7  \n",
       "22            0.879888         0.868850        0.018152                8  \n",
       "105           0.880788         0.868846        0.016584                9  \n",
       "346           0.878888         0.868750        0.017911               10  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV here\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator = rf,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]\n",
    "\n",
    "# It seems this take a while now, just with some more dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9961b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b70a40",
   "metadata": {},
   "source": [
    "#### 5.3.2.3) Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55f10b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.05, 0.1, 0.15],\n",
       " 'n_estimators': [50, 100, 150],\n",
       " 'subsample': [0.8, 1],\n",
       " 'max_depth': [3, 6, 9, 12, 15],\n",
       " 'min_samples_split': [2, 6, 10],\n",
       " 'max_features': ['auto', 6, 8]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have 23 features instead of 19\n",
    "n_features = 23 # Input the number of features here. Alternatively estimate a model and get _n_features_in_ attribute\n",
    "max_features = ['auto', int(np.sqrt(n_features)) + 2, int(np.sqrt(n_features)) + 4]\n",
    "\n",
    "grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'subsample': [0.8, 1],\n",
    "    'max_depth': [3, 6, 9, 12, 15],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'max_features': max_features\n",
    "    }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21f7d3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune time:  340.18131828308105\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.069725</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.15, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.842327</td>\n",
       "      <td>0.875554</td>\n",
       "      <td>0.866597</td>\n",
       "      <td>0.890089</td>\n",
       "      <td>0.894489</td>\n",
       "      <td>0.873811</td>\n",
       "      <td>0.018649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.170393</td>\n",
       "      <td>0.021737</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.848663</td>\n",
       "      <td>0.876648</td>\n",
       "      <td>0.869060</td>\n",
       "      <td>0.890889</td>\n",
       "      <td>0.882488</td>\n",
       "      <td>0.873550</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.081106</td>\n",
       "      <td>0.015224</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'max_fe...</td>\n",
       "      <td>0.841832</td>\n",
       "      <td>0.876798</td>\n",
       "      <td>0.862467</td>\n",
       "      <td>0.895040</td>\n",
       "      <td>0.883588</td>\n",
       "      <td>0.871945</td>\n",
       "      <td>0.018380</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.229138</td>\n",
       "      <td>0.058788</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.844901</td>\n",
       "      <td>0.874011</td>\n",
       "      <td>0.864059</td>\n",
       "      <td>0.891389</td>\n",
       "      <td>0.884388</td>\n",
       "      <td>0.871750</td>\n",
       "      <td>0.016313</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.205604</td>\n",
       "      <td>0.046656</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.842525</td>\n",
       "      <td>0.875355</td>\n",
       "      <td>0.860327</td>\n",
       "      <td>0.893189</td>\n",
       "      <td>0.886889</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.018365</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.148329</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.841832</td>\n",
       "      <td>0.877395</td>\n",
       "      <td>0.862865</td>\n",
       "      <td>0.893089</td>\n",
       "      <td>0.882838</td>\n",
       "      <td>0.871604</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.162003</td>\n",
       "      <td>0.028950</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.843960</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.858884</td>\n",
       "      <td>0.889589</td>\n",
       "      <td>0.882038</td>\n",
       "      <td>0.871587</td>\n",
       "      <td>0.017315</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.156711</td>\n",
       "      <td>0.044368</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.843168</td>\n",
       "      <td>0.876101</td>\n",
       "      <td>0.858685</td>\n",
       "      <td>0.891739</td>\n",
       "      <td>0.887089</td>\n",
       "      <td>0.871356</td>\n",
       "      <td>0.018114</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.240115</td>\n",
       "      <td>0.045160</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.844208</td>\n",
       "      <td>0.871623</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.894989</td>\n",
       "      <td>0.881138</td>\n",
       "      <td>0.871333</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.131973</td>\n",
       "      <td>0.022670</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>0.839703</td>\n",
       "      <td>0.875404</td>\n",
       "      <td>0.864433</td>\n",
       "      <td>0.890739</td>\n",
       "      <td>0.884813</td>\n",
       "      <td>0.871018</td>\n",
       "      <td>0.018014</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "570       0.069725      0.003043         0.004189        0.000398   \n",
       "38        0.170393      0.021737         0.003990        0.000892   \n",
       "295       0.081106      0.015224         0.003590        0.000798   \n",
       "47        0.229138      0.058788         0.004190        0.000398   \n",
       "35        0.205604      0.046656         0.004388        0.000488   \n",
       "20        0.148329      0.022601         0.004188        0.000399   \n",
       "44        0.162003      0.028950         0.005187        0.002393   \n",
       "32        0.156711      0.044368         0.003790        0.000398   \n",
       "28        0.240115      0.045160         0.004492        0.000447   \n",
       "27        0.131973      0.022670         0.004092        0.000207   \n",
       "\n",
       "    param_learning_rate param_max_depth param_max_features  \\\n",
       "570                0.15               3                  6   \n",
       "38                 0.05               3                  8   \n",
       "295                 0.1               3                  6   \n",
       "47                 0.05               3                  8   \n",
       "35                 0.05               3                  6   \n",
       "20                 0.05               3                  6   \n",
       "44                 0.05               3                  8   \n",
       "32                 0.05               3                  6   \n",
       "28                 0.05               3                  6   \n",
       "27                 0.05               3                  6   \n",
       "\n",
       "    param_min_samples_split param_n_estimators param_subsample  \\\n",
       "570                      10                 50             0.8   \n",
       "38                        2                100             0.8   \n",
       "295                       6                 50               1   \n",
       "47                        6                150               1   \n",
       "35                       10                150               1   \n",
       "20                        2                100             0.8   \n",
       "44                        6                100             0.8   \n",
       "32                       10                100             0.8   \n",
       "28                        6                150             0.8   \n",
       "27                        6                100               1   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "570  {'learning_rate': 0.15, 'max_depth': 3, 'max_f...           0.842327   \n",
       "38   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.848663   \n",
       "295  {'learning_rate': 0.1, 'max_depth': 3, 'max_fe...           0.841832   \n",
       "47   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.844901   \n",
       "35   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.842525   \n",
       "20   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.841832   \n",
       "44   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.843960   \n",
       "32   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.843168   \n",
       "28   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.844208   \n",
       "27   {'learning_rate': 0.05, 'max_depth': 3, 'max_f...           0.839703   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "570           0.875554           0.866597           0.890089   \n",
       "38            0.876648           0.869060           0.890889   \n",
       "295           0.876798           0.862467           0.895040   \n",
       "47            0.874011           0.864059           0.891389   \n",
       "35            0.875355           0.860327           0.893189   \n",
       "20            0.877395           0.862865           0.893089   \n",
       "44            0.883465           0.858884           0.889589   \n",
       "32            0.876101           0.858685           0.891739   \n",
       "28            0.871623           0.864706           0.894989   \n",
       "27            0.875404           0.864433           0.890739   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "570           0.894489         0.873811        0.018649                1  \n",
       "38            0.882488         0.873550        0.014350                2  \n",
       "295           0.883588         0.871945        0.018380                3  \n",
       "47            0.884388         0.871750        0.016313                4  \n",
       "35            0.886889         0.871657        0.018365                5  \n",
       "20            0.882838         0.871604        0.017800                6  \n",
       "44            0.882038         0.871587        0.017315                7  \n",
       "32            0.887089         0.871356        0.018114                8  \n",
       "28            0.881138         0.871333        0.016944                9  \n",
       "27            0.884813         0.871018        0.018014               10  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV here\n",
    "start = time.time()\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator = gb,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Tune time: ', (time.time()-start))\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cc92e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.15,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 6,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff8c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4683f65",
   "metadata": {},
   "source": [
    "#### 5.3.2.4) Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09a28091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': ['lbfgs',\n",
       "  'liblinear',\n",
       "  'newton-cg',\n",
       "  'newton-cholesky',\n",
       "  'sag',\n",
       "  'saga'],\n",
       " 'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       " 'C': [0.001, 0.1, 1, 10, 100]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "penalties = ['l1', 'l2', 'elasticnet', None]\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "grid = {'solver': solvers,\n",
    "        'penalty': penalties,\n",
    "        'C': Cs    \n",
    "        }\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc880383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune time:  4.190598487854004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "425 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.5               nan        nan        nan 0.5\n",
      " 0.83717058 0.83259433 0.83717058        nan 0.83717058 0.83716063\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.8604576         nan        nan        nan 0.86225613\n",
      " 0.86958118 0.86631868 0.86958118        nan 0.86958118 0.86957123\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.87640766        nan        nan        nan 0.87644769\n",
      " 0.87643739 0.87562807 0.87644734        nan 0.87644734 0.87642734\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.87737674        nan        nan        nan 0.87776353\n",
      " 0.87798175 0.87785284 0.87798175        nan 0.87798165 0.87795185\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.87766633        nan        nan        nan 0.87776363\n",
      " 0.87765602 0.87777519 0.87771538        nan 0.87780434 0.87777348\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>4.457074e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>0.860941</td>\n",
       "      <td>0.863462</td>\n",
       "      <td>0.870826</td>\n",
       "      <td>0.89954</td>\n",
       "      <td>0.895140</td>\n",
       "      <td>0.877982</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.028427</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>7.979989e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.860941</td>\n",
       "      <td>0.863462</td>\n",
       "      <td>0.870826</td>\n",
       "      <td>0.89954</td>\n",
       "      <td>0.895140</td>\n",
       "      <td>0.877982</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.071518</td>\n",
       "      <td>0.029514</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>3.240473e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>0.860990</td>\n",
       "      <td>0.863462</td>\n",
       "      <td>0.870826</td>\n",
       "      <td>0.89949</td>\n",
       "      <td>0.895140</td>\n",
       "      <td>0.877982</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.035710</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>1.507891e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.860842</td>\n",
       "      <td>0.863412</td>\n",
       "      <td>0.870976</td>\n",
       "      <td>0.89949</td>\n",
       "      <td>0.895040</td>\n",
       "      <td>0.877952</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>2.522703e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.860396</td>\n",
       "      <td>0.863711</td>\n",
       "      <td>0.870578</td>\n",
       "      <td>0.90004</td>\n",
       "      <td>0.894539</td>\n",
       "      <td>0.877853</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.029224</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.305248e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>0.859554</td>\n",
       "      <td>0.862666</td>\n",
       "      <td>0.871822</td>\n",
       "      <td>0.89934</td>\n",
       "      <td>0.895640</td>\n",
       "      <td>0.877804</td>\n",
       "      <td>0.016613</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.989220e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.858960</td>\n",
       "      <td>0.862815</td>\n",
       "      <td>0.872021</td>\n",
       "      <td>0.89944</td>\n",
       "      <td>0.895640</td>\n",
       "      <td>0.877775</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.069022</td>\n",
       "      <td>0.039454</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>4.086242e-03</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.860198</td>\n",
       "      <td>0.862815</td>\n",
       "      <td>0.871225</td>\n",
       "      <td>0.89939</td>\n",
       "      <td>0.895240</td>\n",
       "      <td>0.877773</td>\n",
       "      <td>0.016419</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.084489</td>\n",
       "      <td>0.052379</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>3.591084e-03</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 100, 'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>0.860149</td>\n",
       "      <td>0.862815</td>\n",
       "      <td>0.871175</td>\n",
       "      <td>0.89944</td>\n",
       "      <td>0.895240</td>\n",
       "      <td>0.877764</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.094759</td>\n",
       "      <td>0.040709</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>3.882661e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>0.859950</td>\n",
       "      <td>0.863064</td>\n",
       "      <td>0.871424</td>\n",
       "      <td>0.89954</td>\n",
       "      <td>0.894839</td>\n",
       "      <td>0.877764</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "80        0.026928      0.003153         0.002496    4.457074e-04      10   \n",
       "78        0.028427      0.007026         0.002394    7.979989e-04      10   \n",
       "82        0.071518      0.029514         0.005187    3.240473e-03      10   \n",
       "83        0.035710      0.005958         0.001995    1.507891e-07      10   \n",
       "79        0.007979      0.002092         0.003989    2.522703e-03      10   \n",
       "106       0.029224      0.001073         0.001995    6.305248e-04     100   \n",
       "103       0.005385      0.000489         0.001795    3.989220e-04     100   \n",
       "107       0.069022      0.039454         0.005489    4.086242e-03     100   \n",
       "101       0.084489      0.052379         0.003791    3.591084e-03     100   \n",
       "77        0.094759      0.040709         0.004291    3.882661e-03      10   \n",
       "\n",
       "    param_penalty param_solver  \\\n",
       "80             l2    newton-cg   \n",
       "78             l2        lbfgs   \n",
       "82             l2          sag   \n",
       "83             l2         saga   \n",
       "79             l2    liblinear   \n",
       "106            l2          sag   \n",
       "103            l2    liblinear   \n",
       "107            l2         saga   \n",
       "101            l1         saga   \n",
       "77             l1         saga   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "80   {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}           0.860941   \n",
       "78       {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}           0.860941   \n",
       "82         {'C': 10, 'penalty': 'l2', 'solver': 'sag'}           0.860990   \n",
       "83        {'C': 10, 'penalty': 'l2', 'solver': 'saga'}           0.860842   \n",
       "79   {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}           0.860396   \n",
       "106       {'C': 100, 'penalty': 'l2', 'solver': 'sag'}           0.859554   \n",
       "103  {'C': 100, 'penalty': 'l2', 'solver': 'libline...           0.858960   \n",
       "107      {'C': 100, 'penalty': 'l2', 'solver': 'saga'}           0.860198   \n",
       "101      {'C': 100, 'penalty': 'l1', 'solver': 'saga'}           0.860149   \n",
       "77        {'C': 10, 'penalty': 'l1', 'solver': 'saga'}           0.859950   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "80            0.863462           0.870826            0.89954   \n",
       "78            0.863462           0.870826            0.89954   \n",
       "82            0.863462           0.870826            0.89949   \n",
       "83            0.863412           0.870976            0.89949   \n",
       "79            0.863711           0.870578            0.90004   \n",
       "106           0.862666           0.871822            0.89934   \n",
       "103           0.862815           0.872021            0.89944   \n",
       "107           0.862815           0.871225            0.89939   \n",
       "101           0.862815           0.871175            0.89944   \n",
       "77            0.863064           0.871424            0.89954   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "80            0.895140         0.877982        0.016196                1  \n",
       "78            0.895140         0.877982        0.016196                1  \n",
       "82            0.895140         0.877982        0.016172                3  \n",
       "83            0.895040         0.877952        0.016178                4  \n",
       "79            0.894539         0.877853        0.016300                5  \n",
       "106           0.895640         0.877804        0.016613                6  \n",
       "103           0.895640         0.877775        0.016730                7  \n",
       "107           0.895240         0.877773        0.016419                8  \n",
       "101           0.895240         0.877764        0.016446                9  \n",
       "77            0.894839         0.877764        0.016367               10  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV here\n",
    "start = time.time()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "gs = GridSearchCV(estimator = logreg,\n",
    "                  param_grid = grid,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "\n",
    "print('Tune time: ', (time.time()-start))\n",
    "\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6532521e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147fd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe800394",
   "metadata": {},
   "source": [
    "### 5.3.3) Optimal threshold and final model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589bb9b",
   "metadata": {},
   "source": [
    "#### 5.3.3.1) Choosing optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a637ee7",
   "metadata": {},
   "source": [
    "#### 5.3.3.2) Evaluate performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908d989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bad8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600879b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58465fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77043d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccbe81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b547b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172460d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc9e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd8fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a4fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a9be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
